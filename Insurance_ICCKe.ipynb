{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Insurance/blob/main/Insurance_ICCKe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Load the dataset from Google Drive\n",
        "file_path = '/content/drive/My Drive/Insurance/telematics_syn.csv'\n",
        "df = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cVLFKKghSnQ",
        "outputId": "32d2cdb8-594f-4d4d-ae9c-465c6d841af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "XcAkEjP-hiKL",
        "outputId": "87cff44d-07c9-440c-c776-b30e20a10d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
              "0       366           45        Male       -1  Married  Commute         609.0   \n",
              "1       182           44      Female        3  Married  Commute         575.0   \n",
              "2       184           48      Female        6  Married  Commute         847.0   \n",
              "3       183           71        Male        6  Married  Private         842.0   \n",
              "4       183           84        Male       10  Married  Private         856.0   \n",
              "\n",
              "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
              "0  Urban             6213.71              25  ...                    1.0   \n",
              "1  Urban            12427.42              20  ...                   58.0   \n",
              "2  Urban            12427.42              14  ...                    0.0   \n",
              "3  Urban             6213.71              43  ...                    0.0   \n",
              "4  Urban             6213.71              65  ...                    2.0   \n",
              "\n",
              "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
              "0                    0.0                    0.0                     3.0   \n",
              "1                   24.0                   11.0                  1099.0   \n",
              "2                    0.0                    0.0                     0.0   \n",
              "3                    0.0                    0.0                     0.0   \n",
              "4                    0.0                    0.0                   325.0   \n",
              "\n",
              "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
              "0                     1.0                     0.0                     0.0   \n",
              "1                   615.0                   219.0                   101.0   \n",
              "2                     0.0                     0.0                     0.0   \n",
              "3                     0.0                     0.0                     0.0   \n",
              "4                   111.0                    18.0                     4.0   \n",
              "\n",
              "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
              "0                     0.0         1  5100.171753  \n",
              "1                    40.0         1   883.554840  \n",
              "2                     0.0         0     0.000000  \n",
              "3                     0.0         0     0.000000  \n",
              "4                     2.0         0     0.000000  \n",
              "\n",
              "[5 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa98e2b7-3bcb-4d06-a847-35732214e916\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Insured.age</th>\n",
              "      <th>Insured.sex</th>\n",
              "      <th>Car.age</th>\n",
              "      <th>Marital</th>\n",
              "      <th>Car.use</th>\n",
              "      <th>Credit.score</th>\n",
              "      <th>Region</th>\n",
              "      <th>Annual.miles.drive</th>\n",
              "      <th>Years.noclaims</th>\n",
              "      <th>...</th>\n",
              "      <th>Left.turn.intensity10</th>\n",
              "      <th>Left.turn.intensity11</th>\n",
              "      <th>Left.turn.intensity12</th>\n",
              "      <th>Right.turn.intensity08</th>\n",
              "      <th>Right.turn.intensity09</th>\n",
              "      <th>Right.turn.intensity10</th>\n",
              "      <th>Right.turn.intensity11</th>\n",
              "      <th>Right.turn.intensity12</th>\n",
              "      <th>NB_Claim</th>\n",
              "      <th>AMT_Claim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>366</td>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>-1</td>\n",
              "      <td>Married</td>\n",
              "      <td>Commute</td>\n",
              "      <td>609.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>6213.71</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5100.171753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182</td>\n",
              "      <td>44</td>\n",
              "      <td>Female</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>Commute</td>\n",
              "      <td>575.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>12427.42</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>58.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1099.0</td>\n",
              "      <td>615.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>883.554840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184</td>\n",
              "      <td>48</td>\n",
              "      <td>Female</td>\n",
              "      <td>6</td>\n",
              "      <td>Married</td>\n",
              "      <td>Commute</td>\n",
              "      <td>847.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>12427.42</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>183</td>\n",
              "      <td>71</td>\n",
              "      <td>Male</td>\n",
              "      <td>6</td>\n",
              "      <td>Married</td>\n",
              "      <td>Private</td>\n",
              "      <td>842.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>6213.71</td>\n",
              "      <td>43</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183</td>\n",
              "      <td>84</td>\n",
              "      <td>Male</td>\n",
              "      <td>10</td>\n",
              "      <td>Married</td>\n",
              "      <td>Private</td>\n",
              "      <td>856.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>6213.71</td>\n",
              "      <td>65</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>325.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 52 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa98e2b7-3bcb-4d06-a847-35732214e916')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa98e2b7-3bcb-4d06-a847-35732214e916 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa98e2b7-3bcb-4d06-a847-35732214e916');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f27933aa-784e-4f79-94c0-3bfd174554a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f27933aa-784e-4f79-94c0-3bfd174554a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f27933aa-784e-4f79-94c0-3bfd174554a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "2KoCyTpSiP32",
        "outputId": "ff53c60d-5b51-4536-fe84-e10ac6ed9aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Duration    Insured.age        Car.age   Credit.score  \\\n",
              "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
              "mean      314.204060      51.378950       5.639720     800.888870   \n",
              "std        79.746222      15.467075       4.062135      83.382316   \n",
              "min        27.000000      16.000000      -2.000000     422.000000   \n",
              "25%       200.000000      39.000000       2.000000     766.000000   \n",
              "50%       365.000000      51.000000       5.000000     825.000000   \n",
              "75%       366.000000      63.000000       8.000000     856.000000   \n",
              "max       366.000000     103.000000      20.000000     900.000000   \n",
              "\n",
              "       Annual.miles.drive  Years.noclaims      Territory  Annual.pct.driven  \\\n",
              "count       100000.000000   100000.000000  100000.000000      100000.000000   \n",
              "mean          9124.122908       28.839960      56.531390           0.502294   \n",
              "std           3826.144730       16.123717      24.036518           0.299189   \n",
              "min              0.000000        0.000000      11.000000           0.002740   \n",
              "25%           6213.710000       15.000000      35.000000           0.249315   \n",
              "50%           7456.452000       29.000000      62.000000           0.490411   \n",
              "75%          12427.420000       41.000000      78.000000           0.753425   \n",
              "max          56731.172300       79.000000      91.000000           1.000000   \n",
              "\n",
              "       Total.miles.driven  Pct.drive.mon  ...  Left.turn.intensity10  \\\n",
              "count       100000.000000  100000.000000  ...          100000.000000   \n",
              "mean          4833.575303       0.139365  ...             551.574010   \n",
              "std           4545.943016       0.042807  ...           14687.929802   \n",
              "min              0.095298       0.000000  ...               0.000000   \n",
              "25%           1529.897500       0.120894  ...               0.000000   \n",
              "50%           3468.287765       0.137909  ...               3.000000   \n",
              "75%           6779.876842       0.155203  ...              30.000000   \n",
              "max          47282.603936       0.998172  ...          794380.000000   \n",
              "\n",
              "       Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
              "count          100000.000000          100000.000000           100000.000000   \n",
              "mean              487.340690             447.758420              843.461830   \n",
              "std             14198.331308           13719.790281            11630.185503   \n",
              "min                 0.000000               0.000000                0.000000   \n",
              "25%                 0.000000               0.000000               11.000000   \n",
              "50%                 1.000000               0.000000              122.000000   \n",
              "75%                 9.000000               2.000000              680.000000   \n",
              "max            793926.000000          793170.000000           841210.000000   \n",
              "\n",
              "       Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
              "count           100000.000000           100000.000000           100000.000000   \n",
              "mean               565.056100              326.654840              246.713120   \n",
              "std              10657.402935             9460.244357             8977.569994   \n",
              "min                  0.000000                0.000000                0.000000   \n",
              "25%                  3.000000                0.000000                0.000000   \n",
              "50%                 43.000000                7.000000                2.000000   \n",
              "75%                321.000000               81.000000               27.000000   \n",
              "max             841207.000000           841200.000000           841176.000000   \n",
              "\n",
              "       Right.turn.intensity12      NB_Claim      AMT_Claim  \n",
              "count           100000.000000  100000.00000  100000.000000  \n",
              "mean               198.753690       0.04494     137.602253  \n",
              "std               8585.177049       0.21813    1264.320056  \n",
              "min                  0.000000       0.00000       0.000000  \n",
              "25%                  0.000000       0.00000       0.000000  \n",
              "50%                  0.000000       0.00000       0.000000  \n",
              "75%                  9.000000       0.00000       0.000000  \n",
              "max             841144.000000       3.00000  104074.886700  \n",
              "\n",
              "[8 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a8ecca5-de9f-453c-bb76-74c0bfb7efe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Insured.age</th>\n",
              "      <th>Car.age</th>\n",
              "      <th>Credit.score</th>\n",
              "      <th>Annual.miles.drive</th>\n",
              "      <th>Years.noclaims</th>\n",
              "      <th>Territory</th>\n",
              "      <th>Annual.pct.driven</th>\n",
              "      <th>Total.miles.driven</th>\n",
              "      <th>Pct.drive.mon</th>\n",
              "      <th>...</th>\n",
              "      <th>Left.turn.intensity10</th>\n",
              "      <th>Left.turn.intensity11</th>\n",
              "      <th>Left.turn.intensity12</th>\n",
              "      <th>Right.turn.intensity08</th>\n",
              "      <th>Right.turn.intensity09</th>\n",
              "      <th>Right.turn.intensity10</th>\n",
              "      <th>Right.turn.intensity11</th>\n",
              "      <th>Right.turn.intensity12</th>\n",
              "      <th>NB_Claim</th>\n",
              "      <th>AMT_Claim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.00000</td>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>314.204060</td>\n",
              "      <td>51.378950</td>\n",
              "      <td>5.639720</td>\n",
              "      <td>800.888870</td>\n",
              "      <td>9124.122908</td>\n",
              "      <td>28.839960</td>\n",
              "      <td>56.531390</td>\n",
              "      <td>0.502294</td>\n",
              "      <td>4833.575303</td>\n",
              "      <td>0.139365</td>\n",
              "      <td>...</td>\n",
              "      <td>551.574010</td>\n",
              "      <td>487.340690</td>\n",
              "      <td>447.758420</td>\n",
              "      <td>843.461830</td>\n",
              "      <td>565.056100</td>\n",
              "      <td>326.654840</td>\n",
              "      <td>246.713120</td>\n",
              "      <td>198.753690</td>\n",
              "      <td>0.04494</td>\n",
              "      <td>137.602253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>79.746222</td>\n",
              "      <td>15.467075</td>\n",
              "      <td>4.062135</td>\n",
              "      <td>83.382316</td>\n",
              "      <td>3826.144730</td>\n",
              "      <td>16.123717</td>\n",
              "      <td>24.036518</td>\n",
              "      <td>0.299189</td>\n",
              "      <td>4545.943016</td>\n",
              "      <td>0.042807</td>\n",
              "      <td>...</td>\n",
              "      <td>14687.929802</td>\n",
              "      <td>14198.331308</td>\n",
              "      <td>13719.790281</td>\n",
              "      <td>11630.185503</td>\n",
              "      <td>10657.402935</td>\n",
              "      <td>9460.244357</td>\n",
              "      <td>8977.569994</td>\n",
              "      <td>8585.177049</td>\n",
              "      <td>0.21813</td>\n",
              "      <td>1264.320056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>422.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.002740</td>\n",
              "      <td>0.095298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>200.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>766.000000</td>\n",
              "      <td>6213.710000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.249315</td>\n",
              "      <td>1529.897500</td>\n",
              "      <td>0.120894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>365.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>825.000000</td>\n",
              "      <td>7456.452000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.490411</td>\n",
              "      <td>3468.287765</td>\n",
              "      <td>0.137909</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>366.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>856.000000</td>\n",
              "      <td>12427.420000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>6779.876842</td>\n",
              "      <td>0.155203</td>\n",
              "      <td>...</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>680.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>366.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>900.000000</td>\n",
              "      <td>56731.172300</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>47282.603936</td>\n",
              "      <td>0.998172</td>\n",
              "      <td>...</td>\n",
              "      <td>794380.000000</td>\n",
              "      <td>793926.000000</td>\n",
              "      <td>793170.000000</td>\n",
              "      <td>841210.000000</td>\n",
              "      <td>841207.000000</td>\n",
              "      <td>841200.000000</td>\n",
              "      <td>841176.000000</td>\n",
              "      <td>841144.000000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>104074.886700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a8ecca5-de9f-453c-bb76-74c0bfb7efe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a8ecca5-de9f-453c-bb76-74c0bfb7efe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a8ecca5-de9f-453c-bb76-74c0bfb7efe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5fe5576e-cdc2-4768-ad6a-774158fd52f9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fe5576e-cdc2-4768-ad6a-774158fd52f9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5fe5576e-cdc2-4768-ad6a-774158fd52f9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYk3fcETiesu",
        "outputId": "387dec5b-b13d-49fe-bb4f-752648313758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Duration                100000 non-null  int64  \n",
            " 1   Insured.age             100000 non-null  int64  \n",
            " 2   Insured.sex             100000 non-null  object \n",
            " 3   Car.age                 100000 non-null  int64  \n",
            " 4   Marital                 100000 non-null  object \n",
            " 5   Car.use                 100000 non-null  object \n",
            " 6   Credit.score            100000 non-null  float64\n",
            " 7   Region                  100000 non-null  object \n",
            " 8   Annual.miles.drive      100000 non-null  float64\n",
            " 9   Years.noclaims          100000 non-null  int64  \n",
            " 10  Territory               100000 non-null  int64  \n",
            " 11  Annual.pct.driven       100000 non-null  float64\n",
            " 12  Total.miles.driven      100000 non-null  float64\n",
            " 13  Pct.drive.mon           100000 non-null  float64\n",
            " 14  Pct.drive.tue           100000 non-null  float64\n",
            " 15  Pct.drive.wed           100000 non-null  float64\n",
            " 16  Pct.drive.thr           100000 non-null  float64\n",
            " 17  Pct.drive.fri           100000 non-null  float64\n",
            " 18  Pct.drive.sat           100000 non-null  float64\n",
            " 19  Pct.drive.sun           100000 non-null  float64\n",
            " 20  Pct.drive.2hrs          100000 non-null  float64\n",
            " 21  Pct.drive.3hrs          100000 non-null  float64\n",
            " 22  Pct.drive.4hrs          100000 non-null  float64\n",
            " 23  Pct.drive.wkday         100000 non-null  float64\n",
            " 24  Pct.drive.wkend         100000 non-null  float64\n",
            " 25  Pct.drive.rush am       100000 non-null  float64\n",
            " 26  Pct.drive.rush pm       100000 non-null  float64\n",
            " 27  Avgdays.week            100000 non-null  float64\n",
            " 28  Accel.06miles           100000 non-null  float64\n",
            " 29  Accel.08miles           100000 non-null  float64\n",
            " 30  Accel.09miles           100000 non-null  float64\n",
            " 31  Accel.11miles           100000 non-null  float64\n",
            " 32  Accel.12miles           100000 non-null  float64\n",
            " 33  Accel.14miles           100000 non-null  float64\n",
            " 34  Brake.06miles           100000 non-null  float64\n",
            " 35  Brake.08miles           100000 non-null  float64\n",
            " 36  Brake.09miles           100000 non-null  float64\n",
            " 37  Brake.11miles           100000 non-null  float64\n",
            " 38  Brake.12miles           100000 non-null  float64\n",
            " 39  Brake.14miles           100000 non-null  float64\n",
            " 40  Left.turn.intensity08   100000 non-null  float64\n",
            " 41  Left.turn.intensity09   100000 non-null  float64\n",
            " 42  Left.turn.intensity10   100000 non-null  float64\n",
            " 43  Left.turn.intensity11   100000 non-null  float64\n",
            " 44  Left.turn.intensity12   100000 non-null  float64\n",
            " 45  Right.turn.intensity08  100000 non-null  float64\n",
            " 46  Right.turn.intensity09  100000 non-null  float64\n",
            " 47  Right.turn.intensity10  100000 non-null  float64\n",
            " 48  Right.turn.intensity11  100000 non-null  float64\n",
            " 49  Right.turn.intensity12  100000 non-null  float64\n",
            " 50  NB_Claim                100000 non-null  int64  \n",
            " 51  AMT_Claim               100000 non-null  float64\n",
            "dtypes: float64(42), int64(6), object(4)\n",
            "memory usage: 39.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Preprocessing\n",
        "\n",
        "# Derive the target variable\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "TD3smLImjBrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "BF7Vx3xdlbJm",
        "outputId": "3f635d5d-e734-4c04-9b14-960a08dbb695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Duration  Insured.age  Car.age  Credit.score  Annual.miles.drive  \\\n",
              "0       366           45       -1         609.0             6213.71   \n",
              "1       182           44        3         575.0            12427.42   \n",
              "2       184           48        6         847.0            12427.42   \n",
              "3       183           71        6         842.0             6213.71   \n",
              "4       183           84       10         856.0             6213.71   \n",
              "\n",
              "   Years.noclaims  Territory  Annual.pct.driven  Total.miles.driven  \\\n",
              "0              25         70           0.849315         8864.376247   \n",
              "1              20         26           0.465753         8092.308208   \n",
              "2              14         84           0.520548         3225.832512   \n",
              "3              43         30           0.065753          253.024528   \n",
              "4              65         70           0.441096         4374.379634   \n",
              "\n",
              "   Pct.drive.mon  ...  Right.turn.intensity10  Right.turn.intensity11  \\\n",
              "0       0.148070  ...                     0.0                     0.0   \n",
              "1       0.147686  ...                   219.0                   101.0   \n",
              "2       0.153735  ...                     0.0                     0.0   \n",
              "3       0.106702  ...                     0.0                     0.0   \n",
              "4       0.123807  ...                    18.0                     4.0   \n",
              "\n",
              "   Right.turn.intensity12  ClaimYN  Insured.sex_Male  Marital_Single  \\\n",
              "0                     0.0        1              True           False   \n",
              "1                    40.0        0             False           False   \n",
              "2                     0.0        0             False           False   \n",
              "3                     0.0        0              True           False   \n",
              "4                     2.0        0              True           False   \n",
              "\n",
              "   Car.use_Commute  Car.use_Farmer  Car.use_Private  Region_Urban  \n",
              "0             True           False            False          True  \n",
              "1             True           False            False          True  \n",
              "2             True           False            False          True  \n",
              "3            False           False             True          True  \n",
              "4            False           False             True          True  \n",
              "\n",
              "[5 rows x 53 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-621758f9-8f03-4ac5-b8a1-c5d155199472\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Insured.age</th>\n",
              "      <th>Car.age</th>\n",
              "      <th>Credit.score</th>\n",
              "      <th>Annual.miles.drive</th>\n",
              "      <th>Years.noclaims</th>\n",
              "      <th>Territory</th>\n",
              "      <th>Annual.pct.driven</th>\n",
              "      <th>Total.miles.driven</th>\n",
              "      <th>Pct.drive.mon</th>\n",
              "      <th>...</th>\n",
              "      <th>Right.turn.intensity10</th>\n",
              "      <th>Right.turn.intensity11</th>\n",
              "      <th>Right.turn.intensity12</th>\n",
              "      <th>ClaimYN</th>\n",
              "      <th>Insured.sex_Male</th>\n",
              "      <th>Marital_Single</th>\n",
              "      <th>Car.use_Commute</th>\n",
              "      <th>Car.use_Farmer</th>\n",
              "      <th>Car.use_Private</th>\n",
              "      <th>Region_Urban</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>366</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>609.0</td>\n",
              "      <td>6213.71</td>\n",
              "      <td>25</td>\n",
              "      <td>70</td>\n",
              "      <td>0.849315</td>\n",
              "      <td>8864.376247</td>\n",
              "      <td>0.148070</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182</td>\n",
              "      <td>44</td>\n",
              "      <td>3</td>\n",
              "      <td>575.0</td>\n",
              "      <td>12427.42</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>0.465753</td>\n",
              "      <td>8092.308208</td>\n",
              "      <td>0.147686</td>\n",
              "      <td>...</td>\n",
              "      <td>219.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184</td>\n",
              "      <td>48</td>\n",
              "      <td>6</td>\n",
              "      <td>847.0</td>\n",
              "      <td>12427.42</td>\n",
              "      <td>14</td>\n",
              "      <td>84</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>3225.832512</td>\n",
              "      <td>0.153735</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>183</td>\n",
              "      <td>71</td>\n",
              "      <td>6</td>\n",
              "      <td>842.0</td>\n",
              "      <td>6213.71</td>\n",
              "      <td>43</td>\n",
              "      <td>30</td>\n",
              "      <td>0.065753</td>\n",
              "      <td>253.024528</td>\n",
              "      <td>0.106702</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183</td>\n",
              "      <td>84</td>\n",
              "      <td>10</td>\n",
              "      <td>856.0</td>\n",
              "      <td>6213.71</td>\n",
              "      <td>65</td>\n",
              "      <td>70</td>\n",
              "      <td>0.441096</td>\n",
              "      <td>4374.379634</td>\n",
              "      <td>0.123807</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 53 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-621758f9-8f03-4ac5-b8a1-c5d155199472')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-621758f9-8f03-4ac5-b8a1-c5d155199472 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-621758f9-8f03-4ac5-b8a1-c5d155199472');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dcb92f77-409a-4e69-80fa-479cc44244f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcb92f77-409a-4e69-80fa-479cc44244f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dcb92f77-409a-4e69-80fa-479cc44244f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the 'ClaimYN' column from the DataFrame 'df'\n",
        "df['ClaimYN'].describe()  # Use .describe() for distribution statistics\n",
        "\n",
        "# Or, if you want the ClaimYN Series:\n",
        "ClaimYN_series = df['ClaimYN']\n",
        "ClaimYN_series.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "eZq_BMdVlbEN",
        "outputId": "b4744f07-ac85-4d18-82c9-f991bd25bb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    100000.000000\n",
              "mean          0.026980\n",
              "std           0.162026\n",
              "min           0.000000\n",
              "25%           0.000000\n",
              "50%           0.000000\n",
              "75%           0.000000\n",
              "max           1.000000\n",
              "Name: ClaimYN, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ClaimYN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.026980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.162026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Dual-Path Machine Learning Framework for Driver Risk Assessment\n",
        "# Complete Step-by-Step Implementation with Innovations\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, RandomizedSearchCV, cross_val_score,\n",
        "    StratifiedKFold, learning_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import (\n",
        "    mutual_info_classif, SelectKBest, RFE, VarianceThreshold\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
        "    roc_curve, precision_recall_curve, average_precision_score,\n",
        "    classification_report, log_loss\n",
        ")\n",
        "from sklearn.inspection import permutation_importance, partial_dependence\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "\n",
        "# Class Imbalance Handling\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, BatchNormalization, LSTM,\n",
        "    GRU, Attention, MultiHeadAttention, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "# Interpretability\n",
        "try:\n",
        "    import shap\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "    INTERPRETABILITY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    INTERPRETABILITY_AVAILABLE = False\n",
        "    print(\"SHAP/LIME not available. Install for interpretability features.\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: ENHANCED xLSTM IMPLEMENTATION\n",
        "# =============================================================================\n",
        "\n",
        "class xLSTMCell(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Enhanced xLSTM Cell with exponential gating and matrix memory\n",
        "    Innovation: Implements advanced memory mechanisms for temporal patterns\n",
        "    \"\"\"\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = [units, units, units]  # h, c, m (matrix memory)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Input gates with exponential gating\n",
        "        self.W_i = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_i', initializer='glorot_uniform')\n",
        "        self.U_i = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_i', initializer='orthogonal')\n",
        "        self.b_i = self.add_weight(shape=(self.units,), name='b_i',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        # Forget gates with enhanced memory control\n",
        "        self.W_f = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_f', initializer='glorot_uniform')\n",
        "        self.U_f = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_f', initializer='orthogonal')\n",
        "        self.b_f = self.add_weight(shape=(self.units,), name='b_f',\n",
        "                                  initializer='ones')\n",
        "\n",
        "        # Candidate values\n",
        "        self.W_c = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_c', initializer='glorot_uniform')\n",
        "        self.U_c = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_c', initializer='orthogonal')\n",
        "        self.b_c = self.add_weight(shape=(self.units,), name='b_c',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        # Output gates\n",
        "        self.W_o = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_o', initializer='glorot_uniform')\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_o', initializer='orthogonal')\n",
        "        self.b_o = self.add_weight(shape=(self.units,), name='b_o',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        # Matrix memory weights (Innovation)\n",
        "        self.W_m = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_m', initializer='glorot_uniform')\n",
        "        self.U_m = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_m', initializer='orthogonal')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        h_prev, c_prev, m_prev = states\n",
        "\n",
        "        # Exponential input gate (Innovation)\n",
        "        i = tf.nn.sigmoid(tf.matmul(inputs, self.W_i) +\n",
        "                         tf.matmul(h_prev, self.U_i) + self.b_i)\n",
        "        i = tf.exp(i) / (tf.exp(i) + 1)  # Exponential gating\n",
        "\n",
        "        # Enhanced forget gate with matrix memory influence\n",
        "        f = tf.nn.sigmoid(tf.matmul(inputs, self.W_f) +\n",
        "                         tf.matmul(h_prev, self.U_f) +\n",
        "                         tf.reduce_mean(m_prev, axis=-1, keepdims=True) + self.b_f)\n",
        "\n",
        "        # Candidate values\n",
        "        c_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_c) +\n",
        "                               tf.matmul(h_prev, self.U_c) + self.b_c)\n",
        "\n",
        "        # Matrix memory update (Innovation)\n",
        "        m_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_m) +\n",
        "                               tf.matmul(h_prev, self.U_m))\n",
        "        m_new = f * m_prev + i * tf.expand_dims(m_candidate, axis=-1)\n",
        "\n",
        "        # Cell state update with matrix memory influence\n",
        "        c_new = f * c_prev + i * c_candidate * tf.reduce_mean(m_new, axis=-1)\n",
        "\n",
        "        # Output gate\n",
        "        o = tf.nn.sigmoid(tf.matmul(inputs, self.W_o) +\n",
        "                         tf.matmul(h_prev, self.U_o) + self.b_o)\n",
        "\n",
        "        # Hidden state with matrix memory\n",
        "        h_new = o * tf.nn.tanh(c_new + tf.reduce_mean(m_new, axis=-1))\n",
        "\n",
        "        return h_new, [h_new, c_new, m_new]\n",
        "\n",
        "class xLSTMLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"xLSTM Layer wrapper for sequential processing\"\"\"\n",
        "    def __init__(self, units, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.return_sequences = return_sequences\n",
        "        self.cell = xLSTMCell(units)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "\n",
        "        # Initialize states\n",
        "        h = tf.zeros((batch_size, self.units))\n",
        "        c = tf.zeros((batch_size, self.units))\n",
        "        m = tf.zeros((batch_size, self.units, self.units))\n",
        "        states = [h, c, m]\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            output, states = self.cell(inputs[:, t, :], states)\n",
        "            outputs.append(output)\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return tf.stack(outputs, axis=1)\n",
        "        else:\n",
        "            return outputs[-1]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: COMPREHENSIVE DATA PREPROCESSING CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedDataPreprocessor:\n",
        "    \"\"\"\n",
        "    Comprehensive data preprocessing with multiple scaling strategies\n",
        "    and advanced feature engineering\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scaling_method='standard', handle_outliers=True):\n",
        "        self.scaling_method = scaling_method\n",
        "        self.handle_outliers = handle_outliers\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.categorical_features = []\n",
        "        self.numerical_features = []\n",
        "\n",
        "    def detect_feature_types(self, df):\n",
        "        \"\"\"Automatically detect categorical and numerical features\"\"\"\n",
        "        categorical = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        numerical = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        return categorical, numerical\n",
        "\n",
        "    def handle_missing_values(self, df):\n",
        "        \"\"\"Advanced missing value handling\"\"\"\n",
        "        # Handle negative Car.age values as missing\n",
        "        if 'Car.age' in df.columns:\n",
        "            df.loc[df['Car.age'] < 0, 'Car.age'] = np.nan\n",
        "            df['Car.age'].fillna(df['Car.age'].median(), inplace=True)\n",
        "\n",
        "        # Fill other missing values\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                if df[col].dtype in ['object', 'category']:\n",
        "                    df[col].fillna(df[col].mode().iloc[0], inplace=True)\n",
        "                else:\n",
        "                    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def remove_outliers(self, df, method='iqr', threshold=3):\n",
        "        \"\"\"Remove outliers using IQR or Z-score method\"\"\"\n",
        "        if not self.handle_outliers:\n",
        "            return df\n",
        "\n",
        "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        if method == 'iqr':\n",
        "            for col in numerical_cols:\n",
        "                Q1 = df[col].quantile(0.25)\n",
        "                Q3 = df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "\n",
        "        elif method == 'zscore':\n",
        "            for col in numerical_cols:\n",
        "                z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n",
        "                df = df[z_scores < threshold]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def log_transform_skewed_features(self, df, skewness_threshold=0.75):\n",
        "        \"\"\"Apply log transformation to highly skewed features\"\"\"\n",
        "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        for col in numerical_cols:\n",
        "            if df[col].min() >= 0:  # Can only log-transform non-negative values\n",
        "                skewness = df[col].skew()\n",
        "                if abs(skewness) > skewness_threshold:\n",
        "                    # Add small constant to handle zeros\n",
        "                    df[f'{col}_log'] = np.log1p(df[col])\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_interaction_features(self, df):\n",
        "        \"\"\"Create interaction features for behavioral metrics\"\"\"\n",
        "        # Acceleration-Brake intensity combinations\n",
        "        accel_cols = [col for col in df.columns if 'Accel' in col]\n",
        "        brake_cols = [col for col in df.columns if 'Brake' in col]\n",
        "\n",
        "        for accel_col in accel_cols:\n",
        "            for brake_col in brake_cols:\n",
        "                if accel_col.split('.')[-1] == brake_col.split('.')[-1]:  # Same mile threshold\n",
        "                    df[f'{accel_col}_x_{brake_col}'] = df[accel_col] * df[brake_col]\n",
        "\n",
        "        # Turn intensity ratios\n",
        "        left_turn_cols = [col for col in df.columns if 'Left.turn.intensity' in col]\n",
        "        right_turn_cols = [col for col in df.columns if 'Right.turn.intensity' in col]\n",
        "\n",
        "        for left_col in left_turn_cols:\n",
        "            for right_col in right_turn_cols:\n",
        "                if left_col.split('intensity')[-1] == right_col.split('intensity')[-1]:\n",
        "                    # Avoid division by zero\n",
        "                    df[f'{left_col}_ratio_{right_col}'] = (\n",
        "                        df[left_col] / (df[right_col] + 1e-8)\n",
        "                    )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        \"\"\"Fit preprocessor and transform data\"\"\"\n",
        "        df = X.copy()\n",
        "\n",
        "        # Store original feature names\n",
        "        self.feature_names = df.columns.tolist()\n",
        "\n",
        "        # Detect feature types\n",
        "        self.categorical_features, self.numerical_features = self.detect_feature_types(df)\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Remove outliers\n",
        "        if y is not None:\n",
        "            original_indices = df.index\n",
        "            df = self.remove_outliers(df)\n",
        "            # Filter y to match filtered df\n",
        "            y = y.loc[df.index] if hasattr(y, 'loc') else y[df.index]\n",
        "\n",
        "        # Log transform skewed features\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "\n",
        "        # Create interaction features\n",
        "        df = self.create_interaction_features(df)\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True)\n",
        "\n",
        "        # Update numerical features after transformations\n",
        "        self.numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Apply scaling\n",
        "        if self.scaling_method == 'standard':\n",
        "            scaler = StandardScaler()\n",
        "        elif self.scaling_method == 'robust':\n",
        "            scaler = RobustScaler()\n",
        "        elif self.scaling_method == 'minmax':\n",
        "            scaler = MinMaxScaler()\n",
        "        else:\n",
        "            scaler = StandardScaler()\n",
        "\n",
        "        df[self.numerical_features] = scaler.fit_transform(df[self.numerical_features])\n",
        "        self.scalers['numerical'] = scaler\n",
        "\n",
        "        return df, y\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted preprocessor\"\"\"\n",
        "        df = X.copy()\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Log transform skewed features\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "\n",
        "        # Create interaction features\n",
        "        df = self.create_interaction_features(df)\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True)\n",
        "\n",
        "        # Ensure all columns are present\n",
        "        for col in self.numerical_features:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "\n",
        "        # Apply scaling\n",
        "        if 'numerical' in self.scalers:\n",
        "            df[self.numerical_features] = self.scalers['numerical'].transform(\n",
        "                df[self.numerical_features]\n",
        "            )\n",
        "\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: ADVANCED CLASS IMBALANCE HANDLER\n",
        "# =============================================================================\n",
        "\n",
        "class AdvancedImbalanceHandler:\n",
        "    \"\"\"\n",
        "    Advanced class imbalance handling with multiple techniques\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, method='smote_tomek', random_state=42):\n",
        "        self.method = method\n",
        "        self.random_state = random_state\n",
        "        self.sampler = None\n",
        "\n",
        "    def get_sampler(self):\n",
        "        \"\"\"Get appropriate sampler based on method\"\"\"\n",
        "        if self.method == 'smote':\n",
        "            return SMOTE(random_state=self.random_state)\n",
        "        elif self.method == 'smote_tomek':\n",
        "            return SMOTETomek(random_state=self.random_state)\n",
        "        elif self.method == 'adasyn':\n",
        "            return ADASYN(random_state=self.random_state)\n",
        "        elif self.method == 'borderline_smote':\n",
        "            return BorderlineSMOTE(random_state=self.random_state)\n",
        "        else:\n",
        "            return SMOTE(random_state=self.random_state)\n",
        "\n",
        "    def fit_resample(self, X, y):\n",
        "        \"\"\"Apply resampling to training data\"\"\"\n",
        "        self.sampler = self.get_sampler()\n",
        "        X_resampled, y_resampled = self.sampler.fit_resample(X, y)\n",
        "\n",
        "        print(f\"Original class distribution: {np.bincount(y)}\")\n",
        "        print(f\"Resampled class distribution: {np.bincount(y_resampled)}\")\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: ENHANCED FEATURE SELECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedFeatureSelector:\n",
        "    \"\"\"\n",
        "    Multi-method feature selection with ensemble approach\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_features=20, methods=['mutual_info', 'rfe', 'variance']):\n",
        "        self.n_features = n_features\n",
        "        self.methods = methods\n",
        "        self.selected_features = None\n",
        "        self.feature_scores = {}\n",
        "\n",
        "    def mutual_info_selection(self, X, y):\n",
        "        \"\"\"Feature selection using mutual information\"\"\"\n",
        "        mi_scores = mutual_info_classif(X, y, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, mi_scores))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "\n",
        "    def rfe_selection(self, X, y):\n",
        "        \"\"\"Recursive Feature Elimination\"\"\"\n",
        "        estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "        selector = RFE(estimator, n_features_to_select=self.n_features)\n",
        "        selector.fit(X, y)\n",
        "\n",
        "        feature_scores = dict(zip(X.columns, selector.ranking_))\n",
        "        selected_features = X.columns[selector.support_].tolist()\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def variance_selection(self, X, threshold=0.01):\n",
        "        \"\"\"Remove low-variance features\"\"\"\n",
        "        selector = VarianceThreshold(threshold=threshold)\n",
        "        selector.fit(X)\n",
        "        selected_features = X.columns[selector.get_support()].tolist()\n",
        "        feature_scores = dict(zip(X.columns, selector.variances_))\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def permutation_importance_selection(self, X, y):\n",
        "        \"\"\"Feature selection using permutation importance\"\"\"\n",
        "        estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "        estimator.fit(X, y)\n",
        "\n",
        "        perm_importance = permutation_importance(estimator, X, y, n_repeats=5, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, perm_importance.importances_mean))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "\n",
        "    def ensemble_selection(self, X, y):\n",
        "        \"\"\"Ensemble feature selection combining multiple methods\"\"\"\n",
        "        all_selected_features = []\n",
        "        method_scores = {}\n",
        "\n",
        "        if 'mutual_info' in self.methods:\n",
        "            features, scores = self.mutual_info_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['mutual_info'] = scores\n",
        "\n",
        "        if 'rfe' in self.methods:\n",
        "            features, scores = self.rfe_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['rfe'] = scores\n",
        "\n",
        "        if 'variance' in self.methods:\n",
        "            features, scores = self.variance_selection(X)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['variance'] = scores\n",
        "\n",
        "        if 'permutation' in self.methods:\n",
        "            features, scores = self.permutation_importance_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['permutation'] = scores\n",
        "\n",
        "        # Count feature frequency across methods\n",
        "        feature_counts = defaultdict(int)\n",
        "        for feature in all_selected_features:\n",
        "            feature_counts[feature] += 1\n",
        "\n",
        "        # Select features that appear in multiple methods\n",
        "        ensemble_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.selected_features = [feat[0] for feat in ensemble_features[:self.n_features]]\n",
        "        self.feature_scores = method_scores\n",
        "\n",
        "        return self.selected_features, method_scores\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: ENHANCED GRADIENT BOOSTING MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedGradientBoosting:\n",
        "    \"\"\"Enhanced Gradient Boosting with advanced hyperparameter optimization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.cv_results = None\n",
        "\n",
        "    def get_param_grid(self):\n",
        "        \"\"\"Enhanced parameter grid for optimization\"\"\"\n",
        "        return {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "            'max_depth': [3, 5, 7, 9],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'subsample': [0.8, 0.9, 1.0],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "\n",
        "    def optimize_hyperparameters(self, X, y, cv_folds=5, n_iter=50):\n",
        "        \"\"\"Optimize hyperparameters using RandomizedSearchCV\"\"\"\n",
        "        gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=gb_classifier,\n",
        "            param_distributions=self.get_param_grid(),\n",
        "            n_iter=n_iter,\n",
        "            cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
        "            scoring='roc_auc',\n",
        "            n_jobs=-1,\n",
        "            random_state=42,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        search.fit(X, y)\n",
        "        self.best_params = search.best_params_\n",
        "        self.cv_results = search.cv_results_\n",
        "        self.model = search.best_estimator_\n",
        "\n",
        "        print(\"Best Gradient Boosting Parameters:\")\n",
        "        for param, value in self.best_params.items():\n",
        "            print(f\"  {param}: {value}\")\n",
        "        print(f\"Best CV Score: {search.best_score_:.4f}\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: ENHANCED NEURAL NETWORK WITH xLSTM\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedNeuralNetwork:\n",
        "    \"\"\"Enhanced Neural Network with xLSTM integration\"\"\"\n",
        "\n",
        "    def __init__(self, include_xlstm=True):\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.include_xlstm = include_xlstm\n",
        "\n",
        "    def create_mlp_model(self, input_dim, hidden_layers=[128, 64, 32]):\n",
        "        \"\"\"Create Multi-Layer Perceptron model\"\"\"\n",
        "        inputs = Input(shape=(input_dim,))\n",
        "        x = inputs\n",
        "\n",
        "        for i, units in enumerate(hidden_layers):\n",
        "            x = Dense(units, activation='relu',\n",
        "                     kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(0.3)(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def create_xlstm_enhanced_model(self, input_dim, sequence_features=None):\n",
        "        \"\"\"Create xLSTM-enhanced model for sequential features\"\"\"\n",
        "        if sequence_features is None:\n",
        "            sequence_features = ['Daily.Driving.Percentage', 'Night.Driving.Percentage',\n",
        "                               'Avg.Speed.Per.Trip']\n",
        "\n",
        "        # Main input\n",
        "        main_input = Input(shape=(input_dim,), name='main_input')\n",
        "\n",
        "        # Sequential features processing with xLSTM\n",
        "        if self.include_xlstm:\n",
        "            # Reshape sequential features for xLSTM processing\n",
        "            seq_input = Input(shape=(len(sequence_features), 1), name='seq_input')\n",
        "            xlstm_output = xLSTMLayer(64, return_sequences=False)(seq_input)\n",
        "            xlstm_dense = Dense(32, activation='relu')(xlstm_output)\n",
        "\n",
        "            # Combine main features with xLSTM output\n",
        "            combined = keras.layers.concatenate([main_input, xlstm_dense])\n",
        "        else:\n",
        "            combined = main_input\n",
        "\n",
        "        # MLP layers\n",
        "        x = Dense(128, activation='relu',\n",
        "                 kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = Dense(64, activation='relu',\n",
        "                 kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        if self.include_xlstm:\n",
        "            model = Model(inputs=[main_input, seq_input], outputs=outputs)\n",
        "        else:\n",
        "            model = Model(inputs=main_input, outputs=outputs)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def compile_and_train(self, model, X_train, y_train, X_val, y_val,\n",
        "                         epochs=100, batch_size=32):\n",
        "        \"\"\"Compile and train the neural network\"\"\"\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', 'precision', 'recall']\n",
        "        )\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
        "        ]\n",
        "\n",
        "        if isinstance(X_train, list):  # xLSTM model with multiple inputs\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "        else:  # Standard MLP model\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "        self.model = model\n",
        "        self.history = history\n",
        "        return model, history\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: WEIGHTED ENSEMBLE INTEGRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class WeightedEnsemble:\n",
        "    \"\"\"Advanced weighted ensemble with dynamic weight calculation\"\"\"\n",
        "\n",
        "    def __init__(self, models, weight_method='accuracy'):\n",
        "        self.models = models\n",
        "        self.weight_method = weight_method\n",
        "        self.weights = None\n",
        "\n",
        "    def calculate_weights(self, X_val, y_val):\n",
        "        \"\"\"Calculate dynamic weights based on validation performance\"\"\"\n",
        "        accuracies = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred = model.predict_proba(X_val)[:, 1]\n",
        "            else:\n",
        "                y_pred = model.predict(X_val)\n",
        "\n",
        "            if self.weight_method == 'accuracy':\n",
        "                y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "                accuracies[name] = accuracy_score(y_val, y_pred_binary)\n",
        "            elif self.weight_method == 'auc':\n",
        "                accuracies[name] = roc_auc_score(y_val, y_pred)\n",
        "            elif self.weight_method == 'f1':\n",
        "                y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "                accuracies[name] = f1_score(y_val, y_pred_binary)\n",
        "\n",
        "        # Normalize weights\n",
        "        total_accuracy = sum(accuracies.values())\n",
        "        self.weights = {name: acc/total_accuracy for name, acc in accuracies.items()}\n",
        "\n",
        "        print(\"Ensemble Weights:\")\n",
        "        for name, weight in self.weights.items():\n",
        "            print(f\"  {name}: {weight:.4f}\")\n",
        "\n",
        "        return self.weights\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Generate ensemble predictions\"\"\"\n",
        "        predictions = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                predictions[name] = model.predict_proba(X)[:, 1]\n",
        "            else:\n",
        "                predictions[name] = model.predict(X)\n",
        "\n",
        "        # Weighted average\n",
        "        ensemble_pred = np.zeros(len(X))\n",
        "        for name, pred in predictions.items():\n",
        "            ensemble_pred += self.weights[name] * pred\n",
        "\n",
        "        return ensemble_pred\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        \"\"\"Generate binary predictions\"\"\"\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba > threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: THRESHOLD OPTIMIZER\n",
        "# =============================================================================\n",
        "\n",
        "class ThresholdOptimizer:\n",
        "    \"\"\"Optimize classification threshold for specific metrics\"\"\"\n",
        "\n",
        "    def __init__(self, metric='f1'):\n",
        "        self.metric = metric\n",
        "        self.optimal_threshold = 0.5\n",
        "\n",
        "    def optimize(self, y_true, y_pred_proba):\n",
        "        \"\"\"Find optimal threshold\"\"\"\n",
        "        thresholds = np.linspace(0.01, 0.99, 100)\n",
        "        best_score = 0\n",
        "        best_threshold = 0.5\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "            if self.metric == 'f1':\n",
        "                score = f1_score(y_true, y_pred, zero_division=0)\n",
        "            elif self.metric == 'precision':\n",
        "                score = precision_score(y_true, y_pred, zero_division=0)\n",
        "            elif self.metric == 'recall':\n",
        "                score = recall_score(y_true, y_pred, zero_division=0)\n",
        "            elif self.metric == 'balanced':\n",
        "                precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "                recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "                score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "\n",
        "        self.optimal_threshold = best_threshold\n",
        "        print(f\"Optimal threshold for {self.metric}: {best_threshold:.4f}\")\n",
        "        print(f\"Best {self.metric} score: {best_score:.4f}\")\n",
        "\n",
        "        return best_threshold\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: COMPREHENSIVE MODEL EVALUATOR\n",
        "# =============================================================================\n",
        "\n",
        "class ComprehensiveEvaluator:\n",
        "    \"\"\"Comprehensive model evaluation with advanced metrics and visualizations\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def calculate_all_metrics(self, y_true, y_pred, y_pred_proba, model_name):\n",
        "        \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
        "            'auc_roc': roc_auc_score(y_true, y_pred_proba),\n",
        "            'mcc': matthews_corrcoef(y_true, y_pred),\n",
        "            'log_loss': log_loss(y_true, y_pred_proba),\n",
        "            'avg_precision': average_precision_score(y_true, y_pred_proba)\n",
        "        }\n",
        "\n",
        "        self.results[model_name] = metrics\n",
        "        return metrics\n",
        "\n",
        "    def plot_comprehensive_evaluation(self, y_true, y_pred_proba_dict):\n",
        "        \"\"\"Create comprehensive evaluation plots\"\"\"\n",
        "        n_models = len(y_pred_proba_dict)\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "        # ROC Curves\n",
        "        ax = axes[0, 0]\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "            auc_score = roc_auc_score(y_true, y_pred_proba)\n",
        "            ax.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
        "\n",
        "        ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.set_title('ROC Curves')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Precision-Recall Curves\n",
        "        ax = axes[0, 1]\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            avg_precision = average_precision_score(y_true, y_pred_proba)\n",
        "            ax.plot(recall, precision, label=f'{model_name} (AP = {avg_precision:.3f})')\n",
        "\n",
        "        ax.set_xlabel('Recall')\n",
        "        ax.set_ylabel('Precision')\n",
        "        ax.set_title('Precision-Recall Curves')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Model Comparison Bar Chart\n",
        "        ax = axes[0, 2]\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc_roc']\n",
        "        x = np.arange(len(metrics))\n",
        "        width = 0.8 / len(y_pred_proba_dict)\n",
        "\n",
        "        for i, (model_name, _) in enumerate(y_pred_proba_dict.items()):\n",
        "            if model_name in self.results:\n",
        "                values = [self.results[model_name][metric] for metric in metrics]\n",
        "                ax.bar(x + i * width, values, width, label=model_name, alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Metrics')\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title('Model Comparison')\n",
        "        ax.set_xticks(x + width/2)\n",
        "        ax.set_xticklabels(metrics, rotation=45)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Confusion Matrices\n",
        "        if len(y_pred_proba_dict) <= 3:\n",
        "            for i, (model_name, y_pred_proba) in enumerate(y_pred_proba_dict.items()):\n",
        "                ax = axes[1, i]\n",
        "                y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "                cm = confusion_matrix(y_true, y_pred)\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "                ax.set_title(f'{model_name} Confusion Matrix')\n",
        "                ax.set_xlabel('Predicted')\n",
        "                ax.set_ylabel('Actual')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def print_results_table(self):\n",
        "        \"\"\"Print formatted results table\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"No results to display\")\n",
        "            return\n",
        "\n",
        "        # Create DataFrame for better formatting\n",
        "        df_results = pd.DataFrame(self.results).T\n",
        "        df_results = df_results.round(4)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results.to_string())\n",
        "        print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: MODEL INTERPRETABILITY SUITE\n",
        "# =============================================================================\n",
        "\n",
        "class InterpretabilitySuite:\n",
        "    \"\"\"Comprehensive model interpretability using SHAP and LIME\"\"\"\n",
        "\n",
        "    def __init__(self, models, feature_names):\n",
        "        self.models = models\n",
        "        self.feature_names = feature_names\n",
        "        self.explainers = {}\n",
        "\n",
        "    def setup_shap_explainers(self, X_background, sample_size=100):\n",
        "        \"\"\"Setup SHAP explainers for all models\"\"\"\n",
        "        if not INTERPRETABILITY_AVAILABLE:\n",
        "            print(\"SHAP not available. Install shap package for interpretability.\")\n",
        "            return\n",
        "\n",
        "        # Sample background data\n",
        "        if len(X_background) > sample_size:\n",
        "            background_sample = shap.sample(X_background, sample_size)\n",
        "        else:\n",
        "            background_sample = X_background\n",
        "\n",
        "        for model_name, model in self.models.items():\n",
        "            try:\n",
        "                if hasattr(model, 'predict_proba'):\n",
        "                    self.explainers[model_name] = shap.KernelExplainer(\n",
        "                        lambda x: model.predict_proba(x)[:, 1],\n",
        "                        background_sample\n",
        "                    )\n",
        "                else:\n",
        "                    self.explainers[model_name] = shap.KernelExplainer(\n",
        "                        model.predict, background_sample\n",
        "                    )\n",
        "                print(f\"SHAP explainer ready for {model_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to create SHAP explainer for {model_name}: {e}\")\n",
        "\n",
        "    def explain_predictions(self, X_explain, model_name, max_display=10):\n",
        "        \"\"\"Generate SHAP explanations for predictions\"\"\"\n",
        "        if not INTERPRETABILITY_AVAILABLE or model_name not in self.explainers:\n",
        "            print(f\"SHAP explainer not available for {model_name}\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            shap_values = self.explainers[model_name].shap_values(X_explain)\n",
        "\n",
        "            # Summary plot\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            shap.summary_plot(shap_values, X_explain,\n",
        "                            feature_names=self.feature_names[:X_explain.shape[1]],\n",
        "                            max_display=max_display, show=False)\n",
        "            plt.title(f'SHAP Summary Plot - {model_name}')\n",
        "            plt.show()\n",
        "\n",
        "            return shap_values\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate SHAP explanations for {model_name}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def setup_lime_explainer(self, X_train):\n",
        "        \"\"\"Setup LIME explainer\"\"\"\n",
        "        if not INTERPRETABILITY_AVAILABLE:\n",
        "            print(\"LIME not available. Install lime package for interpretability.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "                X_train,\n",
        "                feature_names=self.feature_names[:X_train.shape[1]],\n",
        "                class_names=['No Claim', 'Claim'],\n",
        "                mode='classification'\n",
        "            )\n",
        "            return explainer\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to create LIME explainer: {e}\")\n",
        "            return None\n",
        "\n",
        "    def explain_instance_lime(self, lime_explainer, instance, model, model_name):\n",
        "        \"\"\"Explain single instance using LIME\"\"\"\n",
        "        if lime_explainer is None:\n",
        "            print(\"LIME explainer not available\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                explanation = lime_explainer.explain_instance(\n",
        "                    instance, model.predict_proba, num_features=10\n",
        "                )\n",
        "            else:\n",
        "                explanation = lime_explainer.explain_instance(\n",
        "                    instance, lambda x: np.column_stack([1-model.predict(x), model.predict(x)]),\n",
        "                    num_features=10\n",
        "                )\n",
        "\n",
        "            explanation.show_in_notebook(show_table=True)\n",
        "            return explanation\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate LIME explanation: {e}\")\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "m6mm6UeafMBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SHAP lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSkwCDwvgwDc",
        "outputId": "eeae9b43-835c-44a3-9999-512cbcc7f93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SHAP in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from SHAP) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from SHAP) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from SHAP) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from SHAP) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from SHAP) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from SHAP) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from SHAP) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from SHAP) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from SHAP) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SHAP) (4.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->SHAP) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->SHAP) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->SHAP) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->SHAP) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->SHAP) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=ff1233600d19bce6347033aca6f4449a36db4d4f4cc5a1bb814b6b217b06981a\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 12: MAIN DUAL-PATH FRAMEWORK CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class DualPathFramework:\n",
        "    \"\"\"\n",
        "    Main class implementing the complete dual-path machine learning framework\n",
        "    with all enhancements and innovations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.config = config or self._get_default_config()\n",
        "        self.preprocessor = None\n",
        "        self.imbalance_handler = None\n",
        "        self.feature_selector = None\n",
        "        self.gb_model = None\n",
        "        self.nn_model = None\n",
        "        self.ensemble = None\n",
        "        self.threshold_optimizer = None\n",
        "        self.evaluator = None\n",
        "        self.interpretability_suite = None\n",
        "        self.results = {}\n",
        "\n",
        "    def _get_default_config(self):\n",
        "        \"\"\"Default configuration for the framework\"\"\"\n",
        "        return {\n",
        "            'preprocessing': {\n",
        "                'scaling_method': 'standard',\n",
        "                'handle_outliers': True,\n",
        "                'create_interactions': True\n",
        "            },\n",
        "            'imbalance_handling': {\n",
        "                'method': 'smote_tomek',\n",
        "                'random_state': 42\n",
        "            },\n",
        "            'feature_selection': {\n",
        "                'n_features': 20,\n",
        "                'methods': ['mutual_info', 'rfe', 'permutation']\n",
        "            },\n",
        "            'models': {\n",
        "                'gb_optimization': {\n",
        "                    'cv_folds': 5,\n",
        "                    'n_iter': 30\n",
        "                },\n",
        "                'nn_config': {\n",
        "                    'include_xlstm': True,\n",
        "                    'epochs': 100,\n",
        "                    'batch_size': 32\n",
        "                }\n",
        "            },\n",
        "            'ensemble': {\n",
        "                'weight_method': 'auc'\n",
        "            },\n",
        "            'threshold_optimization': {\n",
        "                'metric': 'f1'\n",
        "            },\n",
        "            'interpretability': {\n",
        "                'enable_shap': True,\n",
        "                'enable_lime': True,\n",
        "                'background_sample_size': 100\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def load_and_preprocess_data(self, file_path):\n",
        "        \"\"\"Load and preprocess the telematics dataset\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # Load data\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "        # Create target variable\n",
        "        df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "\n",
        "        # Remove original claim columns\n",
        "        df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "        # Separate features and target\n",
        "        X = df.drop('ClaimYN', axis=1)\n",
        "        y = df['ClaimYN']\n",
        "\n",
        "        print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
        "        print(f\"Class imbalance ratio: {y.value_counts()[0] / y.value_counts()[1]:.2f}\")\n",
        "\n",
        "        # Initialize and apply preprocessing\n",
        "        self.preprocessor = EnhancedDataPreprocessor(\n",
        "            scaling_method=self.config['preprocessing']['scaling_method'],\n",
        "            handle_outliers=self.config['preprocessing']['handle_outliers']\n",
        "        )\n",
        "\n",
        "        X_processed, y_processed = self.preprocessor.fit_transform(X, y)\n",
        "\n",
        "        print(f\"Processed dataset shape: {X_processed.shape}\")\n",
        "        print(f\"Added {X_processed.shape[1] - X.shape[1]} new features\")\n",
        "\n",
        "        return X_processed, y_processed\n",
        "\n",
        "    def split_data(self, X, y, test_size=0.15, val_size=0.15):\n",
        "        \"\"\"Split data into train, validation, and test sets\"\"\"\n",
        "        # First split: separate test set\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Second split: separate train and validation from remaining data\n",
        "        val_size_adjusted = val_size / (1 - test_size)  # Adjust val_size for remaining data\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def handle_class_imbalance(self, X_train, y_train):\n",
        "        \"\"\"Apply class imbalance handling techniques\"\"\"\n",
        "        print(\"Handling class imbalance...\")\n",
        "\n",
        "        self.imbalance_handler = AdvancedImbalanceHandler(\n",
        "            method=self.config['imbalance_handling']['method'],\n",
        "            random_state=self.config['imbalance_handling']['random_state']\n",
        "        )\n",
        "\n",
        "        X_resampled, y_resampled = self.imbalance_handler.fit_resample(X_train, y_train)\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def select_features(self, X_train, y_train):\n",
        "        \"\"\"Perform advanced feature selection\"\"\"\n",
        "        print(\"Performing feature selection...\")\n",
        "\n",
        "        self.feature_selector = EnhancedFeatureSelector(\n",
        "            n_features=self.config['feature_selection']['n_features'],\n",
        "            methods=self.config['feature_selection']['methods']\n",
        "        )\n",
        "\n",
        "        selected_features, feature_scores = self.feature_selector.ensemble_selection(X_train, y_train)\n",
        "\n",
        "        print(f\"Selected {len(selected_features)} features:\")\n",
        "        for i, feature in enumerate(selected_features[:10]):  # Show top 10\n",
        "            print(f\"  {i+1}. {feature}\")\n",
        "\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def train_gradient_boosting(self, X_train, y_train):\n",
        "        \"\"\"Train enhanced gradient boosting model\"\"\"\n",
        "        print(\"Training Gradient Boosting model...\")\n",
        "\n",
        "        self.gb_model = EnhancedGradientBoosting()\n",
        "        gb_trained = self.gb_model.optimize_hyperparameters(\n",
        "            X_train, y_train,\n",
        "            cv_folds=self.config['models']['gb_optimization']['cv_folds'],\n",
        "            n_iter=self.config['models']['gb_optimization']['n_iter']\n",
        "        )\n",
        "\n",
        "        return gb_trained\n",
        "\n",
        "    def train_neural_network(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Train enhanced neural network with xLSTM\"\"\"\n",
        "        print(\"Training Neural Network with xLSTM...\")\n",
        "\n",
        "        self.nn_model = EnhancedNeuralNetwork(\n",
        "            include_xlstm=self.config['models']['nn_config']['include_xlstm']\n",
        "        )\n",
        "\n",
        "        # Create model\n",
        "        if self.config['models']['nn_config']['include_xlstm']:\n",
        "            try:\n",
        "                # Prepare sequential features for xLSTM\n",
        "                sequential_features = ['Annual.pct.driven', 'Total.miles.driven', 'Avgdays.week']\n",
        "                seq_indices = [i for i, col in enumerate(X_train.columns) if any(seq_feat in col for seq_feat in sequential_features)]\n",
        "\n",
        "                if len(seq_indices) >= 3:\n",
        "                    X_train_seq = X_train.iloc[:, seq_indices[:3]].values.reshape(-1, 3, 1)\n",
        "                    X_val_seq = X_val.iloc[:, seq_indices[:3]].values.reshape(-1, 3, 1)\n",
        "\n",
        "                    model = self.nn_model.create_xlstm_enhanced_model(X_train.shape[1])\n",
        "\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, [X_train.values, X_train_seq], y_train,\n",
        "                        [X_val.values, X_val_seq], y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "\n",
        "                    # Store sequential indices for prediction\n",
        "                    self.nn_model.seq_indices = seq_indices[:3]\n",
        "                else:\n",
        "                    print(\"Insufficient sequential features for xLSTM. Using standard MLP.\")\n",
        "                    model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, X_train.values, y_train, X_val.values, y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(f\"xLSTM failed with error: {e}\")\n",
        "                print(\"Falling back to standard MLP...\")\n",
        "                model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                trained_model, history = self.nn_model.compile_and_train(\n",
        "                    model, X_train.values, y_train, X_val.values, y_val,\n",
        "                    epochs=self.config['models']['nn_config']['epochs'],\n",
        "                    batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                )\n",
        "        else:\n",
        "            model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "            trained_model, history = self.nn_model.compile_and_train(\n",
        "                model, X_train.values, y_train, X_val.values, y_val,\n",
        "                epochs=self.config['models']['nn_config']['epochs'],\n",
        "                batch_size=self.config['models']['nn_config']['batch_size']\n",
        "            )\n",
        "\n",
        "        return trained_model, history\n",
        "\n",
        "    def create_ensemble(self, X_val, y_val):\n",
        "        \"\"\"Create weighted ensemble of trained models\"\"\"\n",
        "        print(\"Creating weighted ensemble...\")\n",
        "\n",
        "        # Neural Network wrapper to handle different input formats\n",
        "        class NNWrapper:\n",
        "            def __init__(self, nn_model, has_seq=False, seq_indices=None):\n",
        "                self.model = nn_model\n",
        "                self.has_seq = has_seq\n",
        "                self.seq_indices = seq_indices\n",
        "\n",
        "            def predict_proba(self, X):\n",
        "                if self.has_seq and self.seq_indices is not None:\n",
        "                    X_seq = X.iloc[:, self.seq_indices].values.reshape(-1, len(self.seq_indices), 1)\n",
        "                    pred = self.model.predict([X.values, X_seq])\n",
        "                    return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "                else:\n",
        "                    pred = self.model.predict(X.values)\n",
        "                    return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "\n",
        "            def predict(self, X):\n",
        "                proba = self.predict_proba(X)\n",
        "                return (proba[:, 1] > 0.5).astype(int)\n",
        "\n",
        "        # Check if neural network has sequential features\n",
        "        has_seq = hasattr(self.nn_model, 'seq_indices') and self.nn_model.seq_indices is not None\n",
        "        seq_indices = getattr(self.nn_model, 'seq_indices', None)\n",
        "\n",
        "        models_dict = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': NNWrapper(self.nn_model.model, has_seq, seq_indices)\n",
        "        }\n",
        "\n",
        "        self.ensemble = WeightedEnsemble(\n",
        "            models_dict,\n",
        "            weight_method=self.config['ensemble']['weight_method']\n",
        "        )\n",
        "\n",
        "        # Calculate ensemble weights\n",
        "        weights = self.ensemble.calculate_weights(X_val, y_val)\n",
        "\n",
        "        return self.ensemble\n",
        "\n",
        "    def optimize_threshold(self, X_val, y_val):\n",
        "        \"\"\"Optimize classification threshold\"\"\"\n",
        "        print(\"Optimizing classification threshold...\")\n",
        "\n",
        "        self.threshold_optimizer = ThresholdOptimizer(\n",
        "            metric=self.config['threshold_optimization']['metric']\n",
        "        )\n",
        "\n",
        "        # Get ensemble predictions\n",
        "        y_pred_proba = self.ensemble.predict_proba(X_val)\n",
        "\n",
        "        optimal_threshold = self.threshold_optimizer.optimize(y_val, y_pred_proba)\n",
        "\n",
        "        return optimal_threshold\n",
        "\n",
        "    def comprehensive_evaluation(self, X_test, y_test):\n",
        "        \"\"\"Perform comprehensive model evaluation\"\"\"\n",
        "        print(\"Performing comprehensive evaluation...\")\n",
        "\n",
        "        self.evaluator = ComprehensiveEvaluator()\n",
        "\n",
        "        # Evaluate individual models and ensemble\n",
        "        models_to_evaluate = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': self.ensemble.models['Neural Network'],  # Use wrapper\n",
        "            'Ensemble': self.ensemble\n",
        "        }\n",
        "\n",
        "        y_pred_proba_dict = {}\n",
        "\n",
        "        for model_name, model in models_to_evaluate.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred_proba = model.predict_proba(X_test)\n",
        "                if y_pred_proba.ndim > 1:\n",
        "                    y_pred_proba = y_pred_proba[:, 1] if y_pred_proba.shape[1] > 1 else y_pred_proba.flatten()\n",
        "            else:\n",
        "                y_pred_proba = model.predict(X_test)\n",
        "\n",
        "            y_pred_proba_dict[model_name] = y_pred_proba\n",
        "\n",
        "            # Get binary predictions using optimal threshold\n",
        "            if hasattr(self.threshold_optimizer, 'optimal_threshold'):\n",
        "                y_pred = (y_pred_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "            else:\n",
        "                y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = self.evaluator.calculate_all_metrics(y_test, y_pred, y_pred_proba, model_name)\n",
        "            self.results[model_name] = metrics\n",
        "\n",
        "        # Create comprehensive plots\n",
        "        self.evaluator.plot_comprehensive_evaluation(y_test, y_pred_proba_dict)\n",
        "\n",
        "        # Print results table\n",
        "        self.evaluator.print_results_table()\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def setup_interpretability(self, X_train, X_test):\n",
        "        \"\"\"Setup model interpretability suite\"\"\"\n",
        "        if not self.config['interpretability']['enable_shap'] and not self.config['interpretability']['enable_lime']:\n",
        "            print(\"Interpretability disabled in config\")\n",
        "            return\n",
        "\n",
        "        print(\"Setting up interpretability suite...\")\n",
        "\n",
        "        models_for_interpretation = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Ensemble': self.ensemble\n",
        "        }\n",
        "\n",
        "        self.interpretability_suite = InterpretabilitySuite(\n",
        "            models_for_interpretation,\n",
        "            X_train.columns.tolist()\n",
        "        )\n",
        "\n",
        "        if self.config['interpretability']['enable_shap']:\n",
        "            self.interpretability_suite.setup_shap_explainers(\n",
        "                X_train,\n",
        "                sample_size=self.config['interpretability']['background_sample_size']\n",
        "            )\n",
        "\n",
        "        # Generate explanations for test set sample\n",
        "        if len(X_test) > 10:\n",
        "            X_explain = X_test.iloc[:10]  # Explain first 10 test samples\n",
        "        else:\n",
        "            X_explain = X_test\n",
        "\n",
        "        for model_name in models_for_interpretation.keys():\n",
        "            self.interpretability_suite.explain_predictions(X_explain, model_name)\n",
        "\n",
        "    def save_models(self, save_path='models/'):\n",
        "        \"\"\"Save trained models and preprocessors\"\"\"\n",
        "        import os\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        # Save preprocessor\n",
        "        joblib.dump(self.preprocessor, os.path.join(save_path, 'preprocessor.pkl'))\n",
        "\n",
        "        # Save feature selector\n",
        "        joblib.dump(self.feature_selector, os.path.join(save_path, 'feature_selector.pkl'))\n",
        "\n",
        "        # Save gradient boosting model\n",
        "        if self.gb_model and self.gb_model.model:\n",
        "            joblib.dump(self.gb_model.model, os.path.join(save_path, 'gradient_boosting_model.pkl'))\n",
        "\n",
        "        # Save neural network model\n",
        "        if self.nn_model and self.nn_model.model:\n",
        "            self.nn_model.model.save(os.path.join(save_path, 'neural_network_model.h5'))\n",
        "\n",
        "        # Save ensemble\n",
        "        joblib.dump(self.ensemble, os.path.join(save_path, 'ensemble.pkl'))\n",
        "\n",
        "        # Save threshold optimizer\n",
        "        joblib.dump(self.threshold_optimizer, os.path.join(save_path, 'threshold_optimizer.pkl'))\n",
        "\n",
        "        # Save results\n",
        "        joblib.dump(self.results, os.path.join(save_path, 'results.pkl'))\n",
        "\n",
        "        print(f\"Models saved to {save_path}\")\n",
        "\n",
        "    def load_models(self, load_path='models/'):\n",
        "        \"\"\"Load previously trained models\"\"\"\n",
        "        import os\n",
        "\n",
        "        # Load preprocessor\n",
        "        preprocessor_path = os.path.join(load_path, 'preprocessor.pkl')\n",
        "        if os.path.exists(preprocessor_path):\n",
        "            self.preprocessor = joblib.load(preprocessor_path)\n",
        "\n",
        "        # Load feature selector\n",
        "        feature_selector_path = os.path.join(load_path, 'feature_selector.pkl')\n",
        "        if os.path.exists(feature_selector_path):\n",
        "            self.feature_selector = joblib.load(feature_selector_path)\n",
        "\n",
        "        # Load gradient boosting model\n",
        "        gb_model_path = os.path.join(load_path, 'gradient_boosting_model.pkl')\n",
        "        if os.path.exists(gb_model_path):\n",
        "            self.gb_model = EnhancedGradientBoosting()\n",
        "            self.gb_model.model = joblib.load(gb_model_path)\n",
        "\n",
        "        # Load neural network model\n",
        "        nn_model_path = os.path.join(load_path, 'neural_network_model.h5')\n",
        "        if os.path.exists(nn_model_path):\n",
        "            self.nn_model = EnhancedNeuralNetwork()\n",
        "            self.nn_model.model = keras.models.load_model(nn_model_path, custom_objects={\n",
        "                'xLSTMCell': xLSTMCell,\n",
        "                'xLSTMLayer': xLSTMLayer\n",
        "            })\n",
        "\n",
        "        # Load ensemble\n",
        "        ensemble_path = os.path.join(load_path, 'ensemble.pkl')\n",
        "        if os.path.exists(ensemble_path):\n",
        "            self.ensemble = joblib.load(ensemble_path)\n",
        "\n",
        "        # Load threshold optimizer\n",
        "        threshold_path = os.path.join(load_path, 'threshold_optimizer.pkl')\n",
        "        if os.path.exists(threshold_path):\n",
        "            self.threshold_optimizer = joblib.load(threshold_path)\n",
        "\n",
        "        # Load results\n",
        "        results_path = os.path.join(load_path, 'results.pkl')\n",
        "        if os.path.exists(results_path):\n",
        "            self.results = joblib.load(results_path)\n",
        "\n",
        "        print(f\"Models loaded from {load_path}\")\n",
        "\n",
        "    def run_complete_pipeline(self, file_path, save_models=True):\n",
        "        \"\"\"\n",
        "        Run the complete dual-path machine learning pipeline\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the telematics dataset\n",
        "            save_models (bool): Whether to save trained models\n",
        "\n",
        "        Returns:\n",
        "            dict: Complete results from the pipeline\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        print(\"=\"*80)\n",
        "        print(\"STARTING DUAL-PATH MACHINE LEARNING FRAMEWORK\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Load and preprocess data\n",
        "            X, y = self.load_and_preprocess_data(file_path)\n",
        "\n",
        "            # Step 2: Split data\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)\n",
        "\n",
        "            # Step 3: Handle class imbalance\n",
        "            X_train_balanced, y_train_balanced = self.handle_class_imbalance(X_train, y_train)\n",
        "\n",
        "            # Step 4: Feature selection\n",
        "            selected_features, feature_scores = self.select_features(X_train_balanced, y_train_balanced)\n",
        "\n",
        "            # Apply feature selection to all datasets\n",
        "            X_train_selected = X_train_balanced[selected_features]\n",
        "            X_val_selected = X_val[selected_features]\n",
        "            X_test_selected = X_test[selected_features]\n",
        "\n",
        "            # Step 5: Train Gradient Boosting model\n",
        "            gb_model = self.train_gradient_boosting(X_train_selected, y_train_balanced)\n",
        "\n",
        "            # Step 6: Train Neural Network model\n",
        "            nn_model, nn_history = self.train_neural_network(\n",
        "                X_train_selected, y_train_balanced, X_val_selected, y_val\n",
        "            )\n",
        "\n",
        "            # Step 7: Create ensemble\n",
        "            ensemble = self.create_ensemble(X_val_selected, y_val)\n",
        "\n",
        "            # Step 8: Optimize threshold\n",
        "            optimal_threshold = self.optimize_threshold(X_val_selected, y_val)\n",
        "\n",
        "            # Step 9: Comprehensive evaluation\n",
        "            evaluation_results = self.comprehensive_evaluation(X_test_selected, y_test)\n",
        "\n",
        "            # Step 10: Setup interpretability\n",
        "            self.setup_interpretability(X_train_selected, X_test_selected)\n",
        "\n",
        "            # Step 11: Save models if requested\n",
        "            if save_models:\n",
        "                self.save_models()\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_time = end_time - start_time\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"DUAL-PATH FRAMEWORK COMPLETED SUCCESSFULLY\")\n",
        "            print(\"=\"*80)\n",
        "            print(f\"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
        "            print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
        "            print(\"\\nBest performing model based on test set:\")\n",
        "\n",
        "            # Find best model based on F1 score\n",
        "            best_model = max(evaluation_results.keys(), key=lambda x: evaluation_results[x]['f1'])\n",
        "            best_f1 = evaluation_results[best_model]['f1']\n",
        "            best_auc = evaluation_results[best_model]['auc_roc']\n",
        "\n",
        "            print(f\"  {best_model}: F1={best_f1:.4f}, AUC={best_auc:.4f}\")\n",
        "\n",
        "            # Summary of results\n",
        "            pipeline_summary = {\n",
        "                'execution_time': total_time,\n",
        "                'optimal_threshold': optimal_threshold,\n",
        "                'best_model': best_model,\n",
        "                'best_f1_score': best_f1,\n",
        "                'best_auc_score': best_auc,\n",
        "                'selected_features': selected_features,\n",
        "                'feature_scores': feature_scores,\n",
        "                'model_results': evaluation_results,\n",
        "                'data_stats': {\n",
        "                    'original_shape': X.shape,\n",
        "                    'train_size': len(X_train_selected),\n",
        "                    'val_size': len(X_val_selected),\n",
        "                    'test_size': len(X_test_selected),\n",
        "                    'class_distribution': y.value_counts().to_dict()\n",
        "                }\n",
        "            }\n",
        "\n",
        "            return pipeline_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Pipeline failed with error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def predict_new_data(self, new_data_path):\n",
        "        \"\"\"\n",
        "        Make predictions on new data using trained models\n",
        "\n",
        "        Args:\n",
        "            new_data_path (str): Path to new data file\n",
        "\n",
        "        Returns:\n",
        "            dict: Predictions from all models\n",
        "        \"\"\"\n",
        "        if self.ensemble is None:\n",
        "            raise ValueError(\"Models not trained yet. Run the pipeline first.\")\n",
        "\n",
        "        print(\"Making predictions on new data...\")\n",
        "\n",
        "        # Load and preprocess new data\n",
        "        new_df = pd.read_csv(new_data_path)\n",
        "        new_X_processed = self.preprocessor.transform(new_df)\n",
        "\n",
        "        # Apply feature selection\n",
        "        if self.feature_selector and self.feature_selector.selected_features:\n",
        "            new_X_selected = new_X_processed[self.feature_selector.selected_features]\n",
        "        else:\n",
        "            new_X_selected = new_X_processed\n",
        "\n",
        "        # Get predictions from all models\n",
        "        predictions = {}\n",
        "\n",
        "        # Gradient Boosting predictions\n",
        "        gb_proba = self.gb_model.model.predict_proba(new_X_selected)[:, 1]\n",
        "        gb_pred = (gb_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "        predictions['gradient_boosting'] = {\n",
        "            'probabilities': gb_proba,\n",
        "            'predictions': gb_pred\n",
        "        }\n",
        "\n",
        "        # Neural Network predictions\n",
        "        nn_wrapper = self.ensemble.models['Neural Network']\n",
        "        nn_proba = nn_wrapper.predict_proba(new_X_selected)[:, 1]\n",
        "        nn_pred = (nn_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "        predictions['neural_network'] = {\n",
        "            'probabilities': nn_proba,\n",
        "            'predictions': nn_pred\n",
        "        }\n",
        "\n",
        "        # Ensemble predictions\n",
        "        ensemble_proba = self.ensemble.predict_proba(new_X_selected)\n",
        "        ensemble_pred = (ensemble_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "        predictions['ensemble'] = {\n",
        "            'probabilities': ensemble_proba,\n",
        "            'predictions': ensemble_pred\n",
        "        }\n",
        "\n",
        "        print(f\"Generated predictions for {len(new_X_selected)} samples\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# Example usage and pipeline execution function\n",
        "def run_driver_risk_assessment_pipeline(data_path, config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to run the complete driver risk assessment pipeline\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the telematics dataset\n",
        "        config (dict): Optional configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        tuple: (framework_instance, results_summary)\n",
        "    \"\"\"\n",
        "    # Initialize framework\n",
        "    framework = DualPathFramework(config)\n",
        "\n",
        "    # Run complete pipeline\n",
        "    results = framework.run_complete_pipeline(data_path)\n",
        "\n",
        "    return framework, results\n",
        "\n",
        "# Example usage with your dataset\n",
        "if __name__ == \"__main__\":\n",
        "    # Your dataset path\n",
        "    DATA_PATH = '/content/drive/MyDrive/Insurance/telematics_syn.csv'\n",
        "\n",
        "    # Run the complete pipeline\n",
        "    framework, results = run_driver_risk_assessment_pipeline(DATA_PATH)\n",
        "\n",
        "    if results is not None:\n",
        "        print(\"Pipeline completed successfully!\")\n",
        "        print(f\"Best model: {results['best_model']}\")\n",
        "        print(f\"Best F1 Score: {results['best_f1_score']:.4f}\")\n",
        "        print(f\"Best AUC Score: {results['best_auc_score']:.4f}\")\n",
        "    else:\n",
        "        print(\"Pipeline failed. Check the error messages above.\")"
      ],
      "metadata": {
        "id": "W7Dm9tkhhl45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Dual-Path Machine Learning Framework for Driver Risk Assessment\n",
        "# Fixed Implementation with Error Handling and Improvements\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, RandomizedSearchCV, cross_val_score,\n",
        "    StratifiedKFold, learning_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import (\n",
        "    mutual_info_classif, SelectKBest, RFE, VarianceThreshold\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
        "    roc_curve, precision_recall_curve, average_precision_score,\n",
        "    classification_report, log_loss\n",
        ")\n",
        "from sklearn.inspection import permutation_importance, partial_dependence\n",
        "\n",
        "# Class Imbalance Handling\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, BatchNormalization, LSTM,\n",
        "    GRU, Attention, MultiHeadAttention, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =============================================================================\n",
        "# FIXED: Enhanced LSTM Implementation (Simplified)\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedLSTMModel:\n",
        "    \"\"\"\n",
        "    Simplified LSTM model for sequential feature processing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "\n",
        "    def create_lstm_enhanced_model(self, input_dim, sequence_length=5):\n",
        "        \"\"\"Create LSTM-enhanced model\"\"\"\n",
        "        # Main features input\n",
        "        main_input = Input(shape=(input_dim,), name='main_input')\n",
        "\n",
        "        # Sequential features input (reshape for LSTM)\n",
        "        seq_input = Input(shape=(sequence_length, 1), name='seq_input')\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out = LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(seq_input)\n",
        "        lstm_dense = Dense(32, activation='relu')(lstm_out)\n",
        "        lstm_dense = Dropout(0.3)(lstm_dense)\n",
        "\n",
        "        # Combine features\n",
        "        combined = keras.layers.concatenate([main_input, lstm_dense])\n",
        "\n",
        "        # Dense layers\n",
        "        x = Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "\n",
        "        x = Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=[main_input, seq_input], outputs=outputs)\n",
        "        return model\n",
        "\n",
        "# =============================================================================\n",
        "# FIXED: Comprehensive Data Preprocessor\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedDataPreprocessor:\n",
        "    \"\"\"\n",
        "    Fixed data preprocessing with proper data type handling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scaling_method='standard', handle_outliers=True):\n",
        "        self.scaling_method = scaling_method\n",
        "        self.handle_outliers = handle_outliers\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.categorical_features = []\n",
        "        self.numerical_features = []\n",
        "\n",
        "    def detect_feature_types(self, df):\n",
        "        \"\"\"Automatically detect categorical and numerical features\"\"\"\n",
        "        categorical = []\n",
        "        numerical = []\n",
        "\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
        "                # Check if it's actually numeric stored as object\n",
        "                try:\n",
        "                    pd.to_numeric(df[col].dropna())\n",
        "                    numerical.append(col)\n",
        "                except:\n",
        "                    categorical.append(col)\n",
        "            else:\n",
        "                numerical.append(col)\n",
        "\n",
        "        return categorical, numerical\n",
        "\n",
        "    def handle_missing_values(self, df):\n",
        "        \"\"\"Advanced missing value handling\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Handle negative Car.age values as missing\n",
        "        if 'Car.age' in df.columns:\n",
        "            df.loc[df['Car.age'] < 0, 'Car.age'] = np.nan\n",
        "            df['Car.age'].fillna(df['Car.age'].median(), inplace=True)\n",
        "\n",
        "        # Fill other missing values\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
        "                    df[col].fillna(df[col].mode().iloc[0] if len(df[col].mode()) > 0 else 'Unknown', inplace=True)\n",
        "                else:\n",
        "                    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def clean_data_types(self, df):\n",
        "        \"\"\"Ensure proper data types\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype == 'object':\n",
        "                # Try to convert to numeric\n",
        "                try:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "                    # Fill any new NaNs created from conversion\n",
        "                    if df[col].isnull().sum() > 0:\n",
        "                        df[col].fillna(df[col].median(), inplace=True)\n",
        "                except:\n",
        "                    # Keep as categorical\n",
        "                    pass\n",
        "\n",
        "        return df\n",
        "\n",
        "    def remove_outliers(self, df, method='iqr', threshold=3):\n",
        "        \"\"\"Remove outliers using IQR or Z-score method\"\"\"\n",
        "        if not self.handle_outliers:\n",
        "            return df\n",
        "\n",
        "        df = df.copy()\n",
        "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        if method == 'iqr':\n",
        "            for col in numerical_cols:\n",
        "                Q1 = df[col].quantile(0.25)\n",
        "                Q3 = df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "                outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
        "                # Cap outliers instead of removing them\n",
        "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
        "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_interaction_features(self, df):\n",
        "        \"\"\"Create interaction features for behavioral metrics\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Acceleration-Brake intensity combinations\n",
        "        accel_cols = [col for col in df.columns if 'Accel' in col and df[col].dtype in ['float64', 'int64']]\n",
        "        brake_cols = [col for col in df.columns if 'Brake' in col and df[col].dtype in ['float64', 'int64']]\n",
        "\n",
        "        for accel_col in accel_cols[:3]:  # Limit to avoid feature explosion\n",
        "            for brake_col in brake_cols[:3]:\n",
        "                if accel_col.split('.')[-1] == brake_col.split('.')[-1]:  # Same mile threshold\n",
        "                    new_col = f'{accel_col}_x_{brake_col}'\n",
        "                    df[new_col] = df[accel_col] * df[brake_col]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        \"\"\"Fit preprocessor and transform data\"\"\"\n",
        "        df = X.copy()\n",
        "\n",
        "        # Store original feature names\n",
        "        self.feature_names = df.columns.tolist()\n",
        "\n",
        "        # Clean data types first\n",
        "        df = self.clean_data_types(df)\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Detect feature types after cleaning\n",
        "        self.categorical_features, self.numerical_features = self.detect_feature_types(df)\n",
        "\n",
        "        # Remove outliers\n",
        "        if y is not None:\n",
        "            original_len = len(df)\n",
        "            df = self.remove_outliers(df)\n",
        "            if len(df) < original_len:\n",
        "                # Filter y to match filtered df if indices changed\n",
        "                try:\n",
        "                    y = y.loc[df.index] if hasattr(y, 'loc') else y[df.index.tolist()]\n",
        "                except:\n",
        "                    print(\"Warning: Could not filter y after outlier removal\")\n",
        "\n",
        "        # Create interaction features (limited)\n",
        "        try:\n",
        "            df = self.create_interaction_features(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not create interaction features: {e}\")\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            try:\n",
        "                df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not encode categorical features: {e}\")\n",
        "\n",
        "        # Update numerical features after transformations\n",
        "        self.numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Apply scaling\n",
        "        if self.scaling_method == 'standard':\n",
        "            scaler = StandardScaler()\n",
        "        elif self.scaling_method == 'robust':\n",
        "            scaler = RobustScaler()\n",
        "        elif self.scaling_method == 'minmax':\n",
        "            scaler = MinMaxScaler()\n",
        "        else:\n",
        "            scaler = StandardScaler()\n",
        "\n",
        "        # Ensure all columns are numeric before scaling\n",
        "        for col in self.numerical_features:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "                df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "        df[self.numerical_features] = scaler.fit_transform(df[self.numerical_features])\n",
        "        self.scalers['numerical'] = scaler\n",
        "\n",
        "        return df, y\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted preprocessor\"\"\"\n",
        "        df = X.copy()\n",
        "\n",
        "        # Clean data types\n",
        "        df = self.clean_data_types(df)\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Create interaction features\n",
        "        try:\n",
        "            df = self.create_interaction_features(df)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            try:\n",
        "                df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Ensure all required columns are present\n",
        "        for col in self.numerical_features:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "\n",
        "        # Select only the columns that were in training\n",
        "        df = df.reindex(columns=self.numerical_features, fill_value=0)\n",
        "\n",
        "        # Apply scaling\n",
        "        if 'numerical' in self.scalers:\n",
        "            df[self.numerical_features] = self.scalers['numerical'].transform(df[self.numerical_features])\n",
        "\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# Enhanced Feature Selector (Simplified)\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedFeatureSelector:\n",
        "    \"\"\"\n",
        "    Multi-method feature selection with ensemble approach\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_features=20, methods=['mutual_info', 'rfe']):\n",
        "        self.n_features = n_features\n",
        "        self.methods = methods\n",
        "        self.selected_features = None\n",
        "        self.feature_scores = {}\n",
        "\n",
        "    def mutual_info_selection(self, X, y):\n",
        "        \"\"\"Feature selection using mutual information\"\"\"\n",
        "        try:\n",
        "            mi_scores = mutual_info_classif(X, y, random_state=42)\n",
        "            feature_scores = dict(zip(X.columns, mi_scores))\n",
        "            top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "        except Exception as e:\n",
        "            print(f\"Mutual info selection failed: {e}\")\n",
        "            return X.columns.tolist()[:self.n_features], {}\n",
        "\n",
        "    def rfe_selection(self, X, y):\n",
        "        \"\"\"Recursive Feature Elimination\"\"\"\n",
        "        try:\n",
        "            estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "            selector = RFE(estimator, n_features_to_select=min(self.n_features, X.shape[1]))\n",
        "            selector.fit(X, y)\n",
        "\n",
        "            feature_scores = dict(zip(X.columns, selector.ranking_))\n",
        "            selected_features = X.columns[selector.support_].tolist()\n",
        "            return selected_features, feature_scores\n",
        "        except Exception as e:\n",
        "            print(f\"RFE selection failed: {e}\")\n",
        "            return X.columns.tolist()[:self.n_features], {}\n",
        "\n",
        "    def ensemble_selection(self, X, y):\n",
        "        \"\"\"Ensemble feature selection combining multiple methods\"\"\"\n",
        "        all_selected_features = []\n",
        "        method_scores = {}\n",
        "\n",
        "        if 'mutual_info' in self.methods:\n",
        "            features, scores = self.mutual_info_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['mutual_info'] = scores\n",
        "\n",
        "        if 'rfe' in self.methods:\n",
        "            features, scores = self.rfe_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['rfe'] = scores\n",
        "\n",
        "        if not all_selected_features:\n",
        "            # Fallback: use all features up to n_features\n",
        "            self.selected_features = X.columns.tolist()[:self.n_features]\n",
        "        else:\n",
        "            # Count feature frequency across methods\n",
        "            feature_counts = defaultdict(int)\n",
        "            for feature in all_selected_features:\n",
        "                feature_counts[feature] += 1\n",
        "\n",
        "            # Select features that appear in multiple methods\n",
        "            ensemble_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "            self.selected_features = [feat[0] for feat in ensemble_features[:self.n_features]]\n",
        "\n",
        "        self.feature_scores = method_scores\n",
        "        return self.selected_features, method_scores\n",
        "\n",
        "# =============================================================================\n",
        "# Enhanced Neural Network (Fixed)\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedNeuralNetwork:\n",
        "    \"\"\"Enhanced Neural Network with LSTM integration\"\"\"\n",
        "\n",
        "    def __init__(self, include_lstm=True):\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.include_lstm = include_lstm\n",
        "        self.lstm_model = EnhancedLSTMModel()\n",
        "\n",
        "    def create_mlp_model(self, input_dim, hidden_layers=[128, 64, 32]):\n",
        "        \"\"\"Create Multi-Layer Perceptron model\"\"\"\n",
        "        inputs = Input(shape=(input_dim,))\n",
        "        x = inputs\n",
        "\n",
        "        for i, units in enumerate(hidden_layers):\n",
        "            x = Dense(units, activation='relu',\n",
        "                     kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(0.3)(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def prepare_lstm_data(self, X, feature_names):\n",
        "        \"\"\"Prepare data for LSTM processing\"\"\"\n",
        "        # Select features that could be sequential\n",
        "        sequential_candidates = []\n",
        "        for col in feature_names:\n",
        "            if any(keyword in col.lower() for keyword in ['speed', 'time', 'drive', 'mile', 'pct']):\n",
        "                sequential_candidates.append(col)\n",
        "\n",
        "        # Take first 5 features as sequence\n",
        "        seq_features = sequential_candidates[:5] if len(sequential_candidates) >= 5 else feature_names[:5]\n",
        "\n",
        "        # Create sequence data\n",
        "        seq_data = X[seq_features].values.reshape(-1, len(seq_features), 1)\n",
        "\n",
        "        return seq_data, seq_features\n",
        "\n",
        "    def compile_and_train(self, model, X_train, y_train, X_val, y_val,\n",
        "                         epochs=100, batch_size=32):\n",
        "        \"\"\"Compile and train the neural network\"\"\"\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
        "        ]\n",
        "\n",
        "        # Convert to numpy arrays to avoid dtype issues\n",
        "        if isinstance(X_train, list):\n",
        "            X_train = [arr.astype(np.float32) for arr in X_train]\n",
        "            X_val = [arr.astype(np.float32) for arr in X_val]\n",
        "        else:\n",
        "            X_train = X_train.astype(np.float32)\n",
        "            X_val = X_val.astype(np.float32)\n",
        "\n",
        "        y_train = y_train.astype(np.float32)\n",
        "        y_val = y_val.astype(np.float32)\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        self.history = history\n",
        "        return model, history\n",
        "\n",
        "# =============================================================================\n",
        "# Main Framework Class (Simplified and Fixed)\n",
        "# =============================================================================\n",
        "\n",
        "class DualPathFramework:\n",
        "    \"\"\"\n",
        "    Main class implementing the dual-path machine learning framework\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.config = config or self._get_default_config()\n",
        "        self.preprocessor = None\n",
        "        self.imbalance_handler = None\n",
        "        self.feature_selector = None\n",
        "        self.gb_model = None\n",
        "        self.nn_model = None\n",
        "        self.results = {}\n",
        "\n",
        "    def _get_default_config(self):\n",
        "        \"\"\"Default configuration for the framework\"\"\"\n",
        "        return {\n",
        "            'preprocessing': {\n",
        "                'scaling_method': 'standard',\n",
        "                'handle_outliers': True\n",
        "            },\n",
        "            'imbalance_handling': {\n",
        "                'method': 'smote_tomek',\n",
        "                'random_state': 42\n",
        "            },\n",
        "            'feature_selection': {\n",
        "                'n_features': 20,\n",
        "                'methods': ['mutual_info', 'rfe']\n",
        "            },\n",
        "            'models': {\n",
        "                'gb_optimization': {\n",
        "                    'cv_folds': 3,\n",
        "                    'n_iter': 20\n",
        "                },\n",
        "                'nn_config': {\n",
        "                    'include_lstm': False,  # Simplified\n",
        "                    'epochs': 50,\n",
        "                    'batch_size': 64\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def load_and_preprocess_data(self, file_path):\n",
        "        \"\"\"Load and preprocess the telematics dataset\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # Load data\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "        # Create target variable\n",
        "        if 'NB_Claim' in df.columns and 'AMT_Claim' in df.columns:\n",
        "            df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "            df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "        elif 'ClaimYN' not in df.columns:\n",
        "            print(\"Warning: No target variable found. Creating dummy target.\")\n",
        "            df['ClaimYN'] = np.random.choice([0, 1], size=len(df), p=[0.95, 0.05])\n",
        "\n",
        "        # Separate features and target\n",
        "        X = df.drop('ClaimYN', axis=1, errors='ignore')\n",
        "        y = df['ClaimYN'] if 'ClaimYN' in df.columns else np.random.choice([0, 1], size=len(df), p=[0.95, 0.05])\n",
        "\n",
        "        print(f\"Features shape: {X.shape}\")\n",
        "        print(f\"Class distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
        "\n",
        "        # Initialize and apply preprocessing\n",
        "        self.preprocessor = EnhancedDataPreprocessor(\n",
        "            scaling_method=self.config['preprocessing']['scaling_method'],\n",
        "            handle_outliers=self.config['preprocessing']['handle_outliers']\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            X_processed, y_processed = self.preprocessor.fit_transform(X, y)\n",
        "            print(f\"Processed dataset shape: {X_processed.shape}\")\n",
        "            return X_processed, y_processed\n",
        "        except Exception as e:\n",
        "            print(f\"Preprocessing failed: {e}\")\n",
        "            # Fallback: minimal preprocessing\n",
        "            X_numeric = X.select_dtypes(include=[np.number])\n",
        "            X_numeric = X_numeric.fillna(X_numeric.median())\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = pd.DataFrame(scaler.fit_transform(X_numeric),\n",
        "                                  columns=X_numeric.columns,\n",
        "                                  index=X_numeric.index)\n",
        "            return X_scaled, y\n",
        "\n",
        "    def split_data(self, X, y, test_size=0.2, val_size=0.2):\n",
        "        \"\"\"Split data into train, validation, and test sets\"\"\"\n",
        "        # First split: separate test set\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Second split: separate train and validation\n",
        "        val_size_adjusted = val_size / (1 - test_size)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def handle_class_imbalance(self, X_train, y_train):\n",
        "        \"\"\"Apply SMOTE for class imbalance\"\"\"\n",
        "        print(\"Handling class imbalance...\")\n",
        "\n",
        "        try:\n",
        "            smote = SMOTE(random_state=42)\n",
        "            X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "            print(f\"Original class distribution: {np.bincount(y_train)}\")\n",
        "            print(f\"Resampled class distribution: {np.bincount(y_resampled)}\")\n",
        "\n",
        "            return X_resampled, y_resampled\n",
        "        except Exception as e:\n",
        "            print(f\"SMOTE failed: {e}\")\n",
        "            return X_train, y_train\n",
        "\n",
        "    def select_features(self, X_train, y_train):\n",
        "        \"\"\"Perform feature selection\"\"\"\n",
        "        print(\"Performing feature selection...\")\n",
        "\n",
        "        self.feature_selector = EnhancedFeatureSelector(\n",
        "            n_features=min(self.config['feature_selection']['n_features'], X_train.shape[1]),\n",
        "            methods=self.config['feature_selection']['methods']\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            selected_features, feature_scores = self.feature_selector.ensemble_selection(X_train, y_train)\n",
        "            print(f\"Selected {len(selected_features)} features\")\n",
        "            return selected_features, feature_scores\n",
        "        except Exception as e:\n",
        "            print(f\"Feature selection failed: {e}\")\n",
        "            # Fallback: use all features up to limit\n",
        "            n_features = min(20, X_train.shape[1])\n",
        "            selected_features = X_train.columns.tolist()[:n_features]\n",
        "            return selected_features, {}\n",
        "\n",
        "    def train_gradient_boosting(self, X_train, y_train):\n",
        "        \"\"\"Train gradient boosting model\"\"\"\n",
        "        print(\"Training Gradient Boosting model...\")\n",
        "\n",
        "        # Simple parameter grid for faster training\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.1, 0.2],\n",
        "            'max_depth': [3, 5],\n",
        "            'min_samples_split': [2, 5],\n",
        "            'subsample': [0.8, 1.0]\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "            search = RandomizedSearchCV(\n",
        "                estimator=gb_classifier,\n",
        "                param_distributions=param_grid,\n",
        "                n_iter=self.config['models']['gb_optimization']['n_iter'],\n",
        "                cv=self.config['models']['gb_optimization']['cv_folds'],\n",
        "                scoring='roc_auc',\n",
        "                n_jobs=-1,\n",
        "                random_state=42,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            search.fit(X_train, y_train)\n",
        "            self.gb_model = search.best_estimator_\n",
        "\n",
        "            print(\"Best GB Parameters:\")\n",
        "            for param, value in search.best_params_.items():\n",
        "                print(f\"  {param}: {value}\")\n",
        "            print(f\"Best CV Score: {search.best_score_:.4f}\")\n",
        "\n",
        "            return self.gb_model\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"GB training failed: {e}\")\n",
        "            # Fallback: simple GB\n",
        "            gb = GradientBoostingClassifier(random_state=42)\n",
        "            gb.fit(X_train, y_train)\n",
        "            self.gb_model = gb\n",
        "            return gb\n",
        "\n",
        "    def train_neural_network(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Train neural network\"\"\"\n",
        "        print(\"Training Neural Network...\")\n",
        "\n",
        "        self.nn_model = EnhancedNeuralNetwork(\n",
        "            include_lstm=self.config['models']['nn_config']['include_lstm']\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            if self.config['models']['nn_config']['include_lstm']:\n",
        "                # LSTM model (simplified)\n",
        "                seq_data_train, seq_features = self.nn_model.prepare_lstm_data(X_train, X_train.columns)\n",
        "                seq_data_val, _ = self.nn_model.prepare_lstm_data(X_val, X_val.columns)\n",
        "\n",
        "                model = self.nn_model.lstm_model.create_lstm_enhanced_model(X_train.shape[1], len(seq_features))\n",
        "\n",
        "                trained_model, history = self.nn_model.compile_and_train(\n",
        "                    model, [X_train.values.astype(np.float32), seq_data_train], y_train,\n",
        "                    [X_val.values.astype(np.float32), seq_data_val], y_val,\n",
        "                    epochs=self.config['models']['nn_config']['epochs'],\n",
        "                    batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                )\n",
        "\n",
        "                self.nn_model.seq_features = seq_features\n",
        "\n",
        "            else:\n",
        "                # Standard MLP\n",
        "                model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "\n",
        "                trained_model, history = self.nn_model.compile_and_train(\n",
        "                    model, X_train.values, y_train, X_val.values, y_val,\n",
        "                    epochs=self.config['models']['nn_config']['epochs'],\n",
        "                    batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                )\n",
        "\n",
        "            return trained_model, history\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"NN training failed: {e}\")\n",
        "            # Fallback: simple sklearn MLP\n",
        "            from sklearn.neural_network import MLPClassifier\n",
        "            mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=200, random_state=42)\n",
        "            mlp.fit(X_train, y_train)\n",
        "\n",
        "            # Create a wrapper to match interface\n",
        "            class MLPWrapper:\n",
        "                def __init__(self, model):\n",
        "                    self.model = model\n",
        "\n",
        "                def predict(self, X):\n",
        "                    if hasattr(X, 'values'):\n",
        "                        X = X.values\n",
        "                    return self.model.predict(X)\n",
        "\n",
        "                def predict_proba(self, X):\n",
        "                    if hasattr(X, 'values'):\n",
        "                        X = X.values\n",
        "                    return self.model.predict_proba(X)\n",
        "\n",
        "            self.nn_model.model = MLPWrapper(mlp)\n",
        "            return mlp, None\n",
        "\n",
        "    def evaluate_models(self, X_test, y_test):\n",
        "        \"\"\"Evaluate both models\"\"\"\n",
        "        print(\"Evaluating models...\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # Evaluate Gradient Boosting\n",
        "        if self.gb_model is not None:\n",
        "            try:\n",
        "                gb_pred_proba = self.gb_model.predict_proba(X_test)[:, 1]\n",
        "                gb_pred = self.gb_model.predict(X_test)\n",
        "\n",
        "                gb_metrics = {\n",
        "                    'accuracy': accuracy_score(y_test, gb_pred),\n",
        "                    'precision': precision_score(y_test, gb_pred, zero_division=0),\n",
        "                    'recall': recall_score(y_test, gb_pred, zero_division=0),\n",
        "                    'f1': f1_score(y_test, gb_pred, zero_division=0),\n",
        "                    'auc_roc': roc_auc_score(y_test, gb_pred_proba),\n",
        "                    'mcc': matthews_corrcoef(y_test, gb_pred)\n",
        "                }\n",
        "                results['Gradient Boosting'] = gb_metrics\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"GB evaluation failed: {e}\")\n",
        "\n",
        "        # Evaluate Neural Network\n",
        "        if self.nn_model is not None and self.nn_model.model is not None:\n",
        "            try:\n",
        "                if hasattr(self.nn_model, 'seq_features'):\n",
        "                    # LSTM model\n",
        "                    seq_data_test, _ = self.nn_model.prepare_lstm_data(X_test, X_test.columns)\n",
        "                    nn_pred_proba = self.nn_model.model.predict([X_test.values.astype(np.float32), seq_data_test])\n",
        "                    nn_pred_proba = nn_pred_proba.flatten()\n",
        "                else:\n",
        "                    # Standard model\n",
        "                    if hasattr(self.nn_model.model, 'predict_proba'):\n",
        "                        nn_pred_proba = self.nn_model.model.predict_proba(X_test)[:, 1]\n",
        "                    else:\n",
        "                        nn_pred_proba = self.nn_model.model.predict(X_test.values.astype(np.float32))\n",
        "                        if nn_pred_proba.ndim > 1:\n",
        "                            nn_pred_proba = nn_pred_proba.flatten()\n",
        "\n",
        "                nn_pred = (nn_pred_proba > 0.5).astype(int)\n",
        "\n",
        "                nn_metrics = {\n",
        "                    'accuracy': accuracy_score(y_test, nn_pred),\n",
        "                    'precision': precision_score(y_test, nn_pred, zero_division=0),\n",
        "                    'recall': recall_score(y_test, nn_pred, zero_division=0),\n",
        "                    'f1': f1_score(y_test, nn_pred, zero_division=0),\n",
        "                    'auc_roc': roc_auc_score(y_test, nn_pred_proba),\n",
        "                    'mcc': matthews_corrcoef(y_test, nn_pred)\n",
        "                }\n",
        "                results['Neural Network'] = nn_metrics\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"NN evaluation failed: {e}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_results(self, results):\n",
        "        \"\"\"Plot comparison results\"\"\"\n",
        "        if not results:\n",
        "            print(\"No results to plot\")\n",
        "            return\n",
        "\n",
        "        # Create comparison plot\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc_roc', 'mcc']\n",
        "        models = list(results.keys())\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        x = np.arange(len(metrics))\n",
        "        width = 0.35\n",
        "\n",
        "        for i, model in enumerate(models):\n",
        "            values = [results[model].get(metric, 0) for metric in metrics]\n",
        "            ax.bar(x + i * width, values, width, label=model, alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Metrics')\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title('Model Performance Comparison')\n",
        "        ax.set_xticks(x + width/2)\n",
        "        ax.set_xticklabels(metrics, rotation=45)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_ylim(0, 1.1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Print results table\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL EVALUATION RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        df_results = pd.DataFrame(results).T\n",
        "        df_results = df_results.round(4)\n",
        "        print(df_results.to_string())\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    def run_complete_pipeline(self, file_path, save_models=False):\n",
        "        \"\"\"\n",
        "        Run the complete dual-path machine learning pipeline\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the telematics dataset\n",
        "            save_models (bool): Whether to save trained models\n",
        "\n",
        "        Returns:\n",
        "            dict: Complete results from the pipeline\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        print(\"=\"*80)\n",
        "        print(\"STARTING DUAL-PATH MACHINE LEARNING FRAMEWORK\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Load and preprocess data\n",
        "            X, y = self.load_and_preprocess_data(file_path)\n",
        "\n",
        "            # Step 2: Split data\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)\n",
        "\n",
        "            # Step 3: Handle class imbalance\n",
        "            X_train_balanced, y_train_balanced = self.handle_class_imbalance(X_train, y_train)\n",
        "\n",
        "            # Step 4: Feature selection\n",
        "            selected_features, feature_scores = self.select_features(X_train_balanced, y_train_balanced)\n",
        "\n",
        "            # Apply feature selection to all datasets\n",
        "            X_train_selected = X_train_balanced[selected_features]\n",
        "            X_val_selected = X_val[selected_features]\n",
        "            X_test_selected = X_test[selected_features]\n",
        "\n",
        "            # Step 5: Train Gradient Boosting model\n",
        "            gb_model = self.train_gradient_boosting(X_train_selected, y_train_balanced)\n",
        "\n",
        "            # Step 6: Train Neural Network model\n",
        "            nn_model, nn_history = self.train_neural_network(\n",
        "                X_train_selected, y_train_balanced, X_val_selected, y_val\n",
        "            )\n",
        "\n",
        "            # Step 7: Evaluate models\n",
        "            evaluation_results = self.evaluate_models(X_test_selected, y_test)\n",
        "\n",
        "            # Step 8: Plot results\n",
        "            self.plot_results(evaluation_results)\n",
        "\n",
        "            # Step 9: Save models if requested\n",
        "            if save_models:\n",
        "                try:\n",
        "                    import os\n",
        "                    save_path = 'models/'\n",
        "                    if not os.path.exists(save_path):\n",
        "                        os.makedirs(save_path)\n",
        "\n",
        "                    if self.gb_model is not None:\n",
        "                        joblib.dump(self.gb_model, os.path.join(save_path, 'gb_model.pkl'))\n",
        "\n",
        "                    if self.preprocessor is not None:\n",
        "                        joblib.dump(self.preprocessor, os.path.join(save_path, 'preprocessor.pkl'))\n",
        "\n",
        "                    if self.feature_selector is not None:\n",
        "                        joblib.dump(self.feature_selector, os.path.join(save_path, 'feature_selector.pkl'))\n",
        "\n",
        "                    print(f\"Models saved to {save_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to save models: {e}\")\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_time = end_time - start_time\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"DUAL-PATH FRAMEWORK COMPLETED SUCCESSFULLY\")\n",
        "            print(\"=\"*80)\n",
        "            print(f\"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
        "\n",
        "            # Find best model\n",
        "            if evaluation_results:\n",
        "                best_model = max(evaluation_results.keys(),\n",
        "                               key=lambda x: evaluation_results[x].get('f1', 0))\n",
        "                best_f1 = evaluation_results[best_model]['f1']\n",
        "                best_auc = evaluation_results[best_model]['auc_roc']\n",
        "\n",
        "                print(f\"Best performing model: {best_model}\")\n",
        "                print(f\"  F1 Score: {best_f1:.4f}\")\n",
        "                print(f\"  AUC Score: {best_auc:.4f}\")\n",
        "\n",
        "            # Summary of results\n",
        "            pipeline_summary = {\n",
        "                'execution_time': total_time,\n",
        "                'selected_features': selected_features,\n",
        "                'feature_scores': feature_scores,\n",
        "                'model_results': evaluation_results,\n",
        "                'data_stats': {\n",
        "                    'original_shape': X.shape,\n",
        "                    'train_size': len(X_train_selected),\n",
        "                    'val_size': len(X_val_selected),\n",
        "                    'test_size': len(X_test_selected),\n",
        "                    'class_distribution': pd.Series(y).value_counts().to_dict()\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if evaluation_results:\n",
        "                pipeline_summary['best_model'] = best_model\n",
        "                pipeline_summary['best_f1_score'] = best_f1\n",
        "                pipeline_summary['best_auc_score'] = best_auc\n",
        "\n",
        "            self.results = pipeline_summary\n",
        "            return pipeline_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Pipeline failed with error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def predict_new_data(self, new_data_path):\n",
        "        \"\"\"\n",
        "        Make predictions on new data using trained models\n",
        "\n",
        "        Args:\n",
        "            new_data_path (str): Path to new data file\n",
        "\n",
        "        Returns:\n",
        "            dict: Predictions from all models\n",
        "        \"\"\"\n",
        "        if self.gb_model is None and (self.nn_model is None or self.nn_model.model is None):\n",
        "            raise ValueError(\"Models not trained yet. Run the pipeline first.\")\n",
        "\n",
        "        print(\"Making predictions on new data...\")\n",
        "\n",
        "        try:\n",
        "            # Load and preprocess new data\n",
        "            new_df = pd.read_csv(new_data_path)\n",
        "            new_X_processed = self.preprocessor.transform(new_df)\n",
        "\n",
        "            # Apply feature selection\n",
        "            if self.feature_selector and self.feature_selector.selected_features:\n",
        "                # Ensure all selected features exist\n",
        "                missing_features = set(self.feature_selector.selected_features) - set(new_X_processed.columns)\n",
        "                for feat in missing_features:\n",
        "                    new_X_processed[feat] = 0\n",
        "                new_X_selected = new_X_processed[self.feature_selector.selected_features]\n",
        "            else:\n",
        "                new_X_selected = new_X_processed\n",
        "\n",
        "            predictions = {}\n",
        "\n",
        "            # Gradient Boosting predictions\n",
        "            if self.gb_model is not None:\n",
        "                try:\n",
        "                    gb_proba = self.gb_model.predict_proba(new_X_selected)[:, 1]\n",
        "                    gb_pred = self.gb_model.predict(new_X_selected)\n",
        "                    predictions['gradient_boosting'] = {\n",
        "                        'probabilities': gb_proba,\n",
        "                        'predictions': gb_pred\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"GB prediction failed: {e}\")\n",
        "\n",
        "            # Neural Network predictions\n",
        "            if self.nn_model is not None and self.nn_model.model is not None:\n",
        "                try:\n",
        "                    if hasattr(self.nn_model, 'seq_features'):\n",
        "                        # LSTM model\n",
        "                        seq_data_new, _ = self.nn_model.prepare_lstm_data(new_X_selected, new_X_selected.columns)\n",
        "                        nn_proba = self.nn_model.model.predict([new_X_selected.values.astype(np.float32), seq_data_new])\n",
        "                        nn_proba = nn_proba.flatten()\n",
        "                    else:\n",
        "                        # Standard model\n",
        "                        if hasattr(self.nn_model.model, 'predict_proba'):\n",
        "                            nn_proba = self.nn_model.model.predict_proba(new_X_selected)[:, 1]\n",
        "                        else:\n",
        "                            nn_proba = self.nn_model.model.predict(new_X_selected.values.astype(np.float32))\n",
        "                            if nn_proba.ndim > 1:\n",
        "                                nn_proba = nn_proba.flatten()\n",
        "\n",
        "                    nn_pred = (nn_proba > 0.5).astype(int)\n",
        "                    predictions['neural_network'] = {\n",
        "                        'probabilities': nn_proba,\n",
        "                        'predictions': nn_pred\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"NN prediction failed: {e}\")\n",
        "\n",
        "            print(f\"Generated predictions for {len(new_X_selected)} samples\")\n",
        "\n",
        "            return predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction failed: {e}\")\n",
        "            return None\n",
        "\n",
        "# =============================================================================\n",
        "# ADDITIONAL UTILITY FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def load_models(load_path='models/'):\n",
        "    \"\"\"Load previously saved models\"\"\"\n",
        "    import os\n",
        "\n",
        "    framework = DualPathFramework()\n",
        "\n",
        "    # Load preprocessor\n",
        "    preprocessor_path = os.path.join(load_path, 'preprocessor.pkl')\n",
        "    if os.path.exists(preprocessor_path):\n",
        "        framework.preprocessor = joblib.load(preprocessor_path)\n",
        "        print(\"Preprocessor loaded\")\n",
        "\n",
        "    # Load feature selector\n",
        "    feature_selector_path = os.path.join(load_path, 'feature_selector.pkl')\n",
        "    if os.path.exists(feature_selector_path):\n",
        "        framework.feature_selector = joblib.load(feature_selector_path)\n",
        "        print(\"Feature selector loaded\")\n",
        "\n",
        "    # Load gradient boosting model\n",
        "    gb_model_path = os.path.join(load_path, 'gb_model.pkl')\n",
        "    if os.path.exists(gb_model_path):\n",
        "        framework.gb_model = joblib.load(gb_model_path)\n",
        "        print(\"Gradient Boosting model loaded\")\n",
        "\n",
        "    print(f\"Models loaded from {load_path}\")\n",
        "    return framework\n",
        "\n",
        "def run_driver_risk_assessment_pipeline(data_path, config=None, save_models=True):\n",
        "    \"\"\"\n",
        "    Convenience function to run the complete driver risk assessment pipeline\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the telematics dataset\n",
        "        config (dict): Optional configuration dictionary\n",
        "        save_models (bool): Whether to save trained models\n",
        "\n",
        "    Returns:\n",
        "        tuple: (framework_instance, results_summary)\n",
        "    \"\"\"\n",
        "    # Initialize framework\n",
        "    framework = DualPathFramework(config)\n",
        "\n",
        "    # Run complete pipeline\n",
        "    results = framework.run_complete_pipeline(data_path, save_models=save_models)\n",
        "\n",
        "    return framework, results\n",
        "\n",
        "def create_sample_config():\n",
        "    \"\"\"Create a sample configuration for the framework\"\"\"\n",
        "    return {\n",
        "        'preprocessing': {\n",
        "            'scaling_method': 'standard',  # 'standard', 'robust', 'minmax'\n",
        "            'handle_outliers': True\n",
        "        },\n",
        "        'imbalance_handling': {\n",
        "            'method': 'smote_tomek',  # 'smote', 'smote_tomek', 'adasyn'\n",
        "            'random_state': 42\n",
        "        },\n",
        "        'feature_selection': {\n",
        "            'n_features': 15,  # Number of features to select\n",
        "            'methods': ['mutual_info', 'rfe']  # Feature selection methods\n",
        "        },\n",
        "        'models': {\n",
        "            'gb_optimization': {\n",
        "                'cv_folds': 3,  # Number of CV folds\n",
        "                'n_iter': 15    # Number of random search iterations\n",
        "            },\n",
        "            'nn_config': {\n",
        "                'include_lstm': False,  # Whether to include LSTM\n",
        "                'epochs': 30,           # Training epochs\n",
        "                'batch_size': 64        # Batch size\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# EXAMPLE USAGE\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage with error handling\n",
        "\n",
        "    # Your dataset path\n",
        "    DATA_PATH = '/content/drive/MyDrive/Insurance/telematics_syn.csv'  # Update this path\n",
        "\n",
        "    # Option 1: Use default configuration\n",
        "    print(\"Running with default configuration...\")\n",
        "    framework, results = run_driver_risk_assessment_pipeline(DATA_PATH)\n",
        "\n",
        "    if results is not None:\n",
        "        print(\"Pipeline completed successfully!\")\n",
        "        print(f\"Best model: {results.get('best_model', 'N/A')}\")\n",
        "        print(f\"Best F1 Score: {results.get('best_f1_score', 0):.4f}\")\n",
        "        print(f\"Best AUC Score: {results.get('best_auc_score', 0):.4f}\")\n",
        "    else:\n",
        "        print(\"Pipeline failed. Check the error messages above.\")\n",
        "\n",
        "    # Option 2: Use custom configuration\n",
        "    print(\"\\nRunning with custom configuration...\")\n",
        "    custom_config = create_sample_config()\n",
        "    custom_config['models']['nn_config']['include_lstm'] = True  # Enable LSTM\n",
        "\n",
        "    framework_custom, results_custom = run_driver_risk_assessment_pipeline(\n",
        "        DATA_PATH,\n",
        "        config=custom_config,\n",
        "        save_models=True\n",
        "    )\n",
        "\n",
        "    # Option 3: Make predictions on new data (if you have new data)\n",
        "    if framework.gb_model is not None:\n",
        "        try:\n",
        "            # predictions = framework.predict_new_data('new_telematics_data.csv')\n",
        "            # print(f\"Predictions generated: {len(predictions)}\")\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction example skipped: {e}\")\n",
        "\n",
        "print(\"\"\"\n",
        "=============================================================================\n",
        "ENHANCED DUAL-PATH MACHINE LEARNING FRAMEWORK - FIXED VERSION\n",
        "=============================================================================\n",
        "\n",
        "Key Improvements Made:\n",
        "1. ✅ Fixed data type handling and conversion issues\n",
        "2. ✅ Simplified xLSTM implementation to standard LSTM\n",
        "3. ✅ Added comprehensive error handling throughout\n",
        "4. ✅ Fixed neural network input data type issues\n",
        "5. ✅ Improved preprocessing with better categorical handling\n",
        "6. ✅ Reduced parameter search space for faster execution\n",
        "7. ✅ Added fallback mechanisms for failed components\n",
        "8. ✅ Simplified ensemble approach\n",
        "9. ✅ Better memory management and data handling\n",
        "10. ✅ Comprehensive evaluation and visualization\n",
        "\n",
        "Usage Examples:\n",
        "\n",
        "# Basic usage\n",
        "framework, results = run_driver_risk_assessment_pipeline('your_data.csv')\n",
        "\n",
        "# Custom configuration\n",
        "config = create_sample_config()\n",
        "config['feature_selection']['n_features'] = 25\n",
        "framework, results = run_driver_risk_assessment_pipeline('your_data.csv', config)\n",
        "\n",
        "# Load saved models\n",
        "loaded_framework = load_models('models/')\n",
        "predictions = loaded_framework.predict_new_data('new_data.csv')\n",
        "\n",
        "Features:\n",
        "- Robust data preprocessing with type handling\n",
        "- Advanced feature selection and engineering\n",
        "- Class imbalance handling with SMOTE\n",
        "- Gradient Boosting with hyperparameter optimization\n",
        "- Neural Network with optional LSTM integration\n",
        "- Comprehensive model evaluation and visualization\n",
        "- Model saving and loading capabilities\n",
        "- Error handling and fallback mechanisms\n",
        "\n",
        "=============================================================================\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "hiXmU6lzhw0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Dual-Path Machine Learning Framework for Driver Risk Assessment\n",
        "# Complete Step-by-Step Implementation with Innovations\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, RandomizedSearchCV, cross_val_score,\n",
        "    StratifiedKFold, learning_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import (\n",
        "    mutual_info_classif, SelectKBest, RFE, VarianceThreshold\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
        "    roc_curve, precision_recall_curve, average_precision_score,\n",
        "    classification_report, log_loss\n",
        ")\n",
        "from sklearn.inspection import permutation_importance, partial_dependence\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "\n",
        "# Class Imbalance Handling\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, BatchNormalization, LSTM,\n",
        "    GRU, Attention, MultiHeadAttention, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "# Interpretability\n",
        "try:\n",
        "    import shap\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "    INTERPRETABILITY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    INTERPRETABILITY_AVAILABLE = False\n",
        "    print(\"SHAP/LIME not available. Install for interpretability features.\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: ENHANCED xLSTM IMPLEMENTATION\n",
        "# =============================================================================\n",
        "\n",
        "class xLSTMCell(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Enhanced xLSTM Cell with exponential gating and matrix memory\n",
        "    Innovation: Implements advanced memory mechanisms for temporal patterns\n",
        "    \"\"\"\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = [units, units, units]  # h, c, m (matrix memory)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Input gates with exponential gating\n",
        "        self.W_i = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_i', initializer='glorot_uniform')\n",
        "        self.U_i = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_i', initializer='orthogonal')\n",
        "        self.b_i = self.add_weight(shape=(self.units,), name='b_i',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        # Forget gates with enhanced memory control\n",
        "        self.W_f = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_f', initializer='glorot_uniform')\n",
        "        self.U_f = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_f', initializer='orthogonal')\n",
        "        self.b_f = self.add_weight(shape=(self.units,), name='b_f',\n",
        "                                  initializer='ones')\n",
        "\n",
        "        # Candidate values\n",
        "        self.W_c = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_c', initializer='glorot_uniform')\n",
        "        self.U_c = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_c', initializer='orthogonal')\n",
        "        self.b_c = self.add_weight(shape=(self.units,), name='b_c',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        # Output gates\n",
        "        self.W_o = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_o', initializer='glorot_uniform')\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_o', initializer='orthogonal')\n",
        "        self.b_o = self.add_weight(shape=(self.units,), name='b_o',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        # Matrix memory weights (Innovation)\n",
        "        self.W_m = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                  name='W_m', initializer='glorot_uniform')\n",
        "        self.U_m = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_m', initializer='orthogonal')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        h_prev, c_prev, m_prev = states\n",
        "\n",
        "        # Exponential input gate (Innovation)\n",
        "        i = tf.nn.sigmoid(tf.matmul(inputs, self.W_i) +\n",
        "                         tf.matmul(h_prev, self.U_i) + self.b_i)\n",
        "        i = tf.exp(i) / (tf.exp(i) + 1)  # Exponential gating\n",
        "\n",
        "        # Enhanced forget gate with matrix memory influence\n",
        "        f = tf.nn.sigmoid(tf.matmul(inputs, self.W_f) +\n",
        "                         tf.matmul(h_prev, self.U_f) +\n",
        "                         tf.reduce_mean(m_prev, axis=-1, keepdims=True) + self.b_f)\n",
        "\n",
        "        # Candidate values\n",
        "        c_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_c) +\n",
        "                               tf.matmul(h_prev, self.U_c) + self.b_c)\n",
        "\n",
        "        # Matrix memory update (Innovation)\n",
        "        m_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_m) +\n",
        "                               tf.matmul(h_prev, self.U_m))\n",
        "        m_new = f * m_prev + i * tf.expand_dims(m_candidate, axis=-1)\n",
        "\n",
        "        # Cell state update with matrix memory influence\n",
        "        c_new = f * c_prev + i * c_candidate * tf.reduce_mean(m_new, axis=-1)\n",
        "\n",
        "        # Output gate\n",
        "        o = tf.nn.sigmoid(tf.matmul(inputs, self.W_o) +\n",
        "                         tf.matmul(h_prev, self.U_o) + self.b_o)\n",
        "\n",
        "        # Hidden state with matrix memory\n",
        "        h_new = o * tf.nn.tanh(c_new + tf.reduce_mean(m_new, axis=-1))\n",
        "\n",
        "        return h_new, [h_new, c_new, m_new]\n",
        "\n",
        "class xLSTMLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"xLSTM Layer wrapper for sequential processing\"\"\"\n",
        "    def __init__(self, units, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.return_sequences = return_sequences\n",
        "        self.cell = xLSTMCell(units)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "\n",
        "        # Initialize states\n",
        "        h = tf.zeros((batch_size, self.units))\n",
        "        c = tf.zeros((batch_size, self.units))\n",
        "        m = tf.zeros((batch_size, self.units, self.units))\n",
        "        states = [h, c, m]\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            output, states = self.cell(inputs[:, t, :], states)\n",
        "            outputs.append(output)\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return tf.stack(outputs, axis=1)\n",
        "        else:\n",
        "            return outputs[-1]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: COMPREHENSIVE DATA PREPROCESSING CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedDataPreprocessor:\n",
        "    \"\"\"\n",
        "    Comprehensive data preprocessing with multiple scaling strategies\n",
        "    and advanced feature engineering\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scaling_method='standard', handle_outliers=True):\n",
        "        self.scaling_method = scaling_method\n",
        "        self.handle_outliers = handle_outliers\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.categorical_features = []\n",
        "        self.numerical_features = []\n",
        "\n",
        "    def detect_feature_types(self, df):\n",
        "        \"\"\"Automatically detect categorical and numerical features\"\"\"\n",
        "        categorical = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        numerical = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        return categorical, numerical\n",
        "\n",
        "    def handle_missing_values(self, df):\n",
        "        \"\"\"Advanced missing value handling\"\"\"\n",
        "        # Handle negative Car.age values as missing\n",
        "        if 'Car.age' in df.columns:\n",
        "            df.loc[df['Car.age'] < 0, 'Car.age'] = np.nan\n",
        "            df['Car.age'].fillna(df['Car.age'].median(), inplace=True)\n",
        "\n",
        "        # Fill other missing values\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                if df[col].dtype in ['object', 'category']:\n",
        "                    df[col].fillna(df[col].mode().iloc[0], inplace=True)\n",
        "                else:\n",
        "                    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def remove_outliers(self, df, method='iqr', threshold=3):\n",
        "        \"\"\"Remove outliers using IQR or Z-score method\"\"\"\n",
        "        if not self.handle_outliers:\n",
        "            return df\n",
        "\n",
        "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        if method == 'iqr':\n",
        "            for col in numerical_cols:\n",
        "                Q1 = df[col].quantile(0.25)\n",
        "                Q3 = df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "\n",
        "        elif method == 'zscore':\n",
        "            for col in numerical_cols:\n",
        "                z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n",
        "                df = df[z_scores < threshold]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def log_transform_skewed_features(self, df, skewness_threshold=0.75):\n",
        "        \"\"\"Apply log transformation to highly skewed features\"\"\"\n",
        "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        for col in numerical_cols:\n",
        "            if df[col].min() >= 0:  # Can only log-transform non-negative values\n",
        "                skewness = df[col].skew()\n",
        "                if abs(skewness) > skewness_threshold:\n",
        "                    # Add small constant to handle zeros\n",
        "                    df[f'{col}_log'] = np.log1p(df[col])\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_interaction_features(self, df):\n",
        "        \"\"\"Create interaction features for behavioral metrics\"\"\"\n",
        "        # Acceleration-Brake intensity combinations\n",
        "        accel_cols = [col for col in df.columns if 'Accel' in col]\n",
        "        brake_cols = [col for col in df.columns if 'Brake' in col]\n",
        "\n",
        "        for accel_col in accel_cols:\n",
        "            for brake_col in brake_cols:\n",
        "                if accel_col.split('.')[-1] == brake_col.split('.')[-1]:  # Same mile threshold\n",
        "                    df[f'{accel_col}_x_{brake_col}'] = df[accel_col] * df[brake_col]\n",
        "\n",
        "        # Turn intensity ratios\n",
        "        left_turn_cols = [col for col in df.columns if 'Left.turn.intensity' in col]\n",
        "        right_turn_cols = [col for col in df.columns if 'Right.turn.intensity' in col]\n",
        "\n",
        "        for left_col in left_turn_cols:\n",
        "            for right_col in right_turn_cols:\n",
        "                if left_col.split('intensity')[-1] == right_col.split('intensity')[-1]:\n",
        "                    # Avoid division by zero\n",
        "                    df[f'{left_col}_ratio_{right_col}'] = (\n",
        "                        df[left_col] / (df[right_col] + 1e-8)\n",
        "                    )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        \"\"\"Fit preprocessor and transform data\"\"\"\n",
        "        df = X.copy()\n",
        "\n",
        "        # Store original feature names\n",
        "        self.feature_names = df.columns.tolist()\n",
        "\n",
        "        # Detect feature types\n",
        "        self.categorical_features, self.numerical_features = self.detect_feature_types(df)\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Remove outliers\n",
        "        if y is not None:\n",
        "            original_indices = df.index\n",
        "            df = self.remove_outliers(df)\n",
        "            # Filter y to match filtered df\n",
        "            y = y.loc[df.index] if hasattr(y, 'loc') else y[df.index]\n",
        "\n",
        "        # Log transform skewed features\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "\n",
        "        # Create interaction features\n",
        "        df = self.create_interaction_features(df)\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True)\n",
        "\n",
        "        # Update numerical features after transformations\n",
        "        self.numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Apply scaling\n",
        "        if self.scaling_method == 'standard':\n",
        "            scaler = StandardScaler()\n",
        "        elif self.scaling_method == 'robust':\n",
        "            scaler = RobustScaler()\n",
        "        elif self.scaling_method == 'minmax':\n",
        "            scaler = MinMaxScaler()\n",
        "        else:\n",
        "            scaler = StandardScaler()\n",
        "\n",
        "        df[self.numerical_features] = scaler.fit_transform(df[self.numerical_features])\n",
        "        self.scalers['numerical'] = scaler\n",
        "\n",
        "        return df, y\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted preprocessor\"\"\"\n",
        "        df = X.copy()\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Log transform skewed features\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "\n",
        "        # Create interaction features\n",
        "        df = self.create_interaction_features(df)\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True)\n",
        "\n",
        "        # Ensure all columns are present\n",
        "        for col in self.numerical_features:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "\n",
        "        # Apply scaling\n",
        "        if 'numerical' in self.scalers:\n",
        "            df[self.numerical_features] = self.scalers['numerical'].transform(\n",
        "                df[self.numerical_features]\n",
        "            )\n",
        "\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: ADVANCED CLASS IMBALANCE HANDLER\n",
        "# =============================================================================\n",
        "\n",
        "class AdvancedImbalanceHandler:\n",
        "    \"\"\"\n",
        "    Advanced class imbalance handling with multiple techniques\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, method='smote_tomek', random_state=42):\n",
        "        self.method = method\n",
        "        self.random_state = random_state\n",
        "        self.sampler = None\n",
        "\n",
        "    def get_sampler(self):\n",
        "        \"\"\"Get appropriate sampler based on method\"\"\"\n",
        "        if self.method == 'smote':\n",
        "            return SMOTE(random_state=self.random_state)\n",
        "        elif self.method == 'smote_tomek':\n",
        "            return SMOTETomek(random_state=self.random_state)\n",
        "        elif self.method == 'adasyn':\n",
        "            return ADASYN(random_state=self.random_state)\n",
        "        elif self.method == 'borderline_smote':\n",
        "            return BorderlineSMOTE(random_state=self.random_state)\n",
        "        else:\n",
        "            return SMOTE(random_state=self.random_state)\n",
        "\n",
        "    def fit_resample(self, X, y):\n",
        "        \"\"\"Apply resampling to training data\"\"\"\n",
        "        self.sampler = self.get_sampler()\n",
        "        X_resampled, y_resampled = self.sampler.fit_resample(X, y)\n",
        "\n",
        "        print(f\"Original class distribution: {np.bincount(y)}\")\n",
        "        print(f\"Resampled class distribution: {np.bincount(y_resampled)}\")\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: ENHANCED FEATURE SELECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedFeatureSelector:\n",
        "    \"\"\"\n",
        "    Multi-method feature selection with ensemble approach\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_features=20, methods=['mutual_info', 'rfe', 'variance']):\n",
        "        self.n_features = n_features\n",
        "        self.methods = methods\n",
        "        self.selected_features = None\n",
        "        self.feature_scores = {}\n",
        "\n",
        "    def mutual_info_selection(self, X, y):\n",
        "        \"\"\"Feature selection using mutual information\"\"\"\n",
        "        mi_scores = mutual_info_classif(X, y, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, mi_scores))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "\n",
        "    def rfe_selection(self, X, y):\n",
        "        \"\"\"Recursive Feature Elimination\"\"\"\n",
        "        estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "        selector = RFE(estimator, n_features_to_select=self.n_features)\n",
        "        selector.fit(X, y)\n",
        "\n",
        "        feature_scores = dict(zip(X.columns, selector.ranking_))\n",
        "        selected_features = X.columns[selector.support_].tolist()\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def variance_selection(self, X, threshold=0.01):\n",
        "        \"\"\"Remove low-variance features\"\"\"\n",
        "        selector = VarianceThreshold(threshold=threshold)\n",
        "        selector.fit(X)\n",
        "        selected_features = X.columns[selector.get_support()].tolist()\n",
        "        feature_scores = dict(zip(X.columns, selector.variances_))\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def permutation_importance_selection(self, X, y):\n",
        "        \"\"\"Feature selection using permutation importance\"\"\"\n",
        "        estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "        estimator.fit(X, y)\n",
        "\n",
        "        perm_importance = permutation_importance(estimator, X, y, n_repeats=5, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, perm_importance.importances_mean))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "\n",
        "    def ensemble_selection(self, X, y):\n",
        "        \"\"\"Ensemble feature selection combining multiple methods\"\"\"\n",
        "        all_selected_features = []\n",
        "        method_scores = {}\n",
        "\n",
        "        if 'mutual_info' in self.methods:\n",
        "            features, scores = self.mutual_info_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['mutual_info'] = scores\n",
        "\n",
        "        if 'rfe' in self.methods:\n",
        "            features, scores = self.rfe_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['rfe'] = scores\n",
        "\n",
        "        if 'variance' in self.methods:\n",
        "            features, scores = self.variance_selection(X)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['variance'] = scores\n",
        "\n",
        "        if 'permutation' in self.methods:\n",
        "            features, scores = self.permutation_importance_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['permutation'] = scores\n",
        "\n",
        "        # Count feature frequency across methods\n",
        "        feature_counts = defaultdict(int)\n",
        "        for feature in all_selected_features:\n",
        "            feature_counts[feature] += 1\n",
        "\n",
        "        # Select features that appear in multiple methods\n",
        "        ensemble_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.selected_features = [feat[0] for feat in ensemble_features[:self.n_features]]\n",
        "        self.feature_scores = method_scores\n",
        "\n",
        "        return self.selected_features, method_scores\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: ENHANCED GRADIENT BOOSTING MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedGradientBoosting:\n",
        "    \"\"\"Enhanced Gradient Boosting with advanced hyperparameter optimization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.cv_results = None\n",
        "\n",
        "    def get_param_grid(self):\n",
        "        \"\"\"Enhanced parameter grid for optimization\"\"\"\n",
        "        return {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "            'max_depth': [3, 5, 7, 9],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'subsample': [0.8, 0.9, 1.0],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "\n",
        "    def optimize_hyperparameters(self, X, y, cv_folds=5, n_iter=50):\n",
        "        \"\"\"Optimize hyperparameters using RandomizedSearchCV\"\"\"\n",
        "        gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=gb_classifier,\n",
        "            param_distributions=self.get_param_grid(),\n",
        "            n_iter=n_iter,\n",
        "            cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
        "            scoring='roc_auc',\n",
        "            n_jobs=-1,\n",
        "            random_state=42,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        search.fit(X, y)\n",
        "        self.best_params = search.best_params_\n",
        "        self.cv_results = search.cv_results_\n",
        "        self.model = search.best_estimator_\n",
        "\n",
        "        print(\"Best Gradient Boosting Parameters:\")\n",
        "        for param, value in self.best_params.items():\n",
        "            print(f\"  {param}: {value}\")\n",
        "        print(f\"Best CV Score: {search.best_score_:.4f}\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: ENHANCED NEURAL NETWORK WITH xLSTM\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedNeuralNetwork:\n",
        "    \"\"\"Enhanced Neural Network with xLSTM integration\"\"\"\n",
        "\n",
        "    def __init__(self, include_xlstm=True):\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.include_xlstm = include_xlstm\n",
        "\n",
        "    def create_mlp_model(self, input_dim, hidden_layers=[128, 64, 32]):\n",
        "        \"\"\"Create Multi-Layer Perceptron model\"\"\"\n",
        "        inputs = Input(shape=(input_dim,))\n",
        "        x = inputs\n",
        "\n",
        "        for i, units in enumerate(hidden_layers):\n",
        "            x = Dense(units, activation='relu',\n",
        "                     kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(0.3)(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def create_xlstm_enhanced_model(self, input_dim, sequence_features=None):\n",
        "        \"\"\"Create xLSTM-enhanced model for sequential features\"\"\"\n",
        "        if sequence_features is None:\n",
        "            sequence_features = ['Daily.Driving.Percentage', 'Night.Driving.Percentage',\n",
        "                               'Avg.Speed.Per.Trip']\n",
        "\n",
        "        # Main input\n",
        "        main_input = Input(shape=(input_dim,), name='main_input')\n",
        "\n",
        "        # Sequential features processing with xLSTM\n",
        "        if self.include_xlstm:\n",
        "            # Reshape sequential features for xLSTM processing\n",
        "            seq_input = Input(shape=(len(sequence_features), 1), name='seq_input')\n",
        "            xlstm_output = xLSTMLayer(64, return_sequences=False)(seq_input)\n",
        "            xlstm_dense = Dense(32, activation='relu')(xlstm_output)\n",
        "\n",
        "            # Combine main features with xLSTM output\n",
        "            combined = keras.layers.concatenate([main_input, xlstm_dense])\n",
        "        else:\n",
        "            combined = main_input\n",
        "\n",
        "        # MLP layers\n",
        "        x = Dense(128, activation='relu',\n",
        "                 kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = Dense(64, activation='relu',\n",
        "                 kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        if self.include_xlstm:\n",
        "            model = Model(inputs=[main_input, seq_input], outputs=outputs)\n",
        "        else:\n",
        "            model = Model(inputs=main_input, outputs=outputs)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def compile_and_train(self, model, X_train, y_train, X_val, y_val,\n",
        "                         epochs=100, batch_size=32):\n",
        "        \"\"\"Compile and train the neural network\"\"\"\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', 'precision', 'recall']\n",
        "        )\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
        "        ]\n",
        "\n",
        "        if isinstance(X_train, list):  # xLSTM model with multiple inputs\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "        else:  # Standard MLP model\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "        self.model = model\n",
        "        self.history = history\n",
        "        return model, history\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: WEIGHTED ENSEMBLE INTEGRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class WeightedEnsemble:\n",
        "    \"\"\"Advanced weighted ensemble with dynamic weight calculation\"\"\"\n",
        "\n",
        "    def __init__(self, models, weight_method='accuracy'):\n",
        "        self.models = models\n",
        "        self.weight_method = weight_method\n",
        "        self.weights = None\n",
        "\n",
        "    def calculate_weights(self, X_val, y_val):\n",
        "        \"\"\"Calculate dynamic weights based on validation performance\"\"\"\n",
        "        accuracies = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred = model.predict_proba(X_val)[:, 1]\n",
        "            else:\n",
        "                y_pred = model.predict(X_val)\n",
        "\n",
        "            if self.weight_method == 'accuracy':\n",
        "                y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "                accuracies[name] = accuracy_score(y_val, y_pred_binary)\n",
        "            elif self.weight_method == 'auc':\n",
        "                accuracies[name] = roc_auc_score(y_val, y_pred)\n",
        "            elif self.weight_method == 'f1':\n",
        "                y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "                accuracies[name] = f1_score(y_val, y_pred_binary)\n",
        "\n",
        "        # Normalize weights\n",
        "        total_accuracy = sum(accuracies.values())\n",
        "        self.weights = {name: acc/total_accuracy for name, acc in accuracies.items()}\n",
        "\n",
        "        print(\"Ensemble Weights:\")\n",
        "        for name, weight in self.weights.items():\n",
        "            print(f\"  {name}: {weight:.4f}\")\n",
        "\n",
        "        return self.weights\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Generate ensemble predictions\"\"\"\n",
        "        predictions = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                predictions[name] = model.predict_proba(X)[:, 1]\n",
        "            else:\n",
        "                predictions[name] = model.predict(X)\n",
        "\n",
        "        # Weighted average\n",
        "        ensemble_pred = np.zeros(len(X))\n",
        "        for name, pred in predictions.items():\n",
        "            ensemble_pred += self.weights[name] * pred\n",
        "\n",
        "        return ensemble_pred\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        \"\"\"Generate binary predictions\"\"\"\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba > threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: THRESHOLD OPTIMIZER\n",
        "# =============================================================================\n",
        "\n",
        "class ThresholdOptimizer:\n",
        "    \"\"\"Optimize classification threshold for specific metrics\"\"\"\n",
        "\n",
        "    def __init__(self, metric='f1'):\n",
        "        self.metric = metric\n",
        "        self.optimal_threshold = 0.5\n",
        "\n",
        "    def optimize(self, y_true, y_pred_proba):\n",
        "        \"\"\"Find optimal threshold\"\"\"\n",
        "        thresholds = np.linspace(0.01, 0.99, 100)\n",
        "        best_score = 0\n",
        "        best_threshold = 0.5\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "            if self.metric == 'f1':\n",
        "                score = f1_score(y_true, y_pred, zero_division=0)\n",
        "            elif self.metric == 'precision':\n",
        "                score = precision_score(y_true, y_pred, zero_division=0)\n",
        "            elif self.metric == 'recall':\n",
        "                score = recall_score(y_true, y_pred, zero_division=0)\n",
        "            elif self.metric == 'balanced':\n",
        "                precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "                recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "                score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "\n",
        "        self.optimal_threshold = best_threshold\n",
        "        print(f\"Optimal threshold for {self.metric}: {best_threshold:.4f}\")\n",
        "        print(f\"Best {self.metric} score: {best_score:.4f}\")\n",
        "\n",
        "        return best_threshold\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: COMPREHENSIVE MODEL EVALUATOR\n",
        "# =============================================================================\n",
        "\n",
        "class ComprehensiveEvaluator:\n",
        "    \"\"\"Comprehensive model evaluation with advanced metrics and visualizations\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def calculate_all_metrics(self, y_true, y_pred, y_pred_proba, model_name):\n",
        "        \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
        "            'auc_roc': roc_auc_score(y_true, y_pred_proba),\n",
        "            'mcc': matthews_corrcoef(y_true, y_pred),\n",
        "            'log_loss': log_loss(y_true, y_pred_proba),\n",
        "            'avg_precision': average_precision_score(y_true, y_pred_proba)\n",
        "        }\n",
        "\n",
        "        self.results[model_name] = metrics\n",
        "        return metrics\n",
        "\n",
        "    def plot_comprehensive_evaluation(self, y_true, y_pred_proba_dict):\n",
        "        \"\"\"Create comprehensive evaluation plots\"\"\"\n",
        "        n_models = len(y_pred_proba_dict)\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "        # ROC Curves\n",
        "        ax = axes[0, 0]\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "            auc_score = roc_auc_score(y_true, y_pred_proba)\n",
        "            ax.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
        "\n",
        "        ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.set_title('ROC Curves')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Precision-Recall Curves\n",
        "        ax = axes[0, 1]\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            avg_precision = average_precision_score(y_true, y_pred_proba)\n",
        "            ax.plot(recall, precision, label=f'{model_name} (AP = {avg_precision:.3f})')\n",
        "\n",
        "        ax.set_xlabel('Recall')\n",
        "        ax.set_ylabel('Precision')\n",
        "        ax.set_title('Precision-Recall Curves')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Model Comparison Bar Chart\n",
        "        ax = axes[0, 2]\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc_roc']\n",
        "        x = np.arange(len(metrics))\n",
        "        width = 0.8 / len(y_pred_proba_dict)\n",
        "\n",
        "        for i, (model_name, _) in enumerate(y_pred_proba_dict.items()):\n",
        "            if model_name in self.results:\n",
        "                values = [self.results[model_name][metric] for metric in metrics]\n",
        "                ax.bar(x + i * width, values, width, label=model_name, alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Metrics')\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title('Model Comparison')\n",
        "        ax.set_xticks(x + width/2)\n",
        "        ax.set_xticklabels(metrics, rotation=45)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Confusion Matrices\n",
        "        if len(y_pred_proba_dict) <= 3:\n",
        "            for i, (model_name, y_pred_proba) in enumerate(y_pred_proba_dict.items()):\n",
        "                ax = axes[1, i]\n",
        "                y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "                cm = confusion_matrix(y_true, y_pred)\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "                ax.set_title(f'{model_name} Confusion Matrix')\n",
        "                ax.set_xlabel('Predicted')\n",
        "                ax.set_ylabel('Actual')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def print_results_table(self):\n",
        "        \"\"\"Print formatted results table\"\"\"\n",
        "        if not self.results:\n",
        "            print(\"No results to display\")\n",
        "            return\n",
        "\n",
        "        # Create DataFrame for better formatting\n",
        "        df_results = pd.DataFrame(self.results).T\n",
        "        df_results = df_results.round(4)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results.to_string())\n",
        "        print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: MODEL INTERPRETABILITY SUITE\n",
        "# =============================================================================\n",
        "\n",
        "class InterpretabilitySuite:\n",
        "    \"\"\"Comprehensive model interpretability using SHAP and LIME\"\"\"\n",
        "\n",
        "    def __init__(self, models, feature_names):\n",
        "        self.models = models\n",
        "        self.feature_names = feature_names\n",
        "        self.explainers = {}\n",
        "\n",
        "    def setup_shap_explainers(self, X_background, sample_size=100):\n",
        "        \"\"\"Setup SHAP explainers for all models\"\"\"\n",
        "        if not INTERPRETABILITY_AVAILABLE:\n",
        "            print(\"SHAP not available. Install shap package for interpretability.\")\n",
        "            return\n",
        "\n",
        "        # Sample background data\n",
        "        if len(X_background) > sample_size:\n",
        "            background_sample = shap.sample(X_background, sample_size)\n",
        "        else:\n",
        "            background_sample = X_background\n",
        "\n",
        "        for model_name, model in self.models.items():\n",
        "            try:\n",
        "                if hasattr(model, 'predict_proba'):\n",
        "                    self.explainers[model_name] = shap.KernelExplainer(\n",
        "                        lambda x: model.predict_proba(x)[:, 1],\n",
        "                        background_sample\n",
        "                    )\n",
        "                else:\n",
        "                    self.explainers[model_name] = shap.KernelExplainer(\n",
        "                        model.predict, background_sample\n",
        "                    )\n",
        "                print(f\"SHAP explainer ready for {model_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to create SHAP explainer for {model_name}: {e}\")\n",
        "\n",
        "    def explain_predictions(self, X_explain, model_name, max_display=10):\n",
        "        \"\"\"Generate SHAP explanations for predictions\"\"\"\n",
        "        if not INTERPRETABILITY_AVAILABLE or model_name not in self.explainers:\n",
        "            print(f\"SHAP explainer not available for {model_name}\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            shap_values = self.explainers[model_name].shap_values(X_explain)\n",
        "\n",
        "            # Summary plot\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            shap.summary_plot(shap_values, X_explain,\n",
        "                            feature_names=self.feature_names[:X_explain.shape[1]],\n",
        "                            max_display=max_display, show=False)\n",
        "            plt.title(f'SHAP Summary Plot - {model_name}')\n",
        "            plt.show()\n",
        "\n",
        "            return shap_values\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate SHAP explanations for {model_name}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def setup_lime_explainer(self, X_train):\n",
        "        \"\"\"Setup LIME explainer\"\"\"\n",
        "        if not INTERPRETABILITY_AVAILABLE:\n",
        "            print(\"LIME not available. Install lime package for interpretability.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "                X_train,\n",
        "                feature_names=self.feature_names[:X_train.shape[1]],\n",
        "                class_names=['No Claim', 'Claim'],\n",
        "                mode='classification'\n",
        "            )\n",
        "            return explainer\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to create LIME explainer: {e}\")\n",
        "            return None\n",
        "\n",
        "    def explain_instance_lime(self, lime_explainer, instance, model, model_name):\n",
        "        \"\"\"Explain single instance using LIME\"\"\"\n",
        "        if lime_explainer is None:\n",
        "            print(\"LIME explainer not available\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                explanation = lime_explainer.explain_instance(\n",
        "                    instance, model.predict_proba, num_features=10\n",
        "                )\n",
        "            else:\n",
        "                explanation = lime_explainer.explain_instance(\n",
        "                    instance, lambda x: np.column_stack([1-model.predict(x), model.predict(x)]),\n",
        "                    num_features=10\n",
        "                )\n",
        "\n",
        "            explanation.show_in_notebook(show_table=True)\n",
        "            return explanation\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate LIME explanation: {e}\")\n",
        "            return None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: MAIN DUAL-PATH FRAMEWORK CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class DualPathFramework:\n",
        "    \"\"\"\n",
        "    Main class implementing the complete dual-path machine learning framework\n",
        "    with all enhancements and innovations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.config = config or self._get_default_config()\n",
        "        self.preprocessor = None\n",
        "        self.imbalance_handler = None\n",
        "        self.feature_selector = None\n",
        "        self.gb_model = None\n",
        "        self.nn_model = None\n",
        "        self.ensemble = None\n",
        "        self.threshold_optimizer = None\n",
        "        self.evaluator = None\n",
        "        self.interpretability_suite = None\n",
        "        self.results = {}\n",
        "\n",
        "    def _get_default_config(self):\n",
        "        \"\"\"Default configuration for the framework\"\"\"\n",
        "        return {\n",
        "            'preprocessing': {\n",
        "                'scaling_method': 'standard',\n",
        "                'handle_outliers': True,\n",
        "                'create_interactions': True\n",
        "            },\n",
        "            'imbalance_handling': {\n",
        "                'method': 'smote_tomek',\n",
        "                'random_state': 42\n",
        "            },\n",
        "            'feature_selection': {\n",
        "                'n_features': 20,\n",
        "                'methods': ['mutual_info', 'rfe', 'permutation']\n",
        "            },\n",
        "            'models': {\n",
        "                'gb_optimization': {\n",
        "                    'cv_folds': 5,\n",
        "                    'n_iter': 30\n",
        "                },\n",
        "                'nn_config': {\n",
        "                    'include_xlstm': True,\n",
        "                    'epochs': 100,\n",
        "                    'batch_size': 32\n",
        "                }\n",
        "            },\n",
        "            'ensemble': {\n",
        "                'weight_method': 'auc'\n",
        "            },\n",
        "            'threshold_optimization': {\n",
        "                'metric': 'f1'\n",
        "            },\n",
        "            'interpretability': {\n",
        "                'enable_shap': True,\n",
        "                'enable_lime': True,\n",
        "                'background_sample_size': 100\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def load_and_preprocess_data(self, file_path):\n",
        "        \"\"\"Load and preprocess the telematics dataset\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # Load data\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "        # Create target variable\n",
        "        df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "\n",
        "        # Remove original claim columns\n",
        "        df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "        # Separate features and target\n",
        "        X = df.drop('ClaimYN', axis=1)\n",
        "        y = df['ClaimYN']\n",
        "\n",
        "        print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
        "        print(f\"Class imbalance ratio: {y.value_counts()[0] / y.value_counts()[1]:.2f}\")\n",
        "\n",
        "        # Initialize and apply preprocessing\n",
        "        self.preprocessor = EnhancedDataPreprocessor(\n",
        "            scaling_method=self.config['preprocessing']['scaling_method'],\n",
        "            handle_outliers=self.config['preprocessing']['handle_outliers']\n",
        "        )\n",
        "\n",
        "        X_processed, y_processed = self.preprocessor.fit_transform(X, y)\n",
        "\n",
        "        print(f\"Processed dataset shape: {X_processed.shape}\")\n",
        "        print(f\"Added {X_processed.shape[1] - X.shape[1]} new features\")\n",
        "\n",
        "        return X_processed, y_processed\n",
        "\n",
        "    def split_data(self, X, y, test_size=0.15, val_size=0.15):\n",
        "        \"\"\"Split data into train, validation, and test sets\"\"\"\n",
        "        # First split: separate test set\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Second split: separate train and validation from remaining data\n",
        "        val_size_adjusted = val_size / (1 - test_size)  # Adjust val_size for remaining data\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def handle_class_imbalance(self, X_train, y_train):\n",
        "        \"\"\"Apply class imbalance handling techniques\"\"\"\n",
        "        print(\"Handling class imbalance...\")\n",
        "\n",
        "        self.imbalance_handler = AdvancedImbalanceHandler(\n",
        "            method=self.config['imbalance_handling']['method'],\n",
        "            random_state=self.config['imbalance_handling']['random_state']\n",
        "        )\n",
        "\n",
        "        X_resampled, y_resampled = self.imbalance_handler.fit_resample(X_train, y_train)\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def select_features(self, X_train, y_train):\n",
        "        \"\"\"Perform advanced feature selection\"\"\"\n",
        "        print(\"Performing feature selection...\")\n",
        "\n",
        "        self.feature_selector = EnhancedFeatureSelector(\n",
        "            n_features=self.config['feature_selection']['n_features'],\n",
        "            methods=self.config['feature_selection']['methods']\n",
        "        )\n",
        "\n",
        "        selected_features, feature_scores = self.feature_selector.ensemble_selection(X_train, y_train)\n",
        "\n",
        "        print(f\"Selected {len(selected_features)} features:\")\n",
        "        for i, feature in enumerate(selected_features[:10]):  # Show top 10\n",
        "            print(f\"  {i+1}. {feature}\")\n",
        "\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def train_gradient_boosting(self, X_train, y_train):\n",
        "        \"\"\"Train enhanced gradient boosting model\"\"\"\n",
        "        print(\"Training Gradient Boosting model...\")\n",
        "\n",
        "        self.gb_model = EnhancedGradientBoosting()\n",
        "        gb_trained = self.gb_model.optimize_hyperparameters(\n",
        "            X_train, y_train,\n",
        "            cv_folds=self.config['models']['gb_optimization']['cv_folds'],\n",
        "            n_iter=self.config['models']['gb_optimization']['n_iter']\n",
        "        )\n",
        "\n",
        "        return gb_trained\n",
        "\n",
        "    def train_neural_network(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Train enhanced neural network with xLSTM\"\"\"\n",
        "        print(\"Training Neural Network with xLSTM...\")\n",
        "\n",
        "        self.nn_model = EnhancedNeuralNetwork(\n",
        "            include_xlstm=self.config['models']['nn_config']['include_xlstm']\n",
        "        )\n",
        "\n",
        "        # Create model\n",
        "        if self.config['models']['nn_config']['include_xlstm']:\n",
        "            try:\n",
        "                # Prepare sequential features for xLSTM\n",
        "                sequential_features = ['Annual.pct.driven', 'Total.miles.driven', 'Avgdays.week']\n",
        "                seq_indices = [i for i, col in enumerate(X_train.columns) if any(seq_feat in col for seq_feat in sequential_features)]\n",
        "\n",
        "                if len(seq_indices) >= 3:\n",
        "                    X_train_seq = X_train.iloc[:, seq_indices[:3]].values.reshape(-1, 3, 1)\n",
        "                    X_val_seq = X_val.iloc[:, seq_indices[:3]].values.reshape(-1, 3, 1)\n",
        "\n",
        "                    model = self.nn_model.create_xlstm_enhanced_model(X_train.shape[1])\n",
        "\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, [X_train.values, X_train_seq], y_train,\n",
        "                        [X_val.values, X_val_seq], y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "\n",
        "                    # Store sequential indices for prediction\n",
        "                    self.nn_model.seq_indices = seq_indices[:3]\n",
        "                else:\n",
        "                    print(\"Insufficient sequential features for xLSTM. Using standard MLP.\")\n",
        "                    model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, X_train.values, y_train, X_val.values, y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(f\"xLSTM failed with error: {e}\")\n",
        "                print(\"Falling back to standard MLP...\")\n",
        "                model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                trained_model, history = self.nn_model.compile_and_train(\n",
        "                    model, X_train.values, y_train, X_val.values, y_val,\n",
        "                    epochs=self.config['models']['nn_config']['epochs'],\n",
        "                    batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                )\n",
        "        else:\n",
        "            model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "            trained_model, history = self.nn_model.compile_and_train(\n",
        "                model, X_train.values, y_train, X_val.values, y_val,\n",
        "                epochs=self.config['models']['nn_config']['epochs'],\n",
        "                batch_size=self.config['models']['nn_config']['batch_size']\n",
        "            )\n",
        "\n",
        "        return trained_model, history\n",
        "\n",
        "    def create_ensemble(self, X_val, y_val):\n",
        "        \"\"\"Create weighted ensemble of trained models\"\"\"\n",
        "        print(\"Creating weighted ensemble...\")\n",
        "\n",
        "        # Neural Network wrapper to handle different input formats\n",
        "        class NNWrapper:\n",
        "            def __init__(self, nn_model, has_seq=False, seq_indices=None):\n",
        "                self.model = nn_model\n",
        "                self.has_seq = has_seq\n",
        "                self.seq_indices = seq_indices\n",
        "\n",
        "            def predict_proba(self, X):\n",
        "                if self.has_seq and self.seq_indices is not None:\n",
        "                    X_seq = X.iloc[:, self.seq_indices].values.reshape(-1, len(self.seq_indices), 1)\n",
        "                    pred = self.model.predict([X.values, X_seq])\n",
        "                    return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "                else:\n",
        "                    pred = self.model.predict(X.values)\n",
        "                    return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "\n",
        "            def predict(self, X):\n",
        "                proba = self.predict_proba(X)\n",
        "                return (proba[:, 1] > 0.5).astype(int)\n",
        "\n",
        "        # Check if neural network has sequential features\n",
        "        has_seq = hasattr(self.nn_model, 'seq_indices') and self.nn_model.seq_indices is not None\n",
        "        seq_indices = getattr(self.nn_model, 'seq_indices', None)\n",
        "\n",
        "        models_dict = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': NNWrapper(self.nn_model.model, has_seq, seq_indices)\n",
        "        }\n",
        "\n",
        "        self.ensemble = WeightedEnsemble(\n",
        "            models_dict,\n",
        "            weight_method=self.config['ensemble']['weight_method']\n",
        "        )\n",
        "\n",
        "        # Calculate ensemble weights\n",
        "        weights = self.ensemble.calculate_weights(X_val, y_val)\n",
        "\n",
        "        return self.ensemble\n",
        "\n",
        "    def optimize_threshold(self, X_val, y_val):\n",
        "        \"\"\"Optimize classification threshold\"\"\"\n",
        "        print(\"Optimizing classification threshold...\")\n",
        "\n",
        "        self.threshold_optimizer = ThresholdOptimizer(\n",
        "            metric=self.config['threshold_optimization']['metric']\n",
        "        )\n",
        "\n",
        "        # Get ensemble predictions\n",
        "        y_pred_proba = self.ensemble.predict_proba(X_val)\n",
        "\n",
        "        optimal_threshold = self.threshold_optimizer.optimize(y_val, y_pred_proba)\n",
        "\n",
        "        return optimal_threshold\n",
        "\n",
        "    def comprehensive_evaluation(self, X_test, y_test):\n",
        "        \"\"\"Perform comprehensive model evaluation\"\"\"\n",
        "        print(\"Performing comprehensive evaluation...\")\n",
        "\n",
        "        self.evaluator = ComprehensiveEvaluator()\n",
        "\n",
        "        # Evaluate individual models and ensemble\n",
        "        models_to_evaluate = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': self.ensemble.models['Neural Network'],  # Use wrapper\n",
        "            'Ensemble': self.ensemble\n",
        "        }\n",
        "\n",
        "        y_pred_proba_dict = {}\n",
        "\n",
        "        for model_name, model in models_to_evaluate.items():\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred_proba = model.predict_proba(X_test)\n",
        "                if y_pred_proba.ndim > 1:\n",
        "                    y_pred_proba = y_pred_proba[:, 1] if y_pred_proba.shape[1] > 1 else y_pred_proba.flatten()\n",
        "            else:\n",
        "                y_pred_proba = model.predict(X_test)\n",
        "\n",
        "            y_pred_proba_dict[model_name] = y_pred_proba\n",
        "\n",
        "            # Get binary predictions using optimal threshold\n",
        "            if hasattr(self.threshold_optimizer, 'optimal_threshold'):\n",
        "                y_pred = (y_pred_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "            else:\n",
        "                y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = self.evaluator.calculate_all_metrics(y_test, y_pred, y_pred_proba, model_name)\n",
        "            self.results[model_name] = metrics\n",
        "\n",
        "        # Create comprehensive plots\n",
        "        self.evaluator.plot_comprehensive_evaluation(y_test, y_pred_proba_dict)\n",
        "\n",
        "        # Print results table\n",
        "        self.evaluator.print_results_table()\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def setup_interpretability(self, X_train, X_test):\n",
        "        \"\"\"Setup model interpretability suite\"\"\"\n",
        "        if not self.config['interpretability']['enable_shap'] and not self.config['interpretability']['enable_lime']:\n",
        "            print(\"Interpretability disabled in config\")\n",
        "            return\n",
        "\n",
        "        print(\"Setting up interpretability suite...\")\n",
        "\n",
        "        models_for_interpretation = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Ensemble': self.ensemble\n",
        "        }\n",
        "\n",
        "        self.interpretability_suite = InterpretabilitySuite(\n",
        "            models_for_interpretation,\n",
        "            X_train.columns.tolist()\n",
        "        )\n",
        "\n",
        "        if self.config['interpretability']['enable_shap']:\n",
        "            self.interpretability_suite.setup_shap_explainers(\n",
        "                X_train,\n",
        "                sample_size=self.config['interpretability']['background_sample_size']\n",
        "            )\n",
        "\n",
        "        # Generate explanations for test set sample\n",
        "        if len(X_test) > 10:\n",
        "            X_explain = X_test.iloc[:10]  # Explain first 10 test samples\n",
        "        else:\n",
        "            X_explain = X_test\n",
        "\n",
        "        for model_name in models_for_interpretation.keys():\n",
        "            self.interpretability_suite.explain_predictions(X_explain, model_name)\n",
        "\n",
        "    def save_models(self, save_path='models/'):\n",
        "        \"\"\"Save trained models and preprocessors\"\"\"\n",
        "        import os\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        # Save preprocessor\n",
        "        joblib.dump(self.preprocessor, os.path.join(save_path, 'preprocessor.pkl'))\n",
        "\n",
        "        # Save feature selector\n",
        "        joblib.dump(self.feature_selector, os.path.join(save_path, 'feature_selector.pkl'))\n",
        "\n",
        "        # Save gradient boosting model\n",
        "        if self.gb_model and self.gb_model.model:\n",
        "            joblib.dump(self.gb_model.model, os.path.join(save_path, 'gradient_boosting_model.pkl'))\n",
        "\n",
        "        # Save neural network model\n",
        "        if self.nn_model and self.nn_model.model:\n",
        "            self.nn_model.model.save(os.path.join(save_path, 'neural_network_model.h5'))\n",
        "\n",
        "        # Save ensemble\n",
        "        joblib.dump(self.ensemble, os.path.join(save_path, 'ensemble.pkl'))\n",
        "\n",
        "        # Save threshold optimizer\n",
        "        joblib.dump(self.threshold_optimizer, os.path.join(save_path, 'threshold_optimizer.pkl'))\n",
        "\n",
        "        # Save results\n",
        "        joblib.dump(self.results, os.path.join(save_path, 'results.pkl'))\n",
        "\n",
        "        print(f\"Models saved to {save_path}\")\n",
        "\n",
        "    def load_models(self, load_path='models/'):\n",
        "        \"\"\"Load previously trained models\"\"\"\n",
        "        import os\n",
        "\n",
        "        # Load preprocessor\n",
        "        preprocessor_path = os.path.join(load_path, 'preprocessor.pkl')\n",
        "        if os.path.exists(preprocessor_path):\n",
        "            self.preprocessor = joblib.load(preprocessor_path)\n",
        "\n",
        "        # Load feature selector\n",
        "        feature_selector_path = os.path.join(load_path, 'feature_selector.pkl')\n",
        "        if os.path.exists(feature_selector_path):\n",
        "            self.feature_selector = joblib.load(feature_selector_path)\n",
        "\n",
        "        # Load gradient boosting model\n",
        "        gb_model_path = os.path.join(load_path, 'gradient_boosting_model.pkl')\n",
        "        if os.path.exists(gb_model_path):\n",
        "            self.gb_model = EnhancedGradientBoosting()\n",
        "            self.gb_model.model = joblib.load(gb_model_path)\n",
        "\n",
        "        # Load neural network model\n",
        "        nn_model_path = os.path.join(load_path, 'neural_network_model.h5')\n",
        "        if os.path.exists(nn_model_path):\n",
        "            self.nn_model = EnhancedNeuralNetwork()\n",
        "            self.nn_model.model = keras.models.load_model(nn_model_path, custom_objects={\n",
        "                'xLSTMCell': xLSTMCell,\n",
        "                'xLSTMLayer': xLSTMLayer\n",
        "            })\n",
        "\n",
        "        # Load ensemble\n",
        "        ensemble_path = os.path.join(load_path, 'ensemble.pkl')\n",
        "        if os.path.exists(ensemble_path):\n",
        "            self.ensemble = joblib.load(ensemble_path)\n",
        "\n",
        "        # Load threshold optimizer\n",
        "        threshold_path = os.path.join(load_path, 'threshold_optimizer.pkl')\n",
        "        if os.path.exists(threshold_path):\n",
        "            self.threshold_optimizer = joblib.load(threshold_path)\n",
        "\n",
        "        # Load results\n",
        "        results_path = os.path.join(load_path, 'results.pkl')\n",
        "        if os.path.exists(results_path):\n",
        "            self.results = joblib.load(results_path)\n",
        "\n",
        "        print(f\"Models loaded from {load_path}\")\n",
        "\n",
        "    def run_complete_pipeline(self, file_path, save_models=True):\n",
        "        \"\"\"\n",
        "        Run the complete dual-path machine learning pipeline\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the telematics dataset\n",
        "            save_models (bool): Whether to save trained models\n",
        "\n",
        "        Returns:\n",
        "            dict: Complete results from the pipeline\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        print(\"=\"*80)\n",
        "        print(\"STARTING DUAL-PATH MACHINE LEARNING FRAMEWORK\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Load and preprocess data\n",
        "            X, y = self.load_and_preprocess_data(file_path)\n",
        "\n",
        "            # Step 2: Split data\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)\n",
        "\n",
        "            # Step 3: Handle class imbalance\n",
        "            X_train_balanced, y_train_balanced = self.handle_class_imbalance(X_train, y_train)\n",
        "\n",
        "            # Step 4: Feature selection\n",
        "            selected_features, feature_scores = self.select_features(X_train_balanced, y_train_balanced)\n",
        "\n",
        "            # Apply feature selection to all datasets\n",
        "            X_train_selected = X_train_balanced[selected_features]\n",
        "            X_val_selected = X_val[selected_features]\n",
        "            X_test_selected = X_test[selected_features]\n",
        "\n",
        "            # Step 5: Train Gradient Boosting model\n",
        "            gb_model = self.train_gradient_boosting(X_train_selected, y_train_balanced)\n",
        "\n",
        "            # Step 6: Train Neural Network model\n",
        "            nn_model, nn_history = self.train_neural_network(\n",
        "                X_train_selected, y_train_balanced, X_val_selected, y_val\n",
        "            )\n",
        "\n",
        "            # Step 7: Create ensemble\n",
        "            ensemble = self.create_ensemble(X_val_selected, y_val)\n",
        "\n",
        "            # Step 8: Optimize threshold\n",
        "            optimal_threshold = self.optimize_threshold(X_val_selected, y_val)\n",
        "\n",
        "            # Step 9: Comprehensive evaluation\n",
        "            evaluation_results = self.comprehensive_evaluation(X_test_selected, y_test)\n",
        "\n",
        "            # Step 10: Setup interpretability\n",
        "            self.setup_interpretability(X_train_selected, X_test_selected)\n",
        "\n",
        "            # Step 11: Save models if requested\n",
        "            if save_models:\n",
        "                self.save_models()\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_time = end_time - start_time\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"DUAL-PATH FRAMEWORK COMPLETED SUCCESSFULLY\")\n",
        "            print(\"=\"*80)\n",
        "            print(f\"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
        "            print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
        "            print(\"\\nBest performing model based on test set:\")\n",
        "\n",
        "            # Find best model based on F1 score\n",
        "            best_model = max(evaluation_results.keys(), key=lambda x: evaluation_results[x]['f1'])\n",
        "            best_f1 = evaluation_results[best_model]['f1']\n",
        "            best_auc = evaluation_results[best_model]['auc_roc']\n",
        "\n",
        "            print(f\"  {best_model}: F1={best_f1:.4f}, AUC={best_auc:.4f}\")\n",
        "\n",
        "            # Summary of results\n",
        "            pipeline_summary = {\n",
        "                'execution_time': total_time,\n",
        "                'optimal_threshold': optimal_threshold,\n",
        "                'best_model': best_model,\n",
        "                'best_f1_score': best_f1,\n",
        "                'best_auc_score': best_auc,\n",
        "                'selected_features': selected_features,\n",
        "                'feature_scores': feature_scores,\n",
        "                'model_results': evaluation_results,\n",
        "                'data_stats': {\n",
        "                    'original_shape': X.shape,\n",
        "                    'train_size': len(X_train_selected),\n",
        "                    'val_size': len(X_val_selected),\n",
        "                    'test_size': len(X_test_selected),\n",
        "                    'class_distribution': y.value_counts().to_dict()\n",
        "                }\n",
        "            }\n",
        "\n",
        "            return pipeline_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Pipeline failed with error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def predict_new_data(self, new_data_path):\n",
        "        \"\"\"\n",
        "        Make predictions on new data using trained models\n",
        "\n",
        "        Args:\n",
        "            new_data_path (str): Path to new data file\n",
        "\n",
        "        Returns:\n",
        "            dict: Predictions from all models\n",
        "        \"\"\"\n",
        "        if self.ensemble is None:\n",
        "            raise ValueError(\"Models not trained yet. Run the pipeline first.\")\n",
        "\n",
        "        print(\"Making predictions on new data...\")\n",
        "\n",
        "        # Load and preprocess new data\n",
        "        new_df = pd.read_csv(new_data_path)\n",
        "        new_X_processed = self.preprocessor.transform(new_df)\n",
        "\n",
        "        # Apply feature selection\n",
        "        if self.feature_selector and self.feature_selector.selected_features:\n",
        "            new_X_selected = new_X_processed[self.feature_selector.selected_features]\n",
        "        else:\n",
        "            new_X_selected = new_X_processed\n",
        "\n",
        "        # Get predictions from all models\n",
        "        predictions = {}\n",
        "\n",
        "        # Gradient Boosting predictions\n",
        "        gb_proba = self.gb_model.model.predict_proba(new_X_selected)[:, 1]\n",
        "        gb_pred = (gb_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "        predictions['gradient_boosting'] = {\n",
        "            'probabilities': gb_proba,\n",
        "            'predictions': gb_pred\n",
        "        }\n",
        "\n",
        "        # Neural Network predictions\n",
        "        nn_wrapper = self.ensemble.models['Neural Network']\n",
        "        nn_proba = nn_wrapper.predict_proba(new_X_selected)[:, 1]\n",
        "        nn_pred = (nn_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "        predictions['neural_network'] = {\n",
        "            'probabilities': nn_proba,\n",
        "            'predictions': nn_pred\n",
        "        }\n",
        "\n",
        "        # Ensemble predictions\n",
        "        ensemble_proba = self.ensemble.predict_proba(new_X_selected)\n",
        "        ensemble_pred = (ensemble_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "        predictions['ensemble'] = {\n",
        "            'probabilities': ensemble_proba,\n",
        "            'predictions': ensemble_pred\n",
        "        }\n",
        "\n",
        "        print(f\"Generated predictions for {len(new_X_selected)} samples\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# Example usage and pipeline execution function\n",
        "def run_driver_risk_assessment_pipeline(data_path, config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to run the complete driver risk assessment pipeline\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the telematics dataset\n",
        "        config (dict): Optional configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        tuple: (framework_instance, results_summary)\n",
        "    \"\"\"\n",
        "    # Initialize framework\n",
        "    framework = DualPathFramework(config)\n",
        "\n",
        "    # Run complete pipeline\n",
        "    results = framework.run_complete_pipeline(data_path)\n",
        "\n",
        "    return framework, results\n",
        "\n",
        "# Example usage with your dataset\n",
        "if __name__ == \"__main__\":\n",
        "    # Your dataset path\n",
        "    DATA_PATH = '/content/drive/MyDrive/Insurance/telematics_syn.csv'\n",
        "\n",
        "    # Run the complete pipeline\n",
        "    framework, results = run_driver_risk_assessment_pipeline(DATA_PATH)\n",
        "\n",
        "    if results is not None:\n",
        "        print(\"Pipeline completed successfully!\")\n",
        "        print(f\"Best model: {results['best_model']}\")\n",
        "        print(f\"Best F1 Score: {results['best_f1_score']:.4f}\")\n",
        "        print(f\"Best AUC Score: {results['best_auc_score']:.4f}\")\n",
        "    else:\n",
        "        print(\"Pipeline failed. Check the error messages above.\")"
      ],
      "metadata": {
        "id": "9fbP1iy03qPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Dual-Path Machine Learning Framework for Driver Risk Assessment\n",
        "# Complete Step-by-Step Implementation with Fixes for xLSTM and Dtype Issues\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, RandomizedSearchCV, cross_val_score,\n",
        "    StratifiedKFold, learning_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.feature_selection import (\n",
        "    mutual_info_classif, SelectKBest, RFE, VarianceThreshold\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
        "    roc_curve, precision_recall_curve, average_precision_score,\n",
        "    classification_report, log_loss\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, BatchNormalization, LSTM,\n",
        "    GRU, Attention, MultiHeadAttention, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "# Interpretability\n",
        "try:\n",
        "    import shap\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "    INTERPRETABILITY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    INTERPRETABILITY_AVAILABLE = False\n",
        "    print(\"SHAP/LIME not available. Install for interpretability features.\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: ENHANCED xLSTM IMPLEMENTATION\n",
        "# =============================================================================\n",
        "\n",
        "class xLSTMCell(tf.keras.layers.Layer):\n",
        "    \"\"\"Enhanced xLSTM Cell with exponential gating and matrix memory\"\"\"\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = [units, units, [units, units]]  # h, c, m (matrix memory)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        feature_dim = input_shape[-1]\n",
        "        self.W_i = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='W_i', initializer='glorot_uniform')\n",
        "        self.U_i = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_i', initializer='orthogonal')\n",
        "        self.b_i = self.add_weight(shape=(self.units,), name='b_i',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        self.W_f = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='W_f', initializer='glorot_uniform')\n",
        "        self.U_f = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_f', initializer='orthogonal')\n",
        "        self.b_f = self.add_weight(shape=(self.units,), name='b_f',\n",
        "                                  initializer='ones')\n",
        "\n",
        "        self.W_c = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='W_c', initializer='glorot_uniform')\n",
        "        self.U_c = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_c', initializer='orthogonal')\n",
        "        self.b_c = self.add_weight(shape=(self.units,), name='b_c',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        self.W_o = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='W_o', initializer='glorot_uniform')\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_o', initializer='orthogonal')\n",
        "        self.b_o = self.add_weight(shape=(self.units,), name='b_o',\n",
        "                                  initializer='zeros')\n",
        "\n",
        "        self.W_m = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='W_m', initializer='glorot_uniform')\n",
        "        self.U_m = self.add_weight(shape=(self.units, self.units),\n",
        "                                  name='U_m', initializer='orthogonal')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        h_prev, c_prev, m_prev = states\n",
        "\n",
        "        i = tf.nn.sigmoid(tf.matmul(inputs, self.W_i) +\n",
        "                         tf.matmul(h_prev, self.U_i) + self.b_i)\n",
        "        i = tf.exp(i) / (tf.exp(i) + 1)\n",
        "\n",
        "        f = tf.nn.sigmoid(tf.matmul(inputs, self.W_f) +\n",
        "                         tf.matmul(h_prev, self.U_f) +\n",
        "                         tf.reduce_mean(m_prev, axis=-1, keepdims=True) + self.b_f)\n",
        "\n",
        "        c_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_c) +\n",
        "                               tf.matmul(h_prev, self.U_c) + self.b_c)\n",
        "\n",
        "        m_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_m) +\n",
        "                               tf.matmul(h_prev, self.U_m))\n",
        "        m_new = f * m_prev + i * tf.expand_dims(m_candidate, axis=-1)\n",
        "\n",
        "        c_new = f * c_prev + i * c_candidate * tf.reduce_mean(m_new, axis=-1)\n",
        "\n",
        "        o = tf.nn.sigmoid(tf.matmul(inputs, self.W_o) +\n",
        "                         tf.matmul(h_prev, self.U_o) + self.b_o)\n",
        "\n",
        "        h_new = o * tf.nn.tanh(c_new + tf.reduce_mean(m_new, axis=-1))\n",
        "\n",
        "        return h_new, [h_new, c_new, m_new]\n",
        "\n",
        "class xLSTMLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"xLSTM Layer wrapper for sequential processing\"\"\"\n",
        "    def __init__(self, units, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.return_sequences = return_sequences\n",
        "        self.cell = xLSTMCell(units)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.return_sequences:\n",
        "            return tf.TensorShape([input_shape[0], input_shape[1], self.units])\n",
        "        return tf.TensorShape([input_shape[0], self.units])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "\n",
        "        h = tf.zeros((batch_size, self.units))\n",
        "        c = tf.zeros((batch_size, self.units))\n",
        "        m = tf.zeros((batch_size, self.units, self.units))\n",
        "        states = [h, c, m]\n",
        "\n",
        "        outputs = []\n",
        "        for t in tf.range(seq_len):\n",
        "            current_input = inputs[:, t, :]  # Shape: (batch_size, feature_dim)\n",
        "            output, states = self.cell(current_input, states)\n",
        "            outputs.append(output)\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return tf.stack(outputs, axis=1)\n",
        "        else:\n",
        "            return outputs[-1]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: COMPREHENSIVE DATA PREPROCESSING CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedDataPreprocessor:\n",
        "    \"\"\"Comprehensive data preprocessing with robust numeric handling\"\"\"\n",
        "\n",
        "    def __init__(self, scaling_method='standard', handle_outliers=True, create_interactions=True):\n",
        "        self.scaling_method = scaling_method\n",
        "        self.handle_outliers = handle_outliers\n",
        "        self.create_interactions = create_interactions\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.categorical_features = []\n",
        "        self.numerical_features = []\n",
        "\n",
        "    def detect_feature_types(self, df):\n",
        "        categorical = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        numerical = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
        "        return categorical, numerical\n",
        "\n",
        "    def handle_missing_values(self, df):\n",
        "        df = df.copy()\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                if col in self.numerical_features:\n",
        "                    df[col].fillna(df[col].median(), inplace=True)\n",
        "                elif col in self.categorical_features:\n",
        "                    df[col].fillna(df[col].mode().iloc[0], inplace=True)\n",
        "        return df\n",
        "\n",
        "    def remove_outliers(self, df, method='iqr', iqr_multiplier=3.0):\n",
        "        if not self.handle_outliers:\n",
        "            return df\n",
        "        numerical_cols = self.numerical_features\n",
        "        for col in numerical_cols:\n",
        "            if method == 'iqr':\n",
        "                Q1 = df[col].quantile(0.25)\n",
        "                Q3 = df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - iqr_multiplier * IQR\n",
        "                upper_bound = Q3 + iqr_multiplier * IQR\n",
        "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "        print(f\"Data shape after outlier removal: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def log_transform_skewed_features(self, df, skewness_threshold=0.75):\n",
        "        df = df.copy()\n",
        "        for col in self.numerical_features:\n",
        "            if df[col].min() >= 0:\n",
        "                skewness = df[col].skew()\n",
        "                if abs(skewness) > skewness_threshold:\n",
        "                    df[f'{col}_log'] = np.log1p(df[col])\n",
        "                    self.numerical_features.append(f'{col}_log')\n",
        "        return df\n",
        "\n",
        "    def create_interaction_features(self, df):\n",
        "        if not self.create_interactions:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        accel_cols = [col for col in self.numerical_features if 'Accel' in col]\n",
        "        brake_cols = [col for col in self.numerical_features if 'Brake' in col]\n",
        "        for accel_col in accel_cols[:2]:  # Limit to avoid excessive features\n",
        "            for brake_col in brake_cols[:2]:\n",
        "                if accel_col.split('.')[-1] == brake_col.split('.')[-1]:\n",
        "                    new_col = f'{accel_col}_x_{brake_col}'\n",
        "                    df[new_col] = df[accel_col] * df[brake_col]\n",
        "                    self.numerical_features.append(new_col)\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        self.feature_names = df.columns.tolist()\n",
        "        self.categorical_features, self.numerical_features = self.detect_feature_types(df)\n",
        "\n",
        "        print(\"Initial dtypes:\", df.dtypes.value_counts())\n",
        "\n",
        "        # Handle missing values\n",
        "        df = self.handle_missing_values(df)\n",
        "\n",
        "        # Remove outliers\n",
        "        if y is not None and self.handle_outliers:\n",
        "            original_indices = df.index\n",
        "            df = self.remove_outliers(df)\n",
        "            y = y.loc[df.index] if hasattr(y, 'loc') else y[df.index]\n",
        "\n",
        "        # Log transform skewed features\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "\n",
        "        # Create interaction features\n",
        "        df = self.create_interaction_features(df)\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True, dtype=float)\n",
        "            self.categorical_features = [col for col in df.columns if col not in self.numerical_features]\n",
        "\n",
        "        # Update numerical features\n",
        "        self.numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Check for non-numeric columns\n",
        "        non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "        if non_numeric_cols.any():\n",
        "            print(f\"Warning: Non-numeric columns found: {non_numeric_cols.tolist()}\")\n",
        "            raise ValueError(\"Non-numeric columns detected after preprocessing\")\n",
        "\n",
        "        # Apply scaling\n",
        "        scaler = StandardScaler() if self.scaling_method == 'standard' else RobustScaler()\n",
        "        df[self.numerical_features] = scaler.fit_transform(df[self.numerical_features])\n",
        "        self.scalers['numerical'] = scaler\n",
        "\n",
        "        # Final validation\n",
        "        if df.isna().any().any() or not np.all(np.isfinite(df.values)):\n",
        "            raise ValueError(\"Data contains NaN or infinite values after preprocessing\")\n",
        "\n",
        "        print(\"Final dtypes:\", df.dtypes.value_counts())\n",
        "        return df, y\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        df = self.handle_missing_values(df)\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "        df = self.create_interaction_features(df)\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True, dtype=float)\n",
        "        for col in self.numerical_features:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "        df[self.numerical_features] = self.scalers['numerical'].transform(df[self.numerical_features])\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: ADVANCED CLASS IMBALANCE HANDLER\n",
        "# =============================================================================\n",
        "\n",
        "class AdvancedImbalanceHandler:\n",
        "    \"\"\"Advanced class imbalance handling with SMOTETomek\"\"\"\n",
        "\n",
        "    def __init__(self, method='smote_tomek', random_state=42):\n",
        "        self.method = method\n",
        "        self.random_state = random_state\n",
        "        self.sampler = None\n",
        "\n",
        "    def get_sampler(self):\n",
        "        return SMOTETomek(random_state=self.random_state)\n",
        "\n",
        "    def fit_resample(self, X, y):\n",
        "        self.sampler = self.get_sampler()\n",
        "        X_resampled, y_resampled = self.sampler.fit_resample(X, y)\n",
        "        print(f\"Original class distribution: {np.bincount(y)}\")\n",
        "        print(f\"Resampled class distribution: {np.bincount(y_resampled)}\")\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: ENHANCED FEATURE SELECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedFeatureSelector:\n",
        "    \"\"\"Multi-method feature selection with ensemble approach\"\"\"\n",
        "\n",
        "    def __init__(self, n_features=20, methods=['mutual_info', 'rfe', 'permutation']):\n",
        "        self.n_features = n_features\n",
        "        self.methods = methods\n",
        "        self.selected_features = None\n",
        "        self.feature_scores = {}\n",
        "\n",
        "    def mutual_info_selection(self, X, y):\n",
        "        mi_scores = mutual_info_classif(X, y, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, mi_scores))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "\n",
        "    def rfe_selection(self, X, y):\n",
        "        estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "        selector = RFE(estimator, n_features_to_select=self.n_features)\n",
        "        selector.fit(X, y)\n",
        "        feature_scores = dict(zip(X.columns, selector.ranking_))\n",
        "        selected_features = X.columns[selector.support_].tolist()\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def permutation_importance_selection(self, X, y):\n",
        "        estimator = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "        estimator.fit(X, y)\n",
        "        perm_importance = permutation_importance(estimator, X, y, n_repeats=5, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, perm_importance.importances_mean))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [feat[0] for feat in top_features[:self.n_features]], feature_scores\n",
        "\n",
        "    def ensemble_selection(self, X, y):\n",
        "        non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns\n",
        "        if non_numeric_cols.any():\n",
        "            raise ValueError(f\"Non-numeric columns in feature selection: {non_numeric_cols.tolist()}\")\n",
        "\n",
        "        all_selected_features = []\n",
        "        method_scores = {}\n",
        "\n",
        "        if 'mutual_info' in self.methods:\n",
        "            features, scores = self.mutual_info_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['mutual_info'] = scores\n",
        "\n",
        "        if 'rfe' in self.methods:\n",
        "            features, scores = self.rfe_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['rfe'] = scores\n",
        "\n",
        "        if 'permutation' in self.methods:\n",
        "            features, scores = self.permutation_importance_selection(X, y)\n",
        "            all_selected_features.extend(features)\n",
        "            method_scores['permutation'] = scores\n",
        "\n",
        "        feature_counts = defaultdict(int)\n",
        "        for feature in all_selected_features:\n",
        "            feature_counts[feature] += 1\n",
        "\n",
        "        ensemble_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.selected_features = [feat[0] for feat in ensemble_features[:self.n_features]]\n",
        "        self.feature_scores = method_scores\n",
        "\n",
        "        return self.selected_features, method_scores\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: ENHANCED GRADIENT BOOSTING MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedGradientBoosting:\n",
        "    \"\"\"Enhanced Gradient Boosting with hyperparameter optimization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "\n",
        "    def get_param_grid(self):\n",
        "        return {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "            'max_depth': [3, 5, 7],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'subsample': [0.8, 0.9, 1.0],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "\n",
        "    def optimize_hyperparameters(self, X, y, cv_folds=5, n_iter=30):\n",
        "        gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=gb_classifier,\n",
        "            param_distributions=self.get_param_grid(),\n",
        "            n_iter=n_iter,\n",
        "            cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
        "            scoring='roc_auc',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        search.fit(X, y)\n",
        "        self.best_params = search.best_params_\n",
        "        self.model = search.best_estimator_\n",
        "        print(\"Best Gradient Boosting Parameters:\", self.best_params)\n",
        "        print(f\"Best CV Score: {search.best_score_:.4f}\")\n",
        "        return self.model\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: ENHANCED NEURAL NETWORK WITH xLSTM\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedNeuralNetwork:\n",
        "    \"\"\"Enhanced Neural Network with xLSTM integration\"\"\"\n",
        "\n",
        "    def __init__(self, include_xlstm=True):\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.include_xlstm = include_xlstm\n",
        "        self.seq_indices = None\n",
        "\n",
        "    def create_mlp_model(self, input_dim):\n",
        "        model = Sequential([\n",
        "            Dense(128, activation='relu', input_shape=(input_dim,), kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.3),\n",
        "            Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.3),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    def create_xlstm_enhanced_model(self, input_dim):\n",
        "        main_input = Input(shape=(input_dim,), name='main_input')\n",
        "        seq_input = Input(shape=(3, 1), name='seq_input')\n",
        "        xlstm_output = xLSTMLayer(64, return_sequences=False)(seq_input)\n",
        "        xlstm_dense = Dense(32, activation='relu')(xlstm_output)\n",
        "        combined = keras.layers.concatenate([main_input, xlstm_dense])\n",
        "\n",
        "        x = Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        return Model(inputs=[main_input, seq_input], outputs=outputs)\n",
        "\n",
        "    def compile_and_train(self, model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
        "        ]\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        self.model = model\n",
        "        self.history = history\n",
        "        return model, history\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: WEIGHTED ENSEMBLE INTEGRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class WeightedEnsemble:\n",
        "    \"\"\"Weighted ensemble with dynamic weight calculation\"\"\"\n",
        "\n",
        "    def __init__(self, models, weight_method='auc'):\n",
        "        self.models = models\n",
        "        self.weight_method = weight_method\n",
        "        self.weights = None\n",
        "\n",
        "    def calculate_weights(self, X_val, y_val):\n",
        "        accuracies = {}\n",
        "        for name, model in self.models.items():\n",
        "            y_pred = model.predict_proba(X_val)[:, 1]\n",
        "            if self.weight_method == 'auc':\n",
        "                accuracies[name] = roc_auc_score(y_val, y_pred)\n",
        "            elif self.weight_method == 'f1':\n",
        "                y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "                accuracies[name] = f1_score(y_val, y_pred_binary)\n",
        "        total_accuracy = sum(accuracies.values())\n",
        "        self.weights = {name: acc/total_accuracy for name, acc in accuracies.items()}\n",
        "        print(\"Ensemble Weights:\", self.weights)\n",
        "        return self.weights\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        predictions = {}\n",
        "        for name, model in self.models.items():\n",
        "            predictions[name] = model.predict_proba(X)[:, 1]\n",
        "        ensemble_pred = np.zeros(len(X))\n",
        "        for name, pred in predictions.items():\n",
        "            ensemble_pred += self.weights[name] * pred\n",
        "        return ensemble_pred\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba > threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: THRESHOLD OPTIMIZER\n",
        "# =============================================================================\n",
        "\n",
        "class ThresholdOptimizer:\n",
        "    \"\"\"Optimize classification threshold for specific metrics\"\"\"\n",
        "\n",
        "    def __init__(self, metric='f1'):\n",
        "        self.metric = metric\n",
        "        self.optimal_threshold = 0.5\n",
        "\n",
        "    def optimize(self, y_true, y_pred_proba):\n",
        "        thresholds = np.linspace(0.01, 0.99, 100)\n",
        "        best_score = 0\n",
        "        best_threshold = 0.5\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "            score = f1_score(y_true, y_pred, zero_division=0)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "        self.optimal_threshold = best_threshold\n",
        "        print(f\"Optimal threshold for {self.metric}: {best_threshold:.4f}\")\n",
        "        return best_threshold\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: COMPREHENSIVE MODEL EVALUATOR\n",
        "# =============================================================================\n",
        "\n",
        "class ComprehensiveEvaluator:\n",
        "    \"\"\"Comprehensive model evaluation with metrics and visualizations\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def calculate_all_metrics(self, y_true, y_pred, y_pred_proba, model_name):\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
        "            'auc_roc': roc_auc_score(y_true, y_pred_proba)\n",
        "        }\n",
        "        self.results[model_name] = metrics\n",
        "        return metrics\n",
        "\n",
        "    def plot_comprehensive_evaluation(self, y_true, y_pred_proba_dict):\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "            auc_score = roc_auc_score(y_true, y_pred_proba)\n",
        "            ax1.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
        "        ax1.plot([0, 1], [0, 1], 'k--')\n",
        "        ax1.set_xlabel('False Positive Rate')\n",
        "        ax1.set_ylabel('True Positive Rate')\n",
        "        ax1.set_title('ROC Curves')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            ax2.plot(recall, precision, label=f'{model_name}')\n",
        "        ax2.set_xlabel('Recall')\n",
        "        ax2.set_ylabel('Precision')\n",
        "        ax2.set_title('Precision-Recall Curves')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def print_results_table(self):\n",
        "        df_results = pd.DataFrame(self.results).T\n",
        "        df_results = df_results.round(4)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results.to_string())\n",
        "        print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: MAIN DUAL-PATH FRAMEWORK CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class DualPathFramework:\n",
        "    \"\"\"Main class implementing the dual-path machine learning framework\"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.config = config or {\n",
        "            'preprocessing': {\n",
        "                'scaling_method': 'standard',\n",
        "                'handle_outliers': True,\n",
        "                'create_interactions': True,\n",
        "                'iqr_multiplier': 3.0\n",
        "            },\n",
        "            'imbalance_handling': {'method': 'smote_tomek', 'random_state': 42},\n",
        "            'feature_selection': {'n_features': 20, 'methods': ['mutual_info', 'rfe', 'permutation']},\n",
        "            'models': {\n",
        "                'gb_optimization': {'cv_folds': 5, 'n_iter': 30},\n",
        "                'nn_config': {'include_xlstm': True, 'epochs': 50, 'batch_size': 32}\n",
        "            },\n",
        "            'ensemble': {'weight_method': 'auc'},\n",
        "            'threshold_optimization': {'metric': 'f1'},\n",
        "            'interpretability': {'enable_shap': False}\n",
        "        }\n",
        "        self.preprocessor = None\n",
        "        self.imbalance_handler = None\n",
        "        self.feature_selector = None\n",
        "        self.gb_model = None\n",
        "        self.nn_model = None\n",
        "        self.ensemble = None\n",
        "        self.threshold_optimizer = None\n",
        "        self.evaluator = None\n",
        "        self.results = {}\n",
        "\n",
        "    def load_and_preprocess_data(self, file_path):\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "        df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "        df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "        X = df.drop('ClaimYN', axis=1)\n",
        "        y = df['ClaimYN']\n",
        "\n",
        "        print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
        "        print(f\"Class imbalance ratio: {y.value_counts()[0] / y.value_counts()[1]:.2f}\")\n",
        "\n",
        "        self.preprocessor = EnhancedDataPreprocessor(\n",
        "            scaling_method=self.config['preprocessing']['scaling_method'],\n",
        "            handle_outliers=self.config['preprocessing']['handle_outliers'],\n",
        "            create_interactions=self.config['preprocessing']['create_interactions']\n",
        "        )\n",
        "        X_processed, y_processed = self.preprocessor.fit_transform(X, y)\n",
        "\n",
        "        print(f\"Processed dataset shape: {X_processed.shape}\")\n",
        "        print(f\"Added {X_processed.shape[1] - X.shape[1]} new features\")\n",
        "        return X_processed, y_processed\n",
        "\n",
        "    def split_data(self, X, y):\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=0.15, random_state=42, stratify=y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
        "        )\n",
        "        print(f\"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def handle_class_imbalance(self, X_train, y_train):\n",
        "        print(\"Handling class imbalance...\")\n",
        "        self.imbalance_handler = AdvancedImbalanceHandler(\n",
        "            method=self.config['imbalance_handling']['method'],\n",
        "            random_state=self.config['imbalance_handling']['random_state']\n",
        "        )\n",
        "        X_resampled, y_resampled = self.imbalance_handler.fit_resample(X_train, y_train)\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def select_features(self, X_train, y_train):\n",
        "        print(\"Performing feature selection...\")\n",
        "        self.feature_selector = EnhancedFeatureSelector(\n",
        "            n_features=self.config['feature_selection']['n_features'],\n",
        "            methods=self.config['feature_selection']['methods']\n",
        "        )\n",
        "        selected_features, feature_scores = self.feature_selector.ensemble_selection(X_train, y_train)\n",
        "        print(f\"Selected {len(selected_features)} features:\", selected_features[:10])\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def train_gradient_boosting(self, X_train, y_train):\n",
        "        print(\"Training Gradient Boosting model...\")\n",
        "        self.gb_model = EnhancedGradientBoosting()\n",
        "        return self.gb_model.optimize_hyperparameters(\n",
        "            X_train, y_train,\n",
        "            cv_folds=self.config['models']['gb_optimization']['cv_folds'],\n",
        "            n_iter=self.config['models']['gb_optimization']['n_iter']\n",
        "        )\n",
        "\n",
        "    def train_neural_network(self, X_train, y_train, X_val, y_val):\n",
        "        print(\"Training Neural Network...\")\n",
        "        self.nn_model = EnhancedNeuralNetwork(include_xlstm=self.config['models']['nn_config']['include_xlstm'])\n",
        "\n",
        "        if self.config['models']['nn_config']['include_xlstm']:\n",
        "            try:\n",
        "                sequential_features = ['Annual.pct.driven', 'Total.miles.driven', 'Avgdays.week']\n",
        "                seq_indices = [i for i, col in enumerate(X_train.columns) if any(s in col for s in sequential_features)]\n",
        "\n",
        "                if len(seq_indices) >= 3:\n",
        "                    X_train_seq = X_train.iloc[:, seq_indices[:3]].values.astype(np.float32).reshape(-1, 3, 1)\n",
        "                    X_val_seq = X_val.iloc[:, seq_indices[:3]].values.astype(np.float32).reshape(-1, 3, 1)\n",
        "\n",
        "                    if not np.all(np.isfinite(X_train_seq)) or not np.all(np.isfinite(X_val_seq)):\n",
        "                        raise ValueError(\"Sequential features contain non-numeric or invalid values\")\n",
        "\n",
        "                    model = self.nn_model.create_xlstm_enhanced_model(X_train.shape[1])\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, [X_train.values.astype(np.float32), X_train_seq], y_train,\n",
        "                        [X_val.values.astype(np.float32), X_val_seq], y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "                    self.nn_model.seq_indices = seq_indices[:3]\n",
        "                else:\n",
        "                    print(f\"Found only {len(seq_indices)} sequential features. Falling back to MLP.\")\n",
        "                    model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, X_train.values.astype(np.float32), y_train,\n",
        "                        X_val.values.astype(np.float32), y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(f\"xLSTM failed with error: {e}\")\n",
        "                print(\"Falling back to standard MLP...\")\n",
        "                model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                trained_model, history = self.nn_model.compile_and_train(\n",
        "                    model, X_train.values.astype(np.float32), y_train,\n",
        "                    X_val.values.astype(np.float32), y_val,\n",
        "                    epochs=self.config['models']['nn_config']['epochs'],\n",
        "                    batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                )\n",
        "        else:\n",
        "            model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "            trained_model, history = self.nn_model.compile_and_train(\n",
        "                model, X_train.values.astype(np.float32), y_train,\n",
        "                X_val.values.astype(np.float32), y_val,\n",
        "                epochs=self.config['models']['nn_config']['epochs'],\n",
        "                batch_size=self.config['models']['nn_config']['batch_size']\n",
        "            )\n",
        "\n",
        "        return trained_model, history\n",
        "\n",
        "    def create_ensemble(self, X_val, y_val):\n",
        "        print(\"Creating weighted ensemble...\")\n",
        "        class NNWrapper:\n",
        "            def __init__(self, nn_model, has_seq=False, seq_indices=None):\n",
        "                self.model = nn_model\n",
        "                self.has_seq = has_seq\n",
        "                self.seq_indices = seq_indices\n",
        "\n",
        "            def predict_proba(self, X):\n",
        "                if self.has_seq and self.seq_indices:\n",
        "                    X_seq = X.iloc[:, self.seq_indices].values.astype(np.float32).reshape(-1, len(self.seq_indices), 1)\n",
        "                    pred = self.model.predict([X.values.astype(np.float32), X_seq])\n",
        "                    return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "                pred = self.model.predict(X.values.astype(np.float32))\n",
        "                return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "\n",
        "            def predict(self, X):\n",
        "                return (self.predict_proba(X)[:, 1] > 0.5).astype(int)\n",
        "\n",
        "        has_seq = hasattr(self.nn_model, 'seq_indices') and self.nn_model.seq_indices is not None\n",
        "        models_dict = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': NNWrapper(self.nn_model.model, has_seq, self.nn_model.seq_indices)\n",
        "        }\n",
        "        self.ensemble = WeightedEnsemble(models_dict, weight_method=self.config['ensemble']['weight_method'])\n",
        "        self.ensemble.calculate_weights(X_val, y_val)\n",
        "        return self.ensemble\n",
        "\n",
        "    def optimize_threshold(self, X_val, y_val):\n",
        "        print(\"Optimizing classification threshold...\")\n",
        "        self.threshold_optimizer = ThresholdOptimizer(metric=self.config['threshold_optimization']['metric'])\n",
        "        y_pred_proba = self.ensemble.predict_proba(X_val)\n",
        "        return self.threshold_optimizer.optimize(y_val, y_pred_proba)\n",
        "\n",
        "    def comprehensive_evaluation(self, X_test, y_test):\n",
        "        print(\"Performing comprehensive evaluation...\")\n",
        "        self.evaluator = ComprehensiveEvaluator()\n",
        "        models_to_evaluate = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': self.ensemble.models['Neural Network'],\n",
        "            'Ensemble': self.ensemble\n",
        "        }\n",
        "        y_pred_proba_dict = {}\n",
        "        for model_name, model in models_to_evaluate.items():\n",
        "            y_pred_proba = model.predict_proba(X_test)\n",
        "            if y_pred_proba.ndim > 1:\n",
        "                y_pred_proba = y_pred_proba[:, 1]\n",
        "            y_pred = (y_pred_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "            self.evaluator.calculate_all_metrics(y_test, y_pred, y_pred_proba, model_name)\n",
        "            y_pred_proba_dict[model_name] = y_pred_proba\n",
        "        self.evaluator.plot_comprehensive_evaluation(y_test, y_pred_proba_dict)\n",
        "        self.evaluator.print_results_table()\n",
        "        return self.evaluator.results\n",
        "\n",
        "    def run_complete_pipeline(self, file_path):\n",
        "        start_time = time.time()\n",
        "        print(\"=\"*80)\n",
        "        print(\"STARTING DUAL-PATH MACHINE LEARNING FRAMEWORK\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            X, y = self.load_and_preprocess_data(file_path)\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)\n",
        "            X_train_balanced, y_train_balanced = self.handle_class_imbalance(X_train, y_train)\n",
        "            selected_features, feature_scores = self.select_features(X_train_balanced, y_train_balanced)\n",
        "\n",
        "            X_train_selected = X_train_balanced[selected_features]\n",
        "            X_val_selected = X_val[selected_features]\n",
        "            X_test_selected = X_test[selected_features]\n",
        "\n",
        "            # Validate data types\n",
        "            if not X_train_selected.select_dtypes(include=[np.number]).columns.equals(X_train_selected.columns):\n",
        "                raise ValueError(\"Non-numeric columns in X_train_selected\")\n",
        "\n",
        "            self.train_gradient_boosting(X_train_selected, y_train_balanced)\n",
        "            self.train_neural_network(X_train_selected, y_train_balanced, X_val_selected, y_val)\n",
        "            self.create_ensemble(X_val_selected, y_val)\n",
        "            optimal_threshold = self.optimize_threshold(X_val_selected, y_val)\n",
        "            evaluation_results = self.comprehensive_evaluation(X_test_selected, y_test)\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_time = end_time - start_time\n",
        "            best_model = max(evaluation_results.keys(), key=lambda x: evaluation_results[x]['f1'])\n",
        "\n",
        "            pipeline_summary = {\n",
        "                'execution_time': total_time,\n",
        "                'optimal_threshold': optimal_threshold,\n",
        "                'best_model': best_model,\n",
        "                'best_f1_score': evaluation_results[best_model]['f1'],\n",
        "                'best_auc_score': evaluation_results[best_model]['auc_roc'],\n",
        "                'selected_features': selected_features,\n",
        "                'feature_scores': feature_scores,\n",
        "                'model_results': evaluation_results\n",
        "            }\n",
        "\n",
        "            print(\"=\"*80)\n",
        "            print(\"DUAL-PATH FRAMEWORK COMPLETED SUCCESSFULLY\")\n",
        "            print(f\"Total execution time: {total_time:.2f} seconds\")\n",
        "            print(f\"Best model: {best_model}, F1={pipeline_summary['best_f1_score']:.4f}\")\n",
        "            return pipeline_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Pipeline failed with error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: EXECUTE PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    DATA_PATH = '/content/drive/MyDrive/Insurance/telematics_syn.csv'\n",
        "    config = {\n",
        "        'preprocessing': {\n",
        "            'scaling_method': 'standard',\n",
        "            'handle_outliers': True,\n",
        "            'create_interactions': True,\n",
        "            'iqr_multiplier': 3.0\n",
        "        },\n",
        "        'imbalance_handling': {'method': 'smote_tomek', 'random_state': 42},\n",
        "        'feature_selection': {'n_features': 20, 'methods': ['mutual_info', 'rfe', 'permutation']},\n",
        "        'models': {\n",
        "            'gb_optimization': {'cv_folds': 5, 'n_iter': 30},\n",
        "            'nn_config': {'include_xlstm': True, 'epochs': 50, 'batch_size': 32}\n",
        "        },\n",
        "        'ensemble': {'weight_method': 'auc'},\n",
        "        'threshold_optimization': {'metric': 'f1'},\n",
        "        'interpretability': {'enable_shap': False}\n",
        "    }\n",
        "\n",
        "    framework = DualPathFramework(config)\n",
        "    results = framework.run_complete_pipeline(DATA_PATH)\n",
        "\n",
        "    if results:\n",
        "        print(\"Pipeline completed successfully!\")\n",
        "        print(f\"Best model: {results['best_model']}\")\n",
        "        print(f\"Best F1 Score: {results['best_f1_score']:.4f}\")\n",
        "        print(f\"Best AUC Score: {results['best_auc_score']:.4f}\")\n",
        "    else:\n",
        "        print(\"Pipeline failed. Check the error messages above.\")"
      ],
      "metadata": {
        "id": "X5z157XRDsxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Dual-Path Machine Learning Framework for Driver Risk Assessment\n",
        "# Memory-Optimized Implementation with Fixes for xLSTM and Dtype Issues\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import joblib\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.feature_selection import (\n",
        "    mutual_info_classif, SelectKBest, RFE\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, precision_recall_curve\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Configure TensorFlow for memory efficiency\n",
        "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True) if tf.config.list_physical_devices('GPU') else None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: ENHANCED xLSTM IMPLEMENTATION (SIMPLIFIED)\n",
        "# =============================================================================\n",
        "\n",
        "class xLSTMCell(tf.keras.layers.Layer):\n",
        "    \"\"\"Simplified xLSTM Cell with reduced memory footprint\"\"\"\n",
        "    def __init__(self, units=32, **kwargs):  # Reduced units\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = [units, units]  # h, c (removed matrix memory)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        feature_dim = input_shape[-1]\n",
        "        self.W_i = self.add_weight(shape=(feature_dim, self.units), initializer='glorot_uniform')\n",
        "        self.U_i = self.add_weight(shape=(self.units, self.units), initializer='orthogonal')\n",
        "        self.b_i = self.add_weight(shape=(self.units,), initializer='zeros')\n",
        "\n",
        "        self.W_f = self.add_weight(shape=(feature_dim, self.units), initializer='glorot_uniform')\n",
        "        self.U_f = self.add_weight(shape=(self.units, self.units), initializer='orthogonal')\n",
        "        self.b_f = self.add_weight(shape=(self.units,), initializer='ones')\n",
        "\n",
        "        self.W_c = self.add_weight(shape=(feature_dim, self.units), initializer='glorot_uniform')\n",
        "        self.U_c = self.add_weight(shape=(self.units, self.units), initializer='orthogonal')\n",
        "        self.b_c = self.add_weight(shape=(self.units,), initializer='zeros')\n",
        "\n",
        "        self.W_o = self.add_weight(shape=(feature_dim, self.units), initializer='glorot_uniform')\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.units), initializer='orthogonal')\n",
        "        self.b_o = self.add_weight(shape=(self.units,), initializer='zeros')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        h_prev, c_prev = states\n",
        "        i = tf.nn.sigmoid(tf.matmul(inputs, self.W_i) + tf.matmul(h_prev, self.U_i) + self.b_i)\n",
        "        f = tf.nn.sigmoid(tf.matmul(inputs, self.W_f) + tf.matmul(h_prev, self.U_f) + self.b_f)\n",
        "        c_candidate = tf.nn.tanh(tf.matmul(inputs, self.W_c) + tf.matmul(h_prev, self.U_c) + self.b_c)\n",
        "        c_new = f * c_prev + i * c_candidate\n",
        "        o = tf.nn.sigmoid(tf.matmul(inputs, self.W_o) + tf.matmul(h_prev, self.U_o) + self.b_o)\n",
        "        h_new = o * tf.nn.tanh(c_new)\n",
        "        return h_new, [h_new, c_new]\n",
        "\n",
        "class xLSTMLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Simplified xLSTM Layer for sequential processing\"\"\"\n",
        "    def __init__(self, units=32, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.return_sequences = return_sequences\n",
        "        self.cell = xLSTMCell(units)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.return_sequences:\n",
        "            return tf.TensorShape([input_shape[0], input_shape[1], self.units])\n",
        "        return tf.TensorShape([input_shape[0], self.units])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        h = tf.zeros((batch_size, self.units))\n",
        "        c = tf.zeros((batch_size, self.units))\n",
        "        states = [h, c]\n",
        "        outputs = []\n",
        "        for t in tf.range(seq_len):\n",
        "            current_input = inputs[:, t, :]\n",
        "            output, states = self.cell(current_input, states)\n",
        "            outputs.append(output)\n",
        "        if self.return_sequences:\n",
        "            return tf.stack(outputs, axis=1)\n",
        "        return outputs[-1]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: MEMORY-EFFICIENT DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedDataPreprocessor:\n",
        "    \"\"\"Memory-efficient data preprocessing\"\"\"\n",
        "\n",
        "    def __init__(self, scaling_method='standard', handle_outliers=True, create_interactions=True):\n",
        "        self.scaling_method = scaling_method\n",
        "        self.handle_outliers = handle_outliers\n",
        "        self.create_interactions = create_interactions\n",
        "        self.scaler = StandardScaler() if scaling_method == 'standard' else RobustScaler()\n",
        "        self.categorical_features = []\n",
        "        self.numerical_features = []\n",
        "\n",
        "    def detect_feature_types(self, df):\n",
        "        categorical = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "        numerical = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
        "        return categorical, numerical\n",
        "\n",
        "    def handle_missing_values(self, df):\n",
        "        df = df.copy()\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                if col in self.numerical_features:\n",
        "                    df[col] = df[col].fillna(df[col].median())\n",
        "                elif col in self.categorical_features:\n",
        "                    df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
        "        return df\n",
        "\n",
        "    def remove_outliers(self, df, iqr_multiplier=3.0):\n",
        "        if not self.handle_outliers:\n",
        "            return df\n",
        "        numerical_cols = self.numerical_features\n",
        "        for col in numerical_cols:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - iqr_multiplier * IQR\n",
        "            upper_bound = Q3 + iqr_multiplier * IQR\n",
        "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "        print(f\"Data shape after outlier removal: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def log_transform_skewed_features(self, df, skewness_threshold=0.75):\n",
        "        df = df.copy()\n",
        "        for col in self.numerical_features:\n",
        "            if df[col].min() >= 0:\n",
        "                skewness = df[col].skew()\n",
        "                if abs(skewness) > skewness_threshold:\n",
        "                    df[f'{col}_log'] = np.log1p(df[col]).astype(np.float32)\n",
        "                    self.numerical_features.append(f'{col}_log')\n",
        "        return df\n",
        "\n",
        "    def create_interaction_features(self, df):\n",
        "        if not self.create_interactions:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        accel_cols = [col for col in self.numerical_features if 'Accel' in col][:1]  # Limit to 1\n",
        "        brake_cols = [col for col in self.numerical_features if 'Brake' in col][:1]\n",
        "        for accel_col in accel_cols:\n",
        "            for brake_col in brake_cols:\n",
        "                if accel_col.split('.')[-1] == brake_col.split('.')[-1]:\n",
        "                    new_col = f'{accel_col}_x_{brake_col}'\n",
        "                    df[new_col] = (df[accel_col] * df[brake_col]).astype(np.float32)\n",
        "                    self.numerical_features.append(new_col)\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        self.categorical_features, self.numerical_features = self.detect_feature_types(df)\n",
        "        print(\"Initial dtypes:\", df.dtypes.value_counts())\n",
        "\n",
        "        df = self.handle_missing_values(df)\n",
        "        if y is not None and self.handle_outliers:\n",
        "            df = self.remove_outliers(df)\n",
        "            y = y.loc[df.index] if hasattr(y, 'loc') else y[df.index]\n",
        "\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "        df = self.create_interaction_features(df)\n",
        "\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True, dtype=np.float32)\n",
        "            self.categorical_features = [col for col in df.columns if col not in self.numerical_features]\n",
        "\n",
        "        self.numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        if df.select_dtypes(exclude=[np.number]).columns.any():\n",
        "            raise ValueError(\"Non-numeric columns detected after preprocessing\")\n",
        "\n",
        "        df[self.numerical_features] = self.scaler.fit_transform(df[self.numerical_features]).astype(np.float32)\n",
        "\n",
        "        if df.isna().any().any() or not np.all(np.isfinite(df.values)):\n",
        "            raise ValueError(\"Data contains NaN or infinite values\")\n",
        "\n",
        "        print(\"Final dtypes:\", df.dtypes.value_counts())\n",
        "        return df, y\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        df = self.handle_missing_values(df)\n",
        "        df = self.log_transform_skewed_features(df)\n",
        "        df = self.create_interaction_features(df)\n",
        "        if self.categorical_features:\n",
        "            df = pd.get_dummies(df, columns=self.categorical_features, drop_first=True, dtype=np.float32)\n",
        "        for col in self.numerical_features:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0\n",
        "        df[self.numerical_features] = self.scaler.transform(df[self.numerical_features]).astype(np.float32)\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: MEMORY-EFFICIENT CLASS IMBALANCE HANDLER\n",
        "# =============================================================================\n",
        "\n",
        "class AdvancedImbalanceHandler:\n",
        "    \"\"\"Memory-efficient class imbalance handling\"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.sampler = SMOTE(random_state=random_state, sampling_strategy=0.5)  # Reduced oversampling\n",
        "\n",
        "    def fit_resample(self, X, y):\n",
        "        X_resampled, y_resampled = self.sampler.fit_resample(X, y)\n",
        "        print(f\"Original class distribution: {np.bincount(y)}\")\n",
        "        print(f\"Resampled class distribution: {np.bincount(y_resampled)}\")\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: FEATURE SELECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedFeatureSelector:\n",
        "    \"\"\"Memory-efficient feature selection\"\"\"\n",
        "\n",
        "    def __init__(self, n_features=15):  # Reduced number of features\n",
        "        self.n_features = n_features\n",
        "        self.selected_features = None\n",
        "\n",
        "    def ensemble_selection(self, X, y):\n",
        "        if X.select_dtypes(exclude=[np.number]).columns.any():\n",
        "            raise ValueError(\"Non-numeric columns in feature selection\")\n",
        "\n",
        "        mi_scores = mutual_info_classif(X, y, random_state=42)\n",
        "        feature_scores = dict(zip(X.columns, mi_scores))\n",
        "        top_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.selected_features = [feat[0] for feat in top_features[:self.n_features]]\n",
        "        return self.selected_features, feature_scores\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: GRADIENT BOOSTING MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedGradientBoosting:\n",
        "    \"\"\"Memory-efficient Gradient Boosting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "\n",
        "    def get_param_grid(self):\n",
        "        return {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.1],\n",
        "            'max_depth': [3, 5],\n",
        "            'subsample': [0.8, 1.0]\n",
        "        }\n",
        "\n",
        "    def optimize_hyperparameters(self, X, y, cv_folds=3, n_iter=10):\n",
        "        gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=gb_classifier,\n",
        "            param_distributions=self.get_param_grid(),\n",
        "            n_iter=n_iter,\n",
        "            cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
        "            scoring='roc_auc',\n",
        "            n_jobs=1,  # Avoid parallel processing to save memory\n",
        "            verbose=1\n",
        "        )\n",
        "        search.fit(X, y)\n",
        "        self.model = search.best_estimator_\n",
        "        print(\"Best Gradient Boosting Parameters:\", search.best_params_)\n",
        "        print(f\"Best CV Score: {search.best_score_:.4f}\")\n",
        "        return self.model\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: NEURAL NETWORK WITH xLSTM\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedNeuralNetwork:\n",
        "    \"\"\"Memory-efficient Neural Network with simplified xLSTM\"\"\"\n",
        "\n",
        "    def __init__(self, include_xlstm=True):\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.include_xlstm = include_xlstm\n",
        "        self.seq_indices = None\n",
        "\n",
        "    def create_mlp_model(self, input_dim):\n",
        "        model = Sequential([\n",
        "            Dense(64, activation='relu', input_shape=(input_dim,), kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "            Dropout(0.2),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    def create_xlstm_enhanced_model(self, input_dim):\n",
        "        main_input = Input(shape=(input_dim,), name='main_input')\n",
        "        seq_input = Input(shape=(3, 1), name='seq_input')\n",
        "        xlstm_output = xLSTMLayer(32, return_sequences=False)(seq_input)\n",
        "        combined = keras.layers.concatenate([main_input, xlstm_output])\n",
        "        x = Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
        "        x = Dropout(0.2)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "        return Model(inputs=[main_input, seq_input], outputs=outputs)\n",
        "\n",
        "    def compile_and_train(self, model, X_train, y_train, X_val, y_val, epochs=20, batch_size=64):\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
        "        ]\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        self.model = model\n",
        "        self.history = history\n",
        "        return model, history\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: WEIGHTED ENSEMBLE\n",
        "# =============================================================================\n",
        "\n",
        "class WeightedEnsemble:\n",
        "    \"\"\"Memory-efficient weighted ensemble\"\"\"\n",
        "\n",
        "    def __init__(self, models, weight_method='auc'):\n",
        "        self.models = models\n",
        "        self.weight_method = weight_method\n",
        "        self.weights = None\n",
        "\n",
        "    def calculate_weights(self, X_val, y_val):\n",
        "        accuracies = {}\n",
        "        for name, model in self.models.items():\n",
        "            y_pred = model.predict_proba(X_val)[:, 1]\n",
        "            accuracies[name] = roc_auc_score(y_val, y_pred)\n",
        "        total_accuracy = sum(accuracies.values())\n",
        "        self.weights = {name: acc/total_accuracy for name, acc in accuracies.items()}\n",
        "        print(\"Ensemble Weights:\", self.weights)\n",
        "        return self.weights\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        predictions = {}\n",
        "        for name, model in self.models.items():\n",
        "            predictions[name] = model.predict_proba(X)[:, 1]\n",
        "        ensemble_pred = np.zeros(len(X), dtype=np.float32)\n",
        "        for name, pred in predictions.items():\n",
        "            ensemble_pred += self.weights[name] * pred\n",
        "        return ensemble_pred\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba > threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: THRESHOLD OPTIMIZER\n",
        "# =============================================================================\n",
        "\n",
        "class ThresholdOptimizer:\n",
        "    \"\"\"Optimize classification threshold\"\"\"\n",
        "\n",
        "    def __init__(self, metric='f1'):\n",
        "        self.metric = metric\n",
        "        self.optimal_threshold = 0.5\n",
        "\n",
        "    def optimize(self, y_true, y_pred_proba):\n",
        "        thresholds = np.linspace(0.01, 0.99, 50)\n",
        "        best_score = 0\n",
        "        best_threshold = 0.5\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "            score = f1_score(y_true, y_pred, zero_division=0)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "        self.optimal_threshold = best_threshold\n",
        "        print(f\"Optimal threshold for {self.metric}: {best_threshold:.4f}\")\n",
        "        return best_threshold\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: MODEL EVALUATOR\n",
        "# =============================================================================\n",
        "\n",
        "class ComprehensiveEvaluator:\n",
        "    \"\"\"Memory-efficient model evaluation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def calculate_all_metrics(self, y_true, y_pred, y_pred_proba, model_name):\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
        "            'auc_roc': roc_auc_score(y_true, y_pred_proba)\n",
        "        }\n",
        "        self.results[model_name] = metrics\n",
        "        return metrics\n",
        "\n",
        "    def plot_comprehensive_evaluation(self, y_true, y_pred_proba_dict):\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "            auc_score = roc_auc_score(y_true, y_pred_proba)\n",
        "            ax1.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
        "        ax1.plot([0, 1], [0, 1], 'k--')\n",
        "        ax1.set_xlabel('False Positive Rate')\n",
        "        ax1.set_ylabel('True Positive Rate')\n",
        "        ax1.set_title('ROC Curves')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        for model_name, y_pred_proba in y_pred_proba_dict.items():\n",
        "            precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "            ax2.plot(recall, precision, label=f'{model_name}')\n",
        "        ax2.set_xlabel('Recall')\n",
        "        ax2.set_ylabel('Precision')\n",
        "        ax2.set_title('Precision-Recall Curves')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def print_results_table(self):\n",
        "        df_results = pd.DataFrame(self.results).T.round(4)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_results.to_string())\n",
        "        print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: MAIN DUAL-PATH FRAMEWORK\n",
        "# =============================================================================\n",
        "\n",
        "class DualPathFramework:\n",
        "    \"\"\"Memory-efficient dual-path machine learning framework\"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        self.config = config or {\n",
        "            'preprocessing': {\n",
        "                'scaling_method': 'standard',\n",
        "                'handle_outliers': True,\n",
        "                'create_interactions': True,\n",
        "                'iqr_multiplier': 3.0\n",
        "            },\n",
        "            'imbalance_handling': {'random_state': 42},\n",
        "            'feature_selection': {'n_features': 15},\n",
        "            'models': {\n",
        "                'gb_optimization': {'cv_folds': 3, 'n_iter': 10},\n",
        "                'nn_config': {'include_xlstm': True, 'epochs': 20, 'batch_size': 64}\n",
        "            },\n",
        "            'ensemble': {'weight_method': 'auc'},\n",
        "            'threshold_optimization': {'metric': 'f1'}\n",
        "        }\n",
        "        self.preprocessor = None\n",
        "        self.imbalance_handler = None\n",
        "        self.feature_selector = None\n",
        "        self.gb_model = None\n",
        "        self.nn_model = None\n",
        "        self.ensemble = None\n",
        "        self.threshold_optimizer = None\n",
        "        self.evaluator = None\n",
        "        self.results = {}\n",
        "\n",
        "    def load_and_preprocess_data(self, file_path):\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "        # Load smaller subset for testing\n",
        "        df = pd.read_csv(file_path).sample(20000, random_state=42)  # Reduced size\n",
        "        print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "        df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "        df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "        X = df.drop('ClaimYN', axis=1)\n",
        "        y = df['ClaimYN']\n",
        "\n",
        "        print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
        "        self.preprocessor = EnhancedDataPreprocessor(\n",
        "            scaling_method=self.config['preprocessing']['scaling_method'],\n",
        "            handle_outliers=self.config['preprocessing']['handle_outliers'],\n",
        "            create_interactions=self.config['preprocessing']['create_interactions']\n",
        "        )\n",
        "        X_processed, y_processed = self.preprocessor.fit_transform(X, y)\n",
        "        return X_processed, y_processed\n",
        "\n",
        "    def split_data(self, X, y):\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=0.15, random_state=42, stratify=y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
        "        )\n",
        "        print(f\"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def handle_class_imbalance(self, X_train, y_train):\n",
        "        print(\"Handling class imbalance...\")\n",
        "        self.imbalance_handler = AdvancedImbalanceHandler(\n",
        "            random_state=self.config['imbalance_handling']['random_state']\n",
        "        )\n",
        "        return self.imbalance_handler.fit_resample(X_train, y_train)\n",
        "\n",
        "    def select_features(self, X_train, y_train):\n",
        "        print(\"Performing feature selection...\")\n",
        "        self.feature_selector = EnhancedFeatureSelector(\n",
        "            n_features=self.config['feature_selection']['n_features']\n",
        "        )\n",
        "        selected_features, feature_scores = self.feature_selector.ensemble_selection(X_train, y_train)\n",
        "        print(f\"Selected {len(selected_features)} features:\", selected_features[:10])\n",
        "        return selected_features, feature_scores\n",
        "\n",
        "    def train_gradient_boosting(self, X_train, y_train):\n",
        "        print(\"Training Gradient Boosting model...\")\n",
        "        self.gb_model = EnhancedGradientBoosting()\n",
        "        return self.gb_model.optimize_hyperparameters(\n",
        "            X_train, y_train,\n",
        "            cv_folds=self.config['models']['gb_optimization']['cv_folds'],\n",
        "            n_iter=self.config['models']['gb_optimization']['n_iter']\n",
        "        )\n",
        "\n",
        "    def train_neural_network(self, X_train, y_train, X_val, y_val):\n",
        "        print(\"Training Neural Network...\")\n",
        "        self.nn_model = EnhancedNeuralNetwork(include_xlstm=self.config['models']['nn_config']['include_xlstm'])\n",
        "\n",
        "        if self.config['models']['nn_config']['include_xlstm']:\n",
        "            try:\n",
        "                sequential_features = ['Annual.pct.driven', 'Total.miles.driven', 'Avgdays.week']\n",
        "                seq_indices = [i for i, col in enumerate(X_train.columns) if any(s in col for s in sequential_features)]\n",
        "\n",
        "                if len(seq_indices) >= 3:\n",
        "                    X_train_seq = X_train.iloc[:, seq_indices[:3]].values.astype(np.float32).reshape(-1, 3, 1)\n",
        "                    X_val_seq = X_val.iloc[:, seq_indices[:3]].values.astype(np.float32).reshape(-1, 3, 1)\n",
        "\n",
        "                    if not np.all(np.isfinite(X_train_seq)) or not np.all(np.isfinite(X_val_seq)):\n",
        "                        raise ValueError(\"Sequential features contain non-numeric or invalid values\")\n",
        "\n",
        "                    model = self.nn_model.create_xlstm_enhanced_model(X_train.shape[1])\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, [X_train.values.astype(np.float32), X_train_seq], y_train,\n",
        "                        [X_val.values.astype(np.float32), X_val_seq], y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "                    self.nn_model.seq_indices = seq_indices[:3]\n",
        "                else:\n",
        "                    print(f\"Found only {len(seq_indices)} sequential features. Falling back to MLP.\")\n",
        "                    model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                    trained_model, history = self.nn_model.compile_and_train(\n",
        "                        model, X_train.values.astype(np.float32), y_train,\n",
        "                        X_val.values.astype(np.float32), y_val,\n",
        "                        epochs=self.config['models']['nn_config']['epochs'],\n",
        "                        batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(f\"xLSTM failed with error: {e}\")\n",
        "                print(\"Falling back to standard MLP...\")\n",
        "                model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "                trained_model, history = self.nn_model.compile_and_train(\n",
        "                    model, X_train.values.astype(np.float32), y_train,\n",
        "                    X_val.values.astype(np.float32), y_val,\n",
        "                    epochs=self.config['models']['nn_config']['epochs'],\n",
        "                    batch_size=self.config['models']['nn_config']['batch_size']\n",
        "                )\n",
        "        else:\n",
        "            model = self.nn_model.create_mlp_model(X_train.shape[1])\n",
        "            trained_model, history = self.nn_model.compile_and_train(\n",
        "                model, X_train.values.astype(np.float32), y_train,\n",
        "                X_val.values.astype(np.float32), y_val,\n",
        "                epochs=self.config['models']['nn_config']['epochs'],\n",
        "                batch_size=self.config['models']['nn_config']['batch_size']\n",
        "            )\n",
        "        return trained_model, history\n",
        "\n",
        "    def create_ensemble(self, X_val, y_val):\n",
        "        print(\"Creating weighted ensemble...\")\n",
        "        class NNWrapper:\n",
        "            def __init__(self, nn_model, has_seq=False, seq_indices=None):\n",
        "                self.model = nn_model\n",
        "                self.has_seq = has_seq\n",
        "                self.seq_indices = seq_indices\n",
        "\n",
        "            def predict_proba(self, X):\n",
        "                if self.has_seq and self.seq_indices:\n",
        "                    X_seq = X.iloc[:, self.seq_indices].values.astype(np.float32).reshape(-1, len(self.seq_indices), 1)\n",
        "                    pred = self.model.predict([X.values.astype(np.float32), X_seq], batch_size=64)\n",
        "                    return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "                pred = self.model.predict(X.values.astype(np.float32), batch_size=64)\n",
        "                return np.column_stack([1-pred.flatten(), pred.flatten()])\n",
        "\n",
        "            def predict(self, X):\n",
        "                return (self.predict_proba(X)[:, 1] > 0.5).astype(int)\n",
        "\n",
        "        has_seq = hasattr(self.nn_model, 'seq_indices') and self.nn_model.seq_indices is not None\n",
        "        models_dict = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': NNWrapper(self.nn_model.model, has_seq, self.nn_model.seq_indices)\n",
        "        }\n",
        "        self.ensemble = WeightedEnsemble(models_dict, weight_method=self.config['ensemble']['weight_method'])\n",
        "        self.ensemble.calculate_weights(X_val, y_val)\n",
        "        return self.ensemble\n",
        "\n",
        "    def optimize_threshold(self, X_val, y_val):\n",
        "        print(\"Optimizing classification threshold...\")\n",
        "        self.threshold_optimizer = ThresholdOptimizer(metric=self.config['threshold_optimization']['metric'])\n",
        "        y_pred_proba = self.ensemble.predict_proba(X_val)\n",
        "        return self.threshold_optimizer.optimize(y_val, y_pred_proba)\n",
        "\n",
        "    def comprehensive_evaluation(self, X_test, y_test):\n",
        "        print(\"Performing comprehensive evaluation...\")\n",
        "        self.evaluator = ComprehensiveEvaluator()\n",
        "        models_to_evaluate = {\n",
        "            'Gradient Boosting': self.gb_model.model,\n",
        "            'Neural Network': self.ensemble.models['Neural Network'],\n",
        "            'Ensemble': self.ensemble\n",
        "        }\n",
        "        y_pred_proba_dict = {}\n",
        "        for model_name, model in models_to_evaluate.items():\n",
        "            y_pred_proba = model.predict_proba(X_test)\n",
        "            if y_pred_proba.ndim > 1:\n",
        "                y_pred_proba = y_pred_proba[:, 1]\n",
        "            y_pred = (y_pred_proba >= self.threshold_optimizer.optimal_threshold).astype(int)\n",
        "            self.evaluator.calculate_all_metrics(y_test, y_pred, y_pred_proba, model_name)\n",
        "            y_pred_proba_dict[model_name] = y_pred_proba\n",
        "        self.evaluator.plot_comprehensive_evaluation(y_test, y_pred_proba_dict)\n",
        "        self.evaluator.print_results_table()\n",
        "        return self.evaluator.results\n",
        "\n",
        "    def run_complete_pipeline(self, file_path):\n",
        "        start_time = time.time()\n",
        "        print(\"=\"*80)\n",
        "        print(\"STARTING DUAL-PATH MACHINE LEARNING FRAMEWORK\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            X, y = self.load_and_preprocess_data(file_path)\n",
        "            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)\n",
        "            X_train_balanced, y_train_balanced = self.handle_class_imbalance(X_train, y_train)\n",
        "            selected_features, feature_scores = self.select_features(X_train_balanced, y_train_balanced)\n",
        "\n",
        "            X_train_selected = X_train_balanced[selected_features]\n",
        "            X_val_selected = X_val[selected_features]\n",
        "            X_test_selected = X_test[selected_features]\n",
        "\n",
        "            if not X_train_selected.select_dtypes(include=[np.number]).columns.equals(X_train_selected.columns):\n",
        "                raise ValueError(\"Non-numeric columns in X_train_selected\")\n",
        "\n",
        "            self.train_gradient_boosting(X_train_selected, y_train_balanced)\n",
        "            self.train_neural_network(X_train_selected, y_train_balanced, X_val_selected, y_val)\n",
        "            self.create_ensemble(X_val_selected, y_val)\n",
        "            optimal_threshold = self.optimize_threshold(X_val_selected, y_val)\n",
        "            evaluation_results = self.comprehensive_evaluation(X_test_selected, y_test)\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_time = end_time - start_time\n",
        "            best_model = max(evaluation_results.keys(), key=lambda x: evaluation_results[x]['f1'])\n",
        "\n",
        "            pipeline_summary = {\n",
        "                'execution_time': total_time,\n",
        "                'optimal_threshold': optimal_threshold,\n",
        "                'best_model': best_model,\n",
        "                'best_f1_score': evaluation_results[best_model]['f1'],\n",
        "                'best_auc_score': evaluation_results[best_model]['auc_roc'],\n",
        "                'selected_features': selected_features\n",
        "            }\n",
        "\n",
        "            print(\"=\"*80)\n",
        "            print(\"DUAL-PATH FRAMEWORK COMPLETED SUCCESSFULLY\")\n",
        "            print(f\"Total execution time: {total_time:.2f} seconds\")\n",
        "            print(f\"Best model: {best_model}, F1={pipeline_summary['best_f1_score']:.4f}\")\n",
        "            return pipeline_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Pipeline failed with error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: EXECUTE PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    DATA_PATH = '/content/drive/MyDrive/Insurance/telematics_syn.csv'\n",
        "    config = {\n",
        "        'preprocessing': {\n",
        "            'scaling_method': 'standard',\n",
        "            'handle_outliers': True,\n",
        "            'create_interactions': True,\n",
        "            'iqr_multiplier': 3.0\n",
        "        },\n",
        "        'imbalance_handling': {'random_state': 42},\n",
        "        'feature_selection': {'n_features': 15},\n",
        "        'models': {\n",
        "            'gb_optimization': {'cv_folds': 3, 'n_iter': 10},\n",
        "            'nn_config': {'include_xlstm': True, 'epochs': 20, 'batch_size': 64}\n",
        "        },\n",
        "        'ensemble': {'weight_method': 'auc'},\n",
        "        'threshold_optimization': {'metric': 'f1'}\n",
        "    }\n",
        "\n",
        "    framework = DualPathFramework(config)\n",
        "    results = framework.run_complete_pipeline(DATA_PATH)\n",
        "\n",
        "    if results:\n",
        "        print(\"Pipeline completed successfully!\")\n",
        "        print(f\"Best model: {results['best_model']}\")\n",
        "        print(f\"Best F1 Score: {results['best_f1_score']:.4f}\")\n",
        "        print(f\"Best AUC Score: {results['best_auc_score']:.4f}\")\n",
        "    else:\n",
        "        print(\"Pipeline failed. Check the error messages above.\")"
      ],
      "metadata": {
        "id": "H7HEQ2LQIs5C",
        "outputId": "49cd7b9d-6a63-491e-aec9-17df5aaa989e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STARTING DUAL-PATH MACHINE LEARNING FRAMEWORK\n",
            "================================================================================\n",
            "Loading and preprocessing data...\n",
            "Loaded dataset with shape: (20000, 52)\n",
            "Class distribution: {0: 19455, 1: 545}\n",
            "Initial dtypes: float64    41\n",
            "int64       5\n",
            "object      4\n",
            "Name: count, dtype: int64\n",
            "Data shape after outlier removal: (3691, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score, matthews_corrcoef,\n",
        "                           confusion_matrix, roc_curve, precision_recall_curve)\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: DATA LOADING AND INITIAL EXPLORATION\n",
        "# =============================================================================\n",
        "# Mount Google Drive (if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset from Google Drive or local path\n",
        "file_path = '/content/drive/My Drive/Insurance/telematics_syn.csv' # For Colab\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Derive the target variable\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "# Display target variable distribution\n",
        "print(\"\\nClaimYN Distribution:\")\n",
        "print(df['ClaimYN'].describe())\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: ENHANCED DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "# Handle missing values (if any)\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "\n",
        "# Handle negative Car.age values (treat as missing and impute with median)\n",
        "if 'Car.age' in X.columns:\n",
        "    car_age_median = X[X['Car.age'] >= 0]['Car.age'].median()\n",
        "    X.loc[X['Car.age'] < 0, 'Car.age'] = car_age_median\n",
        "    print(f\"\\nImputed negative Car.age values with median: {car_age_median}\")\n",
        "\n",
        "# Apply logarithmic transformation to skewed intensity features (handling zeros)\n",
        "intensity_cols = [col for col in X.columns if 'intensity' in col.lower() or 'accel' in col.lower() or 'brake' in col.lower()]\n",
        "for col in intensity_cols:\n",
        "    # Add 1 to handle zeros before log transformation\n",
        "    X[col] = np.log1p(X[col])\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: FEATURE SCALING\n",
        "# =============================================================================\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns) # Convert back to DataFrame for easier handling\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: HANDLE CLASS IMBALANCE WITH SMOTE\n",
        "# =============================================================================\n",
        "# Use SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Display class distribution after SMOTE\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(pd.Series(y_resampled).value_counts())\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: ENHANCED FEATURE SELECTION\n",
        "# =============================================================================\n",
        "def feature_selection(X_train, y_train, top_k=15):\n",
        "    \"\"\"\n",
        "    Perform feature selection using Mutual Information\n",
        "    \"\"\"\n",
        "    selector = SelectKBest(score_func=mutual_info_classif, k=top_k)\n",
        "    selector.fit(X_train, y_train)\n",
        "    selected_feature_indices = selector.get_support(indices=True)\n",
        "    selected_features = X_train.columns[selected_feature_indices]\n",
        "\n",
        "    # Print top features\n",
        "    feature_scores = dict(zip(X_train.columns, selector.scores_))\n",
        "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"\\nTop Features by Mutual Information:\")\n",
        "    for feature, score in sorted_features[:top_k]:\n",
        "        print(f\"{feature}: {score:.4f}\")\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "# Split the resampled data for feature selection\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.3, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Perform feature selection on training data\n",
        "selected_features = feature_selection(X_train_full, y_train_full, top_k=15)\n",
        "\n",
        "# Select features for all sets\n",
        "X_train_selected = X_train_full[selected_features]\n",
        "X_val_selected = X_val[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: ENHANCED MODEL TRAINING WITH HYPERPARAMETER OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Hyperparameter grids\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "nn_param_grid = {\n",
        "    'hidden_layer_sizes': [(50,50), (100,50), (100,100)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# Gradient Boosting with Randomized Search\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "gb_search = RandomizedSearchCV(\n",
        "    gb_classifier,\n",
        "    param_distributions=gb_param_grid,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "gb_search.fit(X_train_selected, y_train_full)\n",
        "gb_best = gb_search.best_estimator_\n",
        "\n",
        "# Neural Network with Randomized Search\n",
        "nn_classifier = MLPClassifier(max_iter=1000, random_state=42)\n",
        "nn_search = RandomizedSearchCV(\n",
        "    nn_classifier,\n",
        "    param_distributions=nn_param_grid,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "nn_search.fit(X_train_selected, y_train_full)\n",
        "nn_best = nn_search.best_estimator_\n",
        "\n",
        "# Print best parameters\n",
        "print(\"\\nBest Gradient Boosting Parameters:\")\n",
        "for param, value in gb_search.best_params_.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "print(\"\\nBest Neural Network Parameters:\")\n",
        "for param, value in nn_search.best_params_.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: DUAL-PATH ENSEMBLE MODEL\n",
        "# =============================================================================\n",
        "# Get predictions from both models\n",
        "gb_pred_proba = gb_best.predict_proba(X_val_selected)[:, 1]\n",
        "nn_pred_proba = nn_best.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "# Calculate accuracies on validation set\n",
        "gb_val_pred = gb_best.predict(X_val_selected)\n",
        "nn_val_pred = nn_best.predict(X_val_selected)\n",
        "acc_gb = accuracy_score(y_val, gb_val_pred)\n",
        "acc_nn = accuracy_score(y_val, nn_val_pred)\n",
        "\n",
        "# Calculate weights based on accuracies\n",
        "w_gb = acc_gb / (acc_gb + acc_nn)\n",
        "w_nn = acc_nn / (acc_gb + acc_nn)\n",
        "\n",
        "print(f\"\\nValidation Accuracies:\")\n",
        "print(f\"GB Accuracy: {acc_gb:.4f}\")\n",
        "print(f\"NN Accuracy: {acc_nn:.4f}\")\n",
        "print(f\"GB Weight: {w_gb:.4f}\")\n",
        "print(f\"NN Weight: {w_nn:.4f}\")\n",
        "\n",
        "# Combine predictions using weighted average\n",
        "ensemble_pred_proba = w_gb * gb_pred_proba + w_nn * nn_pred_proba\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: THRESHOLD OPTIMIZATION\n",
        "# =============================================================================\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Find optimal threshold based on F1 score\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, ensemble_pred_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "f1_scores = np.nan_to_num(f1_scores) # Handle potential division by zero\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
        "print(f\"Max F1 Score at this threshold: {f1_scores[optimal_idx]:.4f}\")\n",
        "\n",
        "# Apply optimal threshold\n",
        "ensemble_predictions = (ensemble_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: COMPREHENSIVE MODEL EVALUATION ON TEST SET\n",
        "# =============================================================================\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
        "    \"\"\"\n",
        "    Evaluate model performance using multiple metrics\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Performance Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "    print(f\"MCC: {mcc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc_roc': auc_roc,\n",
        "        'mcc': mcc\n",
        "    }\n",
        "\n",
        "# Get test set predictions\n",
        "gb_test_pred_proba = gb_best.predict_proba(X_test_selected)[:, 1]\n",
        "nn_test_pred_proba = nn_best.predict_proba(X_test_selected)[:, 1]\n",
        "ensemble_test_pred_proba = w_gb * gb_test_pred_proba + w_nn * nn_test_pred_proba\n",
        "ensemble_test_predictions = (ensemble_test_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# Evaluate all models on test set\n",
        "gb_test_pred = gb_best.predict(X_test_selected)\n",
        "nn_test_pred = nn_best.predict(X_test_selected)\n",
        "\n",
        "gb_results = evaluate_model(y_test, gb_test_pred, gb_test_pred_proba, \"Gradient Boosting\")\n",
        "nn_results = evaluate_model(y_test, nn_test_pred, nn_test_pred_proba, \"Neural Network\")\n",
        "ensemble_results = evaluate_model(y_test, ensemble_test_predictions, ensemble_test_pred_proba, \"Dual-Path Ensemble\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: ADVANCED VISUALIZATION\n",
        "# =============================================================================\n",
        "def visualize_performance(models_data, y_true):\n",
        "    \"\"\"Comprehensive visualization of model performance\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    # Metrics to visualize\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc_roc', 'mcc']\n",
        "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC', 'MCC']\n",
        "\n",
        "    # Bar plots for metrics\n",
        "    for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "        values = [models_data[model][metric] for model in models_data]\n",
        "        axes[i].bar(models_data.keys(), values, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "        axes[i].set_title(f'{name} Comparison')\n",
        "        axes[i].set_ylabel(name)\n",
        "        axes[i].set_ylim(0, 1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for j, v in enumerate(values):\n",
        "            axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curves\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for model_name, data in models_data.items():\n",
        "        fpr, tpr, _ = roc_curve(y_true, data['proba'])\n",
        "        plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {data['auc_roc']:.3f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curves\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for model_name, data in models_data.items():\n",
        "        prec, rec, _ = precision_recall_curve(y_true, data['proba'])\n",
        "        plt.plot(rec, prec, label=f\"{model_name}\")\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrices\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    for i, (model_name, data) in enumerate(models_data.items()):\n",
        "        cm = confusion_matrix(y_true, data['pred'])\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
        "        axes[i].set_title(f'{model_name} Confusion Matrix')\n",
        "        axes[i].set_xlabel('Predicted Label')\n",
        "        axes[i].set_ylabel('True Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Prepare data for visualization\n",
        "models_data = {\n",
        "    'Gradient Boosting': {\n",
        "        'pred': gb_test_pred,\n",
        "        'proba': gb_test_pred_proba,\n",
        "        **gb_results\n",
        "    },\n",
        "    'Neural Network': {\n",
        "        'pred': nn_test_pred,\n",
        "        'proba': nn_test_pred_proba,\n",
        "        **nn_results\n",
        "    },\n",
        "    'Dual-Path Ensemble': {\n",
        "        'pred': ensemble_test_predictions,\n",
        "        'proba': ensemble_test_pred_proba,\n",
        "        **ensemble_results\n",
        "    }\n",
        "}\n",
        "\n",
        "# Generate visualizations\n",
        "visualize_performance(models_data, y_test)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: MODEL INTERPRETABILITY (Feature Importance)\n",
        "# =============================================================================\n",
        "# Display feature importance from Gradient Boosting model\n",
        "feature_importance_gb = pd.DataFrame({\n",
        "    'feature': selected_features,\n",
        "    'importance': gb_best.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop Features by Gradient Boosting Importance:\")\n",
        "print(feature_importance_gb.head(10))\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance_gb.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Feature Importances (Gradient Boosting)')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPipeline execution completed.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AzMUDlG_ItaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93ce9bba-5c04-401c-c76b-165afc8d9efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Duration                100000 non-null  int64  \n",
            " 1   Insured.age             100000 non-null  int64  \n",
            " 2   Insured.sex             100000 non-null  object \n",
            " 3   Car.age                 100000 non-null  int64  \n",
            " 4   Marital                 100000 non-null  object \n",
            " 5   Car.use                 100000 non-null  object \n",
            " 6   Credit.score            100000 non-null  float64\n",
            " 7   Region                  100000 non-null  object \n",
            " 8   Annual.miles.drive      100000 non-null  float64\n",
            " 9   Years.noclaims          100000 non-null  int64  \n",
            " 10  Territory               100000 non-null  int64  \n",
            " 11  Annual.pct.driven       100000 non-null  float64\n",
            " 12  Total.miles.driven      100000 non-null  float64\n",
            " 13  Pct.drive.mon           100000 non-null  float64\n",
            " 14  Pct.drive.tue           100000 non-null  float64\n",
            " 15  Pct.drive.wed           100000 non-null  float64\n",
            " 16  Pct.drive.thr           100000 non-null  float64\n",
            " 17  Pct.drive.fri           100000 non-null  float64\n",
            " 18  Pct.drive.sat           100000 non-null  float64\n",
            " 19  Pct.drive.sun           100000 non-null  float64\n",
            " 20  Pct.drive.2hrs          100000 non-null  float64\n",
            " 21  Pct.drive.3hrs          100000 non-null  float64\n",
            " 22  Pct.drive.4hrs          100000 non-null  float64\n",
            " 23  Pct.drive.wkday         100000 non-null  float64\n",
            " 24  Pct.drive.wkend         100000 non-null  float64\n",
            " 25  Pct.drive.rush am       100000 non-null  float64\n",
            " 26  Pct.drive.rush pm       100000 non-null  float64\n",
            " 27  Avgdays.week            100000 non-null  float64\n",
            " 28  Accel.06miles           100000 non-null  float64\n",
            " 29  Accel.08miles           100000 non-null  float64\n",
            " 30  Accel.09miles           100000 non-null  float64\n",
            " 31  Accel.11miles           100000 non-null  float64\n",
            " 32  Accel.12miles           100000 non-null  float64\n",
            " 33  Accel.14miles           100000 non-null  float64\n",
            " 34  Brake.06miles           100000 non-null  float64\n",
            " 35  Brake.08miles           100000 non-null  float64\n",
            " 36  Brake.09miles           100000 non-null  float64\n",
            " 37  Brake.11miles           100000 non-null  float64\n",
            " 38  Brake.12miles           100000 non-null  float64\n",
            " 39  Brake.14miles           100000 non-null  float64\n",
            " 40  Left.turn.intensity08   100000 non-null  float64\n",
            " 41  Left.turn.intensity09   100000 non-null  float64\n",
            " 42  Left.turn.intensity10   100000 non-null  float64\n",
            " 43  Left.turn.intensity11   100000 non-null  float64\n",
            " 44  Left.turn.intensity12   100000 non-null  float64\n",
            " 45  Right.turn.intensity08  100000 non-null  float64\n",
            " 46  Right.turn.intensity09  100000 non-null  float64\n",
            " 47  Right.turn.intensity10  100000 non-null  float64\n",
            " 48  Right.turn.intensity11  100000 non-null  float64\n",
            " 49  Right.turn.intensity12  100000 non-null  float64\n",
            " 50  NB_Claim                100000 non-null  int64  \n",
            " 51  AMT_Claim               100000 non-null  float64\n",
            "dtypes: float64(42), int64(6), object(4)\n",
            "memory usage: 39.7+ MB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
            "0       366           45        Male       -1  Married  Commute         609.0   \n",
            "1       182           44      Female        3  Married  Commute         575.0   \n",
            "2       184           48      Female        6  Married  Commute         847.0   \n",
            "3       183           71        Male        6  Married  Private         842.0   \n",
            "4       183           84        Male       10  Married  Private         856.0   \n",
            "\n",
            "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
            "0  Urban             6213.71              25  ...                    1.0   \n",
            "1  Urban            12427.42              20  ...                   58.0   \n",
            "2  Urban            12427.42              14  ...                    0.0   \n",
            "3  Urban             6213.71              43  ...                    0.0   \n",
            "4  Urban             6213.71              65  ...                    2.0   \n",
            "\n",
            "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "0                    0.0                    0.0                     3.0   \n",
            "1                   24.0                   11.0                  1099.0   \n",
            "2                    0.0                    0.0                     0.0   \n",
            "3                    0.0                    0.0                     0.0   \n",
            "4                    0.0                    0.0                   325.0   \n",
            "\n",
            "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "0                     1.0                     0.0                     0.0   \n",
            "1                   615.0                   219.0                   101.0   \n",
            "2                     0.0                     0.0                     0.0   \n",
            "3                     0.0                     0.0                     0.0   \n",
            "4                   111.0                    18.0                     4.0   \n",
            "\n",
            "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
            "0                     0.0         1  5100.171753  \n",
            "1                    40.0         1   883.554840  \n",
            "2                     0.0         0     0.000000  \n",
            "3                     0.0         0     0.000000  \n",
            "4                     2.0         0     0.000000  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "\n",
            "ClaimYN Distribution:\n",
            "count    100000.000000\n",
            "mean          0.026980\n",
            "std           0.162026\n",
            "min           0.000000\n",
            "25%           0.000000\n",
            "50%           0.000000\n",
            "75%           0.000000\n",
            "max           1.000000\n",
            "Name: ClaimYN, dtype: float64\n",
            "\n",
            "Imputed negative Car.age values with median: 5.0\n",
            "\n",
            "Class distribution after SMOTE:\n",
            "ClaimYN\n",
            "1    97302\n",
            "0    97302\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top Features by Mutual Information:\n",
            "Credit.score: 0.5676\n",
            "Annual.pct.driven: 0.5572\n",
            "Brake.06miles: 0.5550\n",
            "Accel.06miles: 0.5245\n",
            "Left.turn.intensity08: 0.5093\n",
            "Insured.age: 0.4981\n",
            "Left.turn.intensity09: 0.4939\n",
            "Right.turn.intensity08: 0.4934\n",
            "Years.noclaims: 0.4932\n",
            "Territory: 0.4911\n",
            "Right.turn.intensity09: 0.4880\n",
            "Right.turn.intensity10: 0.4398\n",
            "Left.turn.intensity10: 0.4220\n",
            "Brake.08miles: 0.4011\n",
            "Right.turn.intensity11: 0.3857\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2267542805.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m )\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0mgb_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0mgb_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier  # Faster than MLP\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score, matthews_corrcoef,\n",
        "                           confusion_matrix, roc_curve, precision_recall_curve)\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: DATA LOADING AND INITIAL EXPLORATION\n",
        "# =============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/My Drive/Insurance/telematics_syn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Create target variable\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "print(\"\\nClaimYN Distribution:\")\n",
        "print(df['ClaimYN'].value_counts())\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "# Drop missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "\n",
        "# Fix negative Car.age\n",
        "if 'Car.age' in X.columns:\n",
        "    valid_age = X[X['Car.age'] >= 0]['Car.age']\n",
        "    median_age = valid_age.median()\n",
        "    X.loc[X['Car.age'] < 0, 'Car.age'] = median_age\n",
        "    print(f\"\\nImputed negative Car.age with median: {median_age:.2f}\")\n",
        "\n",
        "# Log-transform intensity/brake/accel features\n",
        "intensity_cols = [col for col in X.columns if 'intensity' in col.lower() or\n",
        "                  'accel' in col.lower() or 'brake' in col.lower()]\n",
        "for col in intensity_cols:\n",
        "    X[col] = np.log1p(X[col])  # log(1 + x)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: FEATURE SCALING\n",
        "# =============================================================================\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: HANDLE CLASS IMBALANCE WITH SMOTE\n",
        "# =============================================================================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(pd.Series(y_resampled).value_counts())\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: FEATURE SELECTION (Top 10 Features)\n",
        "# =============================================================================\n",
        "def feature_selection(X_train, y_train, top_k=10):\n",
        "    selector = SelectKBest(score_func=mutual_info_classif, k=top_k)\n",
        "    selector.fit(X_train, y_train)\n",
        "    selected_features = X_train.columns[selector.get_support()].tolist()\n",
        "\n",
        "    print(\"\\nTop Features by Mutual Information:\")\n",
        "    scores = sorted(zip(X_train.columns, selector.scores_), key=lambda x: x[1], reverse=True)\n",
        "    for feature, score in scores[:top_k]:\n",
        "        print(f\"{feature}: {score:.4f}\")\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "# Split data: 70% train, 15% val, 15% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.15, random_state=42, stratify=y_resampled\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # ~15% val\n",
        ")\n",
        "\n",
        "# Feature selection on training data only\n",
        "selected_features = feature_selection(X_train, y_train, top_k=10)\n",
        "\n",
        "X_train_sel = X_train[selected_features]\n",
        "X_val_sel = X_val[selected_features]\n",
        "X_test_sel = X_test[selected_features]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: MODEL TRAINING WITH OPTIMIZED HYPERPARAMETER SEARCH\n",
        "# =============================================================================\n",
        "\n",
        "# --- Gradient Boosting ---\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_search = RandomizedSearchCV(\n",
        "    gb, gb_param_grid, n_iter=10, cv=3, scoring='roc_auc',\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "gb_search.fit(X_train_sel, y_train)\n",
        "gb_best = gb_search.best_estimator_\n",
        "\n",
        "# --- XGBoost (replaces slow MLP) ---\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'max_depth': [3, 5],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb, xgb_param_grid, n_iter=10, cv=3, scoring='roc_auc',\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "xgb_search.fit(X_train_sel, y_train)\n",
        "xgb_best = xgb_search.best_estimator_\n",
        "\n",
        "# Print best parameters\n",
        "print(\"\\nBest Gradient Boosting Parameters:\")\n",
        "for k, v in gb_search.best_params_.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "print(\"\\nBest XGBoost Parameters:\")\n",
        "for k, v in xgb_search.best_params_.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: DUAL-MODEL ENSEMBLE WITH WEIGHTED AVERAGE\n",
        "# =============================================================================\n",
        "# Predict on validation set\n",
        "gb_val_proba = gb_best.predict_proba(X_val_sel)[:, 1]\n",
        "xgb_val_proba = xgb_best.predict_proba(X_val_sel)[:, 1]\n",
        "\n",
        "# Compute validation accuracy for weighting\n",
        "gb_val_pred = gb_best.predict(X_val_sel)\n",
        "xgb_val_pred = xgb_best.predict(X_val_sel)\n",
        "acc_gb = accuracy_score(y_val, gb_val_pred)\n",
        "acc_xgb = accuracy_score(y_val, xgb_val_pred)\n",
        "\n",
        "# Normalize weights\n",
        "total_acc = acc_gb + acc_xgb\n",
        "w_gb = acc_gb / total_acc\n",
        "w_xgb = acc_xgb / total_acc\n",
        "\n",
        "print(f\"\\nValidation Accuracies:\")\n",
        "print(f\"GB: {acc_gb:.4f} → Weight: {w_gb:.3f}\")\n",
        "print(f\"XGB: {acc_xgb:.4f} → Weight: {w_xgb:.3f}\")\n",
        "\n",
        "# Ensemble prediction (weighted average)\n",
        "ensemble_val_proba = w_gb * gb_val_proba + w_xgb * xgb_val_proba\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: OPTIMAL THRESHOLD SELECTION (Max F1)\n",
        "# =============================================================================\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, ensemble_val_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)  # avoid div by zero\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
        "print(f\"Max F1 Score: {f1_scores[optimal_idx]:.4f}\")\n",
        "\n",
        "ensemble_val_pred = (ensemble_val_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: FINAL EVALUATION ON TEST SET\n",
        "# =============================================================================\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba, name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(f\"  Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall   : {recall:.4f}\")\n",
        "    print(f\"  F1       : {f1:.4f}\")\n",
        "    print(f\"  AUC-ROC  : {auc:.4f}\")\n",
        "    print(f\"  MCC      : {mcc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'pred': y_pred,\n",
        "        'proba': y_pred_proba,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc_roc': auc,\n",
        "        'mcc': mcc\n",
        "    }\n",
        "\n",
        "# Test predictions\n",
        "gb_test_proba = gb_best.predict_proba(X_test_sel)[:, 1]\n",
        "xgb_test_proba = xgb_best.predict_proba(X_test_sel)[:, 1]\n",
        "ensemble_test_proba = w_gb * gb_test_proba + w_xgb * xgb_test_proba\n",
        "ensemble_test_pred = (ensemble_test_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "gb_test_pred = gb_best.predict(X_test_sel)\n",
        "xgb_test_pred = xgb_best.predict(X_test_sel)\n",
        "\n",
        "# Evaluate all\n",
        "gb_results = evaluate_model(y_test, gb_test_pred, gb_test_proba, \"Gradient Boosting\")\n",
        "xgb_results = evaluate_model(y_test, xgb_test_pred, xgb_test_proba, \"XGBoost\")\n",
        "ensemble_results = evaluate_model(y_test, ensemble_test_pred, ensemble_test_proba, \"Ensemble\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: VISUALIZATION\n",
        "# =============================================================================\n",
        "def visualize_performance(models_data, y_true):\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.ravel()\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc_roc', 'mcc']\n",
        "    names = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC-ROC', 'MCC']\n",
        "\n",
        "    for i, (metric, name) in enumerate(zip(metrics, names)):\n",
        "        vals = [models_data[m][metric] for m in models_data]\n",
        "        axes[i].bar(models_data.keys(), vals, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "        axes[i].set_title(name)\n",
        "        axes[i].set_ylim(0, 1)\n",
        "        for j, v in enumerate(vals):\n",
        "            axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, data in models_data.items():\n",
        "        fpr, tpr, _ = roc_curve(y_true, data['proba'])\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={data['auc_roc']:.3f})\")\n",
        "    plt.plot([0,1],[0,1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves'); plt.legend(); plt.grid(True); plt.show()\n",
        "\n",
        "    # Precision-Recall\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, data in models_data.items():\n",
        "        p, r, _ = precision_recall_curve(y_true, data['proba'])\n",
        "        plt.plot(r, p, label=name)\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curves'); plt.legend(); plt.grid(True); plt.show()\n",
        "\n",
        "    # Confusion Matrices\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    for i, (name, data) in enumerate(models_data.items()):\n",
        "        cm = confusion_matrix(y_true, data['pred'])\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
        "        axes[i].set_title(f'{name} Confusion Matrix')\n",
        "        axes[i].set_xlabel('Predicted'); axes[i].set_ylabel('Actual')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# Prepare data\n",
        "models_data = {\n",
        "    'Gradient Boosting': gb_results,\n",
        "    'XGBoost': xgb_results,\n",
        "    'Ensemble': ensemble_results\n",
        "}\n",
        "\n",
        "# Show plots\n",
        "visualize_performance(models_data, y_test)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: FEATURE IMPORTANCE\n",
        "# =============================================================================\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': selected_features,\n",
        "    'importance': gb_best.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Features (Gradient Boosting):\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Pipeline completed successfully.\")"
      ],
      "metadata": {
        "id": "men68p2j96Dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "987d6e93-0631-4a15-c5f4-756f4f227a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Duration                100000 non-null  int64  \n",
            " 1   Insured.age             100000 non-null  int64  \n",
            " 2   Insured.sex             100000 non-null  object \n",
            " 3   Car.age                 100000 non-null  int64  \n",
            " 4   Marital                 100000 non-null  object \n",
            " 5   Car.use                 100000 non-null  object \n",
            " 6   Credit.score            100000 non-null  float64\n",
            " 7   Region                  100000 non-null  object \n",
            " 8   Annual.miles.drive      100000 non-null  float64\n",
            " 9   Years.noclaims          100000 non-null  int64  \n",
            " 10  Territory               100000 non-null  int64  \n",
            " 11  Annual.pct.driven       100000 non-null  float64\n",
            " 12  Total.miles.driven      100000 non-null  float64\n",
            " 13  Pct.drive.mon           100000 non-null  float64\n",
            " 14  Pct.drive.tue           100000 non-null  float64\n",
            " 15  Pct.drive.wed           100000 non-null  float64\n",
            " 16  Pct.drive.thr           100000 non-null  float64\n",
            " 17  Pct.drive.fri           100000 non-null  float64\n",
            " 18  Pct.drive.sat           100000 non-null  float64\n",
            " 19  Pct.drive.sun           100000 non-null  float64\n",
            " 20  Pct.drive.2hrs          100000 non-null  float64\n",
            " 21  Pct.drive.3hrs          100000 non-null  float64\n",
            " 22  Pct.drive.4hrs          100000 non-null  float64\n",
            " 23  Pct.drive.wkday         100000 non-null  float64\n",
            " 24  Pct.drive.wkend         100000 non-null  float64\n",
            " 25  Pct.drive.rush am       100000 non-null  float64\n",
            " 26  Pct.drive.rush pm       100000 non-null  float64\n",
            " 27  Avgdays.week            100000 non-null  float64\n",
            " 28  Accel.06miles           100000 non-null  float64\n",
            " 29  Accel.08miles           100000 non-null  float64\n",
            " 30  Accel.09miles           100000 non-null  float64\n",
            " 31  Accel.11miles           100000 non-null  float64\n",
            " 32  Accel.12miles           100000 non-null  float64\n",
            " 33  Accel.14miles           100000 non-null  float64\n",
            " 34  Brake.06miles           100000 non-null  float64\n",
            " 35  Brake.08miles           100000 non-null  float64\n",
            " 36  Brake.09miles           100000 non-null  float64\n",
            " 37  Brake.11miles           100000 non-null  float64\n",
            " 38  Brake.12miles           100000 non-null  float64\n",
            " 39  Brake.14miles           100000 non-null  float64\n",
            " 40  Left.turn.intensity08   100000 non-null  float64\n",
            " 41  Left.turn.intensity09   100000 non-null  float64\n",
            " 42  Left.turn.intensity10   100000 non-null  float64\n",
            " 43  Left.turn.intensity11   100000 non-null  float64\n",
            " 44  Left.turn.intensity12   100000 non-null  float64\n",
            " 45  Right.turn.intensity08  100000 non-null  float64\n",
            " 46  Right.turn.intensity09  100000 non-null  float64\n",
            " 47  Right.turn.intensity10  100000 non-null  float64\n",
            " 48  Right.turn.intensity11  100000 non-null  float64\n",
            " 49  Right.turn.intensity12  100000 non-null  float64\n",
            " 50  NB_Claim                100000 non-null  int64  \n",
            " 51  AMT_Claim               100000 non-null  float64\n",
            "dtypes: float64(42), int64(6), object(4)\n",
            "memory usage: 39.7+ MB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
            "0       366           45        Male       -1  Married  Commute         609.0   \n",
            "1       182           44      Female        3  Married  Commute         575.0   \n",
            "2       184           48      Female        6  Married  Commute         847.0   \n",
            "3       183           71        Male        6  Married  Private         842.0   \n",
            "4       183           84        Male       10  Married  Private         856.0   \n",
            "\n",
            "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
            "0  Urban             6213.71              25  ...                    1.0   \n",
            "1  Urban            12427.42              20  ...                   58.0   \n",
            "2  Urban            12427.42              14  ...                    0.0   \n",
            "3  Urban             6213.71              43  ...                    0.0   \n",
            "4  Urban             6213.71              65  ...                    2.0   \n",
            "\n",
            "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "0                    0.0                    0.0                     3.0   \n",
            "1                   24.0                   11.0                  1099.0   \n",
            "2                    0.0                    0.0                     0.0   \n",
            "3                    0.0                    0.0                     0.0   \n",
            "4                    0.0                    0.0                   325.0   \n",
            "\n",
            "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "0                     1.0                     0.0                     0.0   \n",
            "1                   615.0                   219.0                   101.0   \n",
            "2                     0.0                     0.0                     0.0   \n",
            "3                     0.0                     0.0                     0.0   \n",
            "4                   111.0                    18.0                     4.0   \n",
            "\n",
            "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
            "0                     0.0         1  5100.171753  \n",
            "1                    40.0         1   883.554840  \n",
            "2                     0.0         0     0.000000  \n",
            "3                     0.0         0     0.000000  \n",
            "4                     2.0         0     0.000000  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "\n",
            "ClaimYN Distribution:\n",
            "ClaimYN\n",
            "0    97302\n",
            "1     2698\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Imputed negative Car.age with median: 5.00\n",
            "\n",
            "Class distribution after SMOTE:\n",
            "ClaimYN\n",
            "1    97302\n",
            "0    97302\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top Features by Mutual Information:\n",
            "Credit.score: 0.5678\n",
            "Annual.pct.driven: 0.5570\n",
            "Brake.06miles: 0.5533\n",
            "Accel.06miles: 0.5249\n",
            "Left.turn.intensity08: 0.5094\n",
            "Insured.age: 0.4970\n",
            "Right.turn.intensity08: 0.4938\n",
            "Left.turn.intensity09: 0.4936\n",
            "Territory: 0.4921\n",
            "Years.noclaims: 0.4917\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-62218659.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m )\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mgb_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0mgb_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier  # Faster than MLP\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score, matthews_corrcoef,\n",
        "                           confusion_matrix, roc_curve, precision_recall_curve)\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: DATA LOADING AND INITIAL EXPLORATION\n",
        "# =============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/My Drive/Insurance/telematics_syn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Create target variable\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "print(\"\\nClaimYN Distribution:\")\n",
        "print(df['ClaimYN'].value_counts())\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "# Drop missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "\n",
        "# Fix negative Car.age\n",
        "if 'Car.age' in X.columns:\n",
        "    valid_age = X[X['Car.age'] >= 0]['Car.age']\n",
        "    median_age = valid_age.median()\n",
        "    X.loc[X['Car.age'] < 0, 'Car.age'] = median_age\n",
        "    print(f\"\\nImputed negative Car.age with median: {median_age:.2f}\")\n",
        "\n",
        "# Log-transform intensity/brake/accel features\n",
        "intensity_cols = [col for col in X.columns if 'intensity' in col.lower() or\n",
        "                  'accel' in col.lower() or 'brake' in col.lower()]\n",
        "for col in intensity_cols:\n",
        "    X[col] = np.log1p(X[col])  # log(1 + x)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: FEATURE SCALING\n",
        "# =============================================================================\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: HANDLE CLASS IMBALANCE WITH SMOTE\n",
        "# =============================================================================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(pd.Series(y_resampled).value_counts())\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: FEATURE SELECTION (Top 10 Features)\n",
        "# =============================================================================\n",
        "def feature_selection(X_train, y_train, top_k=10):\n",
        "    selector = SelectKBest(score_func=mutual_info_classif, k=top_k)\n",
        "    selector.fit(X_train, y_train)\n",
        "    selected_features = X_train.columns[selector.get_support()].tolist()\n",
        "\n",
        "    print(\"\\nTop Features by Mutual Information:\")\n",
        "    scores = sorted(zip(X_train.columns, selector.scores_), key=lambda x: x[1], reverse=True)\n",
        "    for feature, score in scores[:top_k]:\n",
        "        print(f\"{feature}: {score:.4f}\")\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "# Split data: 70% train, 15% val, 15% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.15, random_state=42, stratify=y_resampled\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # ~15% val\n",
        ")\n",
        "\n",
        "# Feature selection on training data only\n",
        "selected_features = feature_selection(X_train, y_train, top_k=10)\n",
        "\n",
        "X_train_sel = X_train[selected_features]\n",
        "X_val_sel = X_val[selected_features]\n",
        "X_test_sel = X_test[selected_features]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: MODEL TRAINING WITH OPTIMIZED HYPERPARAMETER SEARCH\n",
        "# =============================================================================\n",
        "\n",
        "# --- Gradient Boosting ---\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_search = RandomizedSearchCV(\n",
        "    gb, gb_param_grid, n_iter=10, cv=3, scoring='roc_auc',\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "gb_search.fit(X_train_sel, y_train)\n",
        "gb_best = gb_search.best_estimator_\n",
        "\n",
        "# --- XGBoost (replaces slow MLP) ---\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'max_depth': [3, 5],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb, xgb_param_grid, n_iter=10, cv=3, scoring='roc_auc',\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "xgb_search.fit(X_train_sel, y_train)\n",
        "xgb_best = xgb_search.best_estimator_\n",
        "\n",
        "# Print best parameters\n",
        "print(\"\\nBest Gradient Boosting Parameters:\")\n",
        "for k, v in gb_search.best_params_.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "print(\"\\nBest XGBoost Parameters:\")\n",
        "for k, v in xgb_search.best_params_.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: DUAL-MODEL ENSEMBLE WITH WEIGHTED AVERAGE\n",
        "# =============================================================================\n",
        "# Predict on validation set\n",
        "gb_val_proba = gb_best.predict_proba(X_val_sel)[:, 1]\n",
        "xgb_val_proba = xgb_best.predict_proba(X_val_sel)[:, 1]\n",
        "\n",
        "# Compute validation accuracy for weighting\n",
        "gb_val_pred = gb_best.predict(X_val_sel)\n",
        "xgb_val_pred = xgb_best.predict(X_val_sel)\n",
        "acc_gb = accuracy_score(y_val, gb_val_pred)\n",
        "acc_xgb = accuracy_score(y_val, xgb_val_pred)\n",
        "\n",
        "# Normalize weights\n",
        "total_acc = acc_gb + acc_xgb\n",
        "w_gb = acc_gb / total_acc\n",
        "w_xgb = acc_xgb / total_acc\n",
        "\n",
        "print(f\"\\nValidation Accuracies:\")\n",
        "print(f\"GB: {acc_gb:.4f} → Weight: {w_gb:.3f}\")\n",
        "print(f\"XGB: {acc_xgb:.4f} → Weight: {w_xgb:.3f}\")\n",
        "\n",
        "# Ensemble prediction (weighted average)\n",
        "ensemble_val_proba = w_gb * gb_val_proba + w_xgb * xgb_val_proba\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: OPTIMAL THRESHOLD SELECTION (Max F1)\n",
        "# =============================================================================\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, ensemble_val_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)  # avoid div by zero\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
        "print(f\"Max F1 Score: {f1_scores[optimal_idx]:.4f}\")\n",
        "\n",
        "ensemble_val_pred = (ensemble_val_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: FINAL EVALUATION ON TEST SET\n",
        "# =============================================================================\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba, name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(f\"  Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall   : {recall:.4f}\")\n",
        "    print(f\"  F1       : {f1:.4f}\")\n",
        "    print(f\"  AUC-ROC  : {auc:.4f}\")\n",
        "    print(f\"  MCC      : {mcc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'pred': y_pred,\n",
        "        'proba': y_pred_proba,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc_roc': auc,\n",
        "        'mcc': mcc\n",
        "    }\n",
        "\n",
        "# Test predictions\n",
        "gb_test_proba = gb_best.predict_proba(X_test_sel)[:, 1]\n",
        "xgb_test_proba = xgb_best.predict_proba(X_test_sel)[:, 1]\n",
        "ensemble_test_proba = w_gb * gb_test_proba + w_xgb * xgb_test_proba\n",
        "ensemble_test_pred = (ensemble_test_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "gb_test_pred = gb_best.predict(X_test_sel)\n",
        "xgb_test_pred = xgb_best.predict(X_test_sel)\n",
        "\n",
        "# Evaluate all\n",
        "gb_results = evaluate_model(y_test, gb_test_pred, gb_test_proba, \"Gradient Boosting\")\n",
        "xgb_results = evaluate_model(y_test, xgb_test_pred, xgb_test_proba, \"XGBoost\")\n",
        "ensemble_results = evaluate_model(y_test, ensemble_test_pred, ensemble_test_proba, \"Ensemble\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 11: VISUALIZATION\n",
        "# =============================================================================\n",
        "def visualize_performance(models_data, y_true):\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.ravel()\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc_roc', 'mcc']\n",
        "    names = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC-ROC', 'MCC']\n",
        "\n",
        "    for i, (metric, name) in enumerate(zip(metrics, names)):\n",
        "        vals = [models_data[m][metric] for m in models_data]\n",
        "        axes[i].bar(models_data.keys(), vals, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "        axes[i].set_title(name)\n",
        "        axes[i].set_ylim(0, 1)\n",
        "        for j, v in enumerate(vals):\n",
        "            axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, data in models_data.items():\n",
        "        fpr, tpr, _ = roc_curve(y_true, data['proba'])\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={data['auc_roc']:.3f})\")\n",
        "    plt.plot([0,1],[0,1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves'); plt.legend(); plt.grid(True); plt.show()\n",
        "\n",
        "    # Precision-Recall\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, data in models_data.items():\n",
        "        p, r, _ = precision_recall_curve(y_true, data['proba'])\n",
        "        plt.plot(r, p, label=name)\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curves'); plt.legend(); plt.grid(True); plt.show()\n",
        "\n",
        "    # Confusion Matrices\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    for i, (name, data) in enumerate(models_data.items()):\n",
        "        cm = confusion_matrix(y_true, data['pred'])\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
        "        axes[i].set_title(f'{name} Confusion Matrix')\n",
        "        axes[i].set_xlabel('Predicted'); axes[i].set_ylabel('Actual')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# Prepare data\n",
        "models_data = {\n",
        "    'Gradient Boosting': gb_results,\n",
        "    'XGBoost': xgb_results,\n",
        "    'Ensemble': ensemble_results\n",
        "}\n",
        "\n",
        "# Show plots\n",
        "visualize_performance(models_data, y_test)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 12: FEATURE IMPORTANCE\n",
        "# =============================================================================\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': selected_features,\n",
        "    'importance': gb_best.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Features (Gradient Boosting):\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Pipeline completed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UXCqmawyOTwA",
        "outputId": "2da29d2c-903c-4f30-8c93-b7caac57797b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Duration                100000 non-null  int64  \n",
            " 1   Insured.age             100000 non-null  int64  \n",
            " 2   Insured.sex             100000 non-null  object \n",
            " 3   Car.age                 100000 non-null  int64  \n",
            " 4   Marital                 100000 non-null  object \n",
            " 5   Car.use                 100000 non-null  object \n",
            " 6   Credit.score            100000 non-null  float64\n",
            " 7   Region                  100000 non-null  object \n",
            " 8   Annual.miles.drive      100000 non-null  float64\n",
            " 9   Years.noclaims          100000 non-null  int64  \n",
            " 10  Territory               100000 non-null  int64  \n",
            " 11  Annual.pct.driven       100000 non-null  float64\n",
            " 12  Total.miles.driven      100000 non-null  float64\n",
            " 13  Pct.drive.mon           100000 non-null  float64\n",
            " 14  Pct.drive.tue           100000 non-null  float64\n",
            " 15  Pct.drive.wed           100000 non-null  float64\n",
            " 16  Pct.drive.thr           100000 non-null  float64\n",
            " 17  Pct.drive.fri           100000 non-null  float64\n",
            " 18  Pct.drive.sat           100000 non-null  float64\n",
            " 19  Pct.drive.sun           100000 non-null  float64\n",
            " 20  Pct.drive.2hrs          100000 non-null  float64\n",
            " 21  Pct.drive.3hrs          100000 non-null  float64\n",
            " 22  Pct.drive.4hrs          100000 non-null  float64\n",
            " 23  Pct.drive.wkday         100000 non-null  float64\n",
            " 24  Pct.drive.wkend         100000 non-null  float64\n",
            " 25  Pct.drive.rush am       100000 non-null  float64\n",
            " 26  Pct.drive.rush pm       100000 non-null  float64\n",
            " 27  Avgdays.week            100000 non-null  float64\n",
            " 28  Accel.06miles           100000 non-null  float64\n",
            " 29  Accel.08miles           100000 non-null  float64\n",
            " 30  Accel.09miles           100000 non-null  float64\n",
            " 31  Accel.11miles           100000 non-null  float64\n",
            " 32  Accel.12miles           100000 non-null  float64\n",
            " 33  Accel.14miles           100000 non-null  float64\n",
            " 34  Brake.06miles           100000 non-null  float64\n",
            " 35  Brake.08miles           100000 non-null  float64\n",
            " 36  Brake.09miles           100000 non-null  float64\n",
            " 37  Brake.11miles           100000 non-null  float64\n",
            " 38  Brake.12miles           100000 non-null  float64\n",
            " 39  Brake.14miles           100000 non-null  float64\n",
            " 40  Left.turn.intensity08   100000 non-null  float64\n",
            " 41  Left.turn.intensity09   100000 non-null  float64\n",
            " 42  Left.turn.intensity10   100000 non-null  float64\n",
            " 43  Left.turn.intensity11   100000 non-null  float64\n",
            " 44  Left.turn.intensity12   100000 non-null  float64\n",
            " 45  Right.turn.intensity08  100000 non-null  float64\n",
            " 46  Right.turn.intensity09  100000 non-null  float64\n",
            " 47  Right.turn.intensity10  100000 non-null  float64\n",
            " 48  Right.turn.intensity11  100000 non-null  float64\n",
            " 49  Right.turn.intensity12  100000 non-null  float64\n",
            " 50  NB_Claim                100000 non-null  int64  \n",
            " 51  AMT_Claim               100000 non-null  float64\n",
            "dtypes: float64(42), int64(6), object(4)\n",
            "memory usage: 39.7+ MB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
            "0       366           45        Male       -1  Married  Commute         609.0   \n",
            "1       182           44      Female        3  Married  Commute         575.0   \n",
            "2       184           48      Female        6  Married  Commute         847.0   \n",
            "3       183           71        Male        6  Married  Private         842.0   \n",
            "4       183           84        Male       10  Married  Private         856.0   \n",
            "\n",
            "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
            "0  Urban             6213.71              25  ...                    1.0   \n",
            "1  Urban            12427.42              20  ...                   58.0   \n",
            "2  Urban            12427.42              14  ...                    0.0   \n",
            "3  Urban             6213.71              43  ...                    0.0   \n",
            "4  Urban             6213.71              65  ...                    2.0   \n",
            "\n",
            "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "0                    0.0                    0.0                     3.0   \n",
            "1                   24.0                   11.0                  1099.0   \n",
            "2                    0.0                    0.0                     0.0   \n",
            "3                    0.0                    0.0                     0.0   \n",
            "4                    0.0                    0.0                   325.0   \n",
            "\n",
            "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "0                     1.0                     0.0                     0.0   \n",
            "1                   615.0                   219.0                   101.0   \n",
            "2                     0.0                     0.0                     0.0   \n",
            "3                     0.0                     0.0                     0.0   \n",
            "4                   111.0                    18.0                     4.0   \n",
            "\n",
            "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
            "0                     0.0         1  5100.171753  \n",
            "1                    40.0         1   883.554840  \n",
            "2                     0.0         0     0.000000  \n",
            "3                     0.0         0     0.000000  \n",
            "4                     2.0         0     0.000000  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "\n",
            "ClaimYN Distribution:\n",
            "ClaimYN\n",
            "0    97302\n",
            "1     2698\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Imputed negative Car.age with median: 5.00\n",
            "\n",
            "Class distribution after SMOTE:\n",
            "ClaimYN\n",
            "1    97302\n",
            "0    97302\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top Features by Mutual Information:\n",
            "Credit.score: 0.5670\n",
            "Annual.pct.driven: 0.5571\n",
            "Brake.06miles: 0.5528\n",
            "Accel.06miles: 0.5245\n",
            "Left.turn.intensity08: 0.5095\n",
            "Insured.age: 0.4969\n",
            "Right.turn.intensity08: 0.4936\n",
            "Left.turn.intensity09: 0.4927\n",
            "Years.noclaims: 0.4921\n",
            "Territory: 0.4905\n",
            "\n",
            "Best Gradient Boosting Parameters:\n",
            "  n_estimators: 200\n",
            "  min_samples_split: 5\n",
            "  min_samples_leaf: 1\n",
            "  max_depth: 5\n",
            "  learning_rate: 0.2\n",
            "\n",
            "Best XGBoost Parameters:\n",
            "  subsample: 0.8\n",
            "  n_estimators: 200\n",
            "  max_depth: 5\n",
            "  learning_rate: 0.2\n",
            "  colsample_bytree: 1.0\n",
            "\n",
            "Validation Accuracies:\n",
            "GB: 0.9786 → Weight: 0.505\n",
            "XGB: 0.9589 → Weight: 0.495\n",
            "\n",
            "Optimal Threshold: 0.5149\n",
            "Max F1 Score: 0.9779\n",
            "\n",
            "Gradient Boosting Performance:\n",
            "  Accuracy : 0.9813\n",
            "  Precision: 0.9911\n",
            "  Recall   : 0.9714\n",
            "  F1       : 0.9811\n",
            "  AUC-ROC  : 0.9959\n",
            "  MCC      : 0.9629\n",
            "\n",
            "XGBoost Performance:\n",
            "  Accuracy : 0.9594\n",
            "  Precision: 0.9631\n",
            "  Recall   : 0.9553\n",
            "  F1       : 0.9592\n",
            "  AUC-ROC  : 0.9926\n",
            "  MCC      : 0.9188\n",
            "\n",
            "Ensemble Performance:\n",
            "  Accuracy : 0.9798\n",
            "  Precision: 0.9877\n",
            "  Recall   : 0.9716\n",
            "  F1       : 0.9796\n",
            "  AUC-ROC  : 0.9963\n",
            "  MCC      : 0.9596\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1200 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAc5RJREFUeJzt3Xd4FOXexvF7drNpJCEQSAEioXdBQXgBFVQ6otjgKCqgYAGOBVHBhmIBPIhwjihWUI8Kio0jSBHFAiiKYKV3kdAEEhKSbJn3jyUb1iQkmzZZ+H6uK+/OzE757eZ5Pbl5nnnGME3TFAAAAACgUDarCwAAAACAyo7gBAAAAABFIDgBAAAAQBEITgAAAABQBIITAAAAABSB4AQAAAAARSA4AQAAAEARCE4AAAAAUASCEwAAAAAUgeAEAPAZMmSIUlJSAjpm+fLlMgxDy5cvL5eagl3Xrl3VtWtX3/qOHTtkGIZmz55tWU0AgMARnADAQrNnz5ZhGL6f8PBwNW7cWKNGjdK+ffusLq/Syw0huT82m03Vq1dX7969tWrVKqvLKxP79u3TmDFj1LRpU0VGRqpKlSpq27atnnjiCR05csTq8gDgjBFidQEAAGnChAmqV6+esrKy9M033+iFF17QwoUL9euvvyoyMrLC6nj55Zfl8XgCOubCCy/U8ePHFRoaWk5VFe3aa69Vnz595Ha7tWnTJj3//PO66KKL9P3336tVq1aW1VVa33//vfr06aNjx47p+uuvV9u2bSVJP/zwgyZNmqSvvvpKS5YssbhKADgzEJwAoBLo3bu32rVrJ0kaNmyY4uLiNHXqVH388ce69tprCzwmIyNDVapUKdM6HA5HwMfYbDaFh4eXaR2BOvfcc3X99df71i+44AL17t1bL7zwgp5//nkLKyu5I0eO6IorrpDdbtfatWvVtGlTv/effPJJvfzyy2VyrfJoSwBwumGoHgBUQhdffLEkafv27ZK89x5FRUVp69at6tOnj6KjozVo0CBJksfj0bRp09SiRQuFh4crISFBt956qw4fPpzvvJ9++qm6dOmi6OhoxcTE6LzzztPbb7/te7+ge5zmzJmjtm3b+o5p1aqVpk+f7nu/sHuc3nvvPbVt21YRERGqUaOGrr/+eu3Zs8dvn9zPtWfPHvXv319RUVGqWbOmxowZI7fbXeLv74ILLpAkbd261W/7kSNHdNdddyk5OVlhYWFq2LChJk+enK+XzePxaPr06WrVqpXCw8NVs2ZN9erVSz/88INvn1mzZuniiy9WfHy8wsLC1Lx5c73wwgslrvnvXnzxRe3Zs0dTp07NF5okKSEhQQ899JBv3TAMPfroo/n2S0lJ0ZAhQ3zrucNDv/zyS40YMULx8fGqU6eO5s2b59teUC2GYejXX3/1bduwYYOuvvpqVa9eXeHh4WrXrp3mz5/vd5zT6dRjjz2mRo0aKTw8XHFxcTr//PO1dOnSEnwjAGAtepwAoBLK/YM/Li7Ot83lcqlnz546//zzNWXKFN8QvltvvVWzZ8/W0KFDdccdd2j79u167rnntHbtWq1YscLXizR79mzddNNNatGihcaNG6fY2FitXbtWixYt0nXXXVdgHUuXLtW1116rSy65RJMnT5YkrV+/XitWrNCdd95ZaP259Zx33nmaOHGi9u3bp+nTp2vFihVau3atYmNjffu63W717NlTHTp00JQpU/TZZ5/pmWeeUYMGDXT77beX6PvbsWOHJKlatWq+bZmZmerSpYv27NmjW2+9VWeddZZWrlypcePGae/evZo2bZpv35tvvlmzZ89W7969NWzYMLlcLn399df69ttvfT2DL7zwglq0aKHLLrtMISEh+t///qcRI0bI4/Fo5MiRJar7ZPPnz1dERISuvvrqUp+rICNGjFDNmjX1yCOPKCMjQ3379lVUVJTeffdddenSxW/fuXPnqkWLFmrZsqUk6bffflPnzp1Vu3ZtjR07VlWqVNG7776r/v376/3339cVV1whSXr00Uc1ceJEDRs2TO3bt1daWpp++OEH/fjjj+revXu5fC4AKDcmAMAys2bNMiWZn332mXngwAFz9+7d5pw5c8y4uDgzIiLC/OOPP0zTNM3BgwebksyxY8f6Hf/111+bksy33nrLb/uiRYv8th85csSMjo42O3ToYB4/ftxvX4/H41sePHiwWbduXd/6nXfeacbExJgul6vQz/DFF1+YkswvvvjCNE3TzMnJMePj482WLVv6XeuTTz4xJZmPPPKI3/UkmRMmTPA75znnnGO2bdu20Gvm2r59uynJfOyxx8wDBw6Yqamp5tdff22ed955piTzvffe8+37+OOPm1WqVDE3bdrkd46xY8eadrvd3LVrl2mapvn555+bksw77rgj3/VO/q4yMzPzvd+zZ0+zfv36ftu6dOlidunSJV/Ns2bNOuVnq1atmtm6detT7nMySeb48ePzba9bt645ePBg33pumzv//PPz/V6vvfZaMz4+3m/73r17TZvN5vc7uuSSS8xWrVqZWVlZvm0ej8fs1KmT2ahRI9+21q1bm3379i32ZwCAyoyhegBQCXTr1k01a9ZUcnKy/vGPfygqKkoffvihateu7bff33tg3nvvPVWtWlXdu3fXwYMHfT9t27ZVVFSUvvjiC0nenqP09HSNHTs23/1IhmEUWldsbKwyMjICGlr1ww8/aP/+/RoxYoTftfr27aumTZtqwYIF+Y657bbb/NYvuOACbdu2rdjXHD9+vGrWrKnExERdcMEFWr9+vZ555hm/3pr33ntPF1xwgapVq+b3XXXr1k1ut1tfffWVJOn999+XYRgaP358vuuc/F1FRET4lo8ePaqDBw+qS5cu2rZtm44ePVrs2guTlpam6OjoUp+nMMOHD5fdbvfbNnDgQO3fv99v2OW8efPk8Xg0cOBASdJff/2lzz//XAMGDFB6errvezx06JB69uypzZs3+4ZkxsbG6rffftPmzZvL7XMAQEVhqB4AVAIzZsxQ48aNFRISooSEBDVp0kQ2m/+/bYWEhKhOnTp+2zZv3qyjR48qPj6+wPPu379fUt7Qv9yhVsU1YsQIvfvuu+rdu7dq166tHj16aMCAAerVq1ehx+zcuVOS1KRJk3zvNW3aVN98843fttx7iE5WrVo1v3u0Dhw44HfPU1RUlKKionzrt9xyi6655hplZWXp888/17///e9890ht3rxZP//8c75r5Tr5u6pVq5aqV69e6GeUpBUrVmj8+PFatWqVMjMz/d47evSoqlatesrjixITE6P09PRSneNU6tWrl29br169VLVqVc2dO1eXXHKJJO8wvTZt2qhx48aSpC1btsg0TT388MN6+OGHCzz3/v37Vbt2bU2YMEGXX365GjdurJYtW6pXr1664YYbdPbZZ5fb5wKA8kJwAoBKoH379r57ZwoTFhaWL0x5PB7Fx8frrbfeKvCYwkJCccXHx2vdunVavHixPv30U3366aeaNWuWbrzxRr3++uulOneuv/d6FOS8887zBTLJ28N08kQIjRo1Urdu3SRJl156qex2u8aOHauLLrrI9716PB51795d9913X4HXyA0GxbF161Zdcsklatq0qaZOnark5GSFhoZq4cKFevbZZwOe0r0gTZs21bp165STk1Oqqd4Lm2Tj5B6zXGFhYerfv78+/PBDPf/889q3b59WrFihp556yrdP7mcbM2aMevbsWeC5GzZsKMk7Vf3WrVv18ccfa8mSJXrllVf07LPPaubMmRo2bFiJPxMAWIHgBABBrEGDBvrss8/UuXPnAv8QPnk/Sfr11199f9QWV2hoqPr166d+/frJ4/FoxIgRevHFF/Xwww8XeK66detKkjZu3OibHTDXxo0bfe8H4q233tLx48d96/Xr1z/l/g8++KBefvllPfTQQ1q0aJEk73dw7NgxX8AqTIMGDbR48WL99ddfhfY6/e9//1N2drbmz5+vs846y7c9d2hkWejXr59WrVql999/v9Ap6U9WrVq1fA/EzcnJ0d69ewO67sCBA/X6669r2bJlWr9+vUzT9A3Tk/K+e4fDUeR3KUnVq1fX0KFDNXToUB07dkwXXnihHn30UYITgKDDPU4AEMQGDBggt9utxx9/PN97LpfL94d0jx49FB0drYkTJyorK8tvP9M0Cz3/oUOH/NZtNptvmFV2dnaBx7Rr107x8fGaOXOm3z6ffvqp1q9fr759+xbrs52sc+fO6tatm++nqOAUGxurW2+9VYsXL9a6deskeb+rVatWafHixfn2P3LkiFwulyTpqquukmmaeuyxx/Ltl/td5faSnfzdHT16VLNmzQr4sxXmtttuU1JSku655x5t2rQp3/v79+/XE0884Vtv0KCB7z6tXC+99FLA07p369ZN1atX19y5czV37ly1b9/eb1hffHy8unbtqhdffLHAUHbgwAHf8t/bT1RUlBo2bFho2wGAyoweJwAIYl26dNGtt96qiRMnat26derRo4ccDoc2b96s9957T9OnT9fVV1+tmJgYPfvssxo2bJjOO+88XXfddapWrZp++uknZWZmFjrsbtiwYfrrr7908cUXq06dOtq5c6f+85//qE2bNmrWrFmBxzgcDk2ePFlDhw5Vly5ddO211/qmI09JSdHdd99dnl+Jz5133qlp06Zp0qRJmjNnju69917Nnz9fl156qYYMGaK2bdsqIyNDv/zyi+bNm6cdO3aoRo0auuiii3TDDTfo3//+tzZv3qxevXrJ4/Ho66+/1kUXXaRRo0apR48evp64W2+9VceOHdPLL7+s+Pj4gHt4ClOtWjV9+OGH6tOnj9q0aaPrr79ebdu2lST9+OOPeuedd9SxY0ff/sOGDdNtt92mq666St27d9dPP/2kxYsXq0aNGgFd1+Fw6Morr9ScOXOUkZGhKVOm5NtnxowZOv/889WqVSsNHz5c9evX1759+7Rq1Sr98ccf+umnnyRJzZs3V9euXdW2bVtVr15dP/zwg+bNm6dRo0aV4psBAItYOaUfAJzpcqeG/v7770+53+DBg80qVaoU+v5LL71ktm3b1oyIiDCjo6PNVq1amffdd5/5559/+u03f/58s1OnTmZERIQZExNjtm/f3nznnXf8rnPydOTz5s0ze/ToYcbHx5uhoaHmWWedZd56663m3r17ffv8fTryXHPnzjXPOeccMywszKxevbo5aNAg3/TqRX2u8ePHm8X5n6jcqb3/9a9/Ffj+kCFDTLvdbm7ZssU0TdNMT083x40bZzZs2NAMDQ01a9SoYXbq1MmcMmWKmZOT4zvO5XKZ//rXv8ymTZuaoaGhZs2aNc3evXuba9as8fsuzz77bDM8PNxMSUkxJ0+ebL722mumJHP79u2+/Uo6HXmuP//807z77rvNxo0bm+Hh4WZkZKTZtm1b88knnzSPHj3q28/tdpv333+/WaNGDTMyMtLs2bOnuWXLlkKnIz9Vm1u6dKkpyTQMw9y9e3eB+2zdutW88cYbzcTERNPhcJi1a9c2L730UnPevHm+fZ544gmzffv2ZmxsrBkREWE2bdrUfPLJJ/2+awAIFoZpnmKMBgAAAACAe5wAAAAAoCgEJwAAAAAoAsEJAAAAAIpAcAIAAACAIhCcAAAAAKAIBCcAAAAAKMIZ9wBcj8ejP//8U9HR0TIMw+pyAAAAAFjENE2lp6erVq1astlO3ad0xgWnP//8U8nJyVaXAQAAAKCS2L17t+rUqXPKfc644BQdHS3J++XExMRYXI3kdDq1ZMkS9ejRQw6Hw+pyUMnRXhAo2gwCRZtBoGgzCFRlajNpaWlKTk72ZYRTOeOCU+7wvJiYmEoTnCIjIxUTE2N5w0HlR3tBoGgzCBRtBoGizSBQlbHNFOcWHiaHAAAAAIAiEJwAAAAAoAgEJwAAAAAoAsEJAAAAAIpAcAIAAACAIhCcAAAAAKAIBCcAAAAAKALBCQAAAACKQHACAAAAgCIQnAAAAACgCAQnAAAAACgCwQkAAAAAikBwAgAAAIAiEJwAAAAAoAiWBqevvvpK/fr1U61atWQYhj766KMij1m+fLnOPfdchYWFqWHDhpo9e3a51wkAAADgzGZpcMrIyFDr1q01Y8aMYu2/fft29e3bVxdddJHWrVunu+66S8OGDdPixYvLuVIAAAAAZ7IQKy/eu3dv9e7du9j7z5w5U/Xq1dMzzzwjSWrWrJm++eYbPfvss+rZs2d5lVlulv/woTbs/l779u3T3k++k81mWF0SKjmPx6S9lBND5ft9lv9vq+AreDwe7du3T/s+WS2breT/VlZe9bs9pmIjQmUUcQGzqAqKOEHpf79FnL+I6xdZf1FXN0r775zF//48Ho92Htip7OUbi99mivoFFvn5i/H9FHINo4ClgphF1ljIZU+c1x0WKxnGid+lIRk2b02GIVM2SYY8odHF+C7yX6E8lfd/ewzDkNvt1q/pW3Xsty9kt9vL+gplfL48dsOuyJAqkgwZhuH7XRsn1k8sebf+7X1JigiJlMMWJsMwZJPNdw7v8baTzpOfx/T+t89mk2yGceLH+3Fz10NDbKoSai/yvy+oOJYGp0CtWrVK3bp189vWs2dP3XXXXYUek52drezsbN96WlqaJMnpdMrpdJZLncX1v3UvaYnjDylCUpqlpSCY0F4QqMreZipzbWcqh6Q/rS4CweaTn6yuoPIxTUOmK0Y2x1G5s2pJZu4/RhiSmRfEDXnkcVaTJztRpmmTYc+WJztBkkemq5o3mJnRsslQtlOKCgtRTHio7Dab7GaUth/M0nkp1WQ3JJvNG97+PHJc55wVK4fd0IH0HNWNi9RlZyepRa1oy8NY7t/gVv8tHmgNQRWcUlNTlZCQ4LctISFBaWlpOn78uCIiIvIdM3HiRD322GP5ti9ZskSRkZHlVmtxOLIj1djNvyIApzszyM9fXv/g6yn3witKOX+QcvyfieJUXvTlCz9L2Zy/JFcuO6FyypTkkU3GSVc0TqqgpJ+h3P/bUM5/YpS0flOGcuRQqFzKVJivR9Yhl7IUJo8MeUybcgy73LL7jpEk94nePdN3Lu/vJrDfgimF7pdc0f6fxDj5rKb/ezJPXOLEui2nWFcyDFOG46gkyR5+6n+NsGuXpKLTp+PE68n/5hRdU1rvjpBp2iTTLtMTJndII+3ekiL38RSZrhhJ0qyVO33HpESZigs3lRhhqlOCqSiHKtzSpUsr/qJ/k5mZWex9gyo4lcS4ceM0evRo33paWpqSk5PVo0cPxcTEWFiZ1Ed95HQ6tXTpUnXv3l0OhwUtFkGF9oJA0WYQKNpMCblzpKyjknlynDixbP7tj3Dzb+8Xut/f/3gvZB/TIyPjgGSzn3jfuy1vOfdVeeumR5Ip4/AOmY5IyZ0j2961MqMSJI9HMt2S6ZZx/Ij011YppvaJc544r+n2Xnf7V/LUaKK0o4dVNaqKDJky9v9Wwi+xdMzq9SWbQ8bBjfLU6yojbY/MpNYyQ6NkZByUWa+L5HHLc/ZAKSy6yPMVJcedI1OmPKZHpmnKoxOvpkce06PD2YflNt36K+svuT1umTLz7yePth7Zql8P/aqEyAS5PC79sO8HnRV9ltYeWKtqYXHam7lHkhRhj5DnpOu5TZfMk8O8/bhffLSHHZCqr/Stu7Pj5T7WRM70lvJk1dKOYw7tOOY9YsFuKTLUruZJ0erWLF43d04p9fdzKpXpvzO5o9GKI6iCU2Jiovbt2+e3bd++fYqJiSmwt0mSwsLCFBYWlm+7w+Gw/Bd1sspWDyo32gsCRZtBoGgzAXI4pPAqFhbQzLIre5xOfbVwofr06ZPXZjweKedYXtjyuL3h8tBm7/KhrZIj3LvscUkHN0uOE3/Lpf0p/fKuFNfQ+77plo7s8r5nDzspwLn96jD+2uZbtm1f7t12aHPeDhs/8Z5iydgT5wqV6rSXstOkswdI0Ukn7lEzJJlSVKJ01v95A2kBivr/j/jo+CK/u9Jye9w6nH1Y+zP3y+lxau+xvfrl4C/am7FXPx34Sfsz9/v2tYftlz1sv0LjvvZtC8lpoLS9F8ud2UCZOW79sPOIfth5RJMWbdL2iX3KfUhfZfjvTCDXD6rg1LFjRy1cuNBv29KlS9WxY0eLKgIAAEA+NpsUXsDInqq1va8NLzn18Ve9XLzrOLOkQ1sk53FvAEvf6w1Vf233vm8Y0q5vpdBI6feP/Y9150g7v/Eup/5c9LWufFmq3kCKbyqFWhmS89htdtWIqKEaETUkSa1rtlaver1873tMj7764yt9uPlDfb7783zHu0K3KrLuVklS52qDtWhlXgCvN26hfnm0h6LD+QeUXJYGp2PHjmnLli2+9e3bt2vdunWqXr26zjrrLI0bN0579uzRG2+8IUm67bbb9Nxzz+m+++7TTTfdpM8//1zvvvuuFixYYNVHAAAAgFUc4VJiy8COObJb2vuTNzh9+bTkOi5VS8kbhpi+1xvG/u6D4f7riWdLdodUo4nkzJDOuUGq29kb0ioJm2FT1+Su6prc1bfNY3q0ZMcSPf390zpw/IBv+4rDryu6mRRvdtfWDV0l2dXq0SWKDg/R2oe7K8Ru6VOMKgVLg9MPP/ygiy66yLeeey/S4MGDNXv2bO3du1e7du3yvV+vXj0tWLBAd999t6ZPn646derolVdeCcqpyAEAAGCB2GTvjyS1vLLw/VzZ0u7vpKWPSH+ularXl04aDujrpdqzxvt6co/WRQ9JMUlSfHOpah2pSs0STFVfPmyGTb3q9fL1TP1v6//0wDcP+N7fbyxVdLOlcmXW1fGdtys9y6WGD36qHZP6WlVypWFpcOratatMv5so/c2ePbvAY9auXVuOVQEAAOCMFxIm1btQumV53jZnlvc+rZwMaedK6fhh6ed3pWOp/sd+8UT+88XWlVr/Q2p9rbeHq5IEqX4N+qlfg35avGOxJqyaoLQc72QJIZE7FVl3pjJ33irJUMrYBRVy31NlFlT3OAEAAACWcYRLia28y2f9n/e1x+PeV9OU1v7X2zu19ydpzw/+xx7ZKX052fsjecNTeKzUuKfUZaz3vjAL9UzpqZ4pPbXp8CZdNf8qSZI9coeim41T+vonJdlVb9zCM7rnicGKAAAAQGkZhnTuDdKlU6Xhy6RHj3p/RnwrJbTKv//hHdLedd4gNaGatOQhKeNQRVedT+NqjbXi2hV+26KbPSh7pHeY4pb96VaUVSkQnAAAAIDyEt9Muv2bvCD10H7pnz9Kba7332/lf6R/1ZeerCVt/syaWk+ICY3Rzzf+rKQqSb5tkXVfkhFyRN2mfnXKW21OZwQnAAAAoKKEhElxDaT+M7xBatjfpgl3ZkhvXSU9WlX6vIB7pSqIYRhacvUSPd75cd+2qEaTJCNHyzcdOMWRpy+CEwAAAGCVOm3zeqN6P+3/3lf/8gao716ypjZJ/Rv21z1t7/GtRzd9RGPfL8Zzr05DBCcAAACgMuhwqzdA3Tjff/un93oDVOovlpQ1pOUQNYxt6Fs/ZK6xpA6rEZwAAACAyqR+F2+AGviW//aZ50vpqQUfU84+uOwD33Jo3HIdzXRaUoeVCE4AAABAZdTsUm+AuuLFvG3PNPH2Pm1YUKGlGIah+88bJ0myR/yhR//3W4VevzIgOAEAAACVWet/SM36+W+bc5303pAKLaNnSnff8sfrV+t4jrtCr281ghMAAABQ2Q38rzT+iPdhubl++9Db++SumGFzNSNr+pbD4j/Vza9/XyHXrSwITgAAAEAwMAzponHeZ0Gd7PEa0tsDK6SErsldJUkhVbZo1e4NFXLNyoLgBAAAAASTkDDpkb+kqIS8bZsWeXufMv8q10s/2vFR33JUg2fOqEkiCE4AAABAsLHZpTGbpJsW+29/up70xw/ldtm4iDhd1uAy3/oba1aV27UqG4ITAAAAEKzO+j9v71Od8/K2vXKJtOLf5XbJJ89/0rf80o8fltt1KhuCEwAAABDMbHZp2GdS13F525Y+LLlyyu2SNW3tvQuxn5XbNSobghMAAABwOug6Vhq2LG/9iZrlNmyvb6POvuUsZ/kFtMqE4AQAAACcLuq0kxr3ylt/5RJp+eQyv8ywNlf7lrf/dbjMz18ZEZwAAACA08l1c6W+U/PWlz8l7VlTppeICYuWTG+UmL9xRZmeu7IiOAEAAACnm/Nulkaf9Jylly8u0/BkGIZkeCRJX/+5pMzOW5kRnAAAAIDTUUySf8/TyxdLW5YVvn+AojwtJUk7s+lxAgAAABDMzrtZuvC+vPX/Xikd/aNMTp0S1dS37PSc/g/CJTgBAAAAp7OLH5SGLMhbf7aFdHhnqU/7aJcRvuX/bfmk1Oer7AhOAAAAwOku5XzpgjF569PPllJ/LdUp68fF+Za/3bWjVOcKBgQnAAAA4ExwycNSiyvy1md2LnzfYnDYbXIeaStJ2nJ0fanOFQwITgAAAMCZ4prZUv8X8tYfrSplHS3x6eJjTUnShr2ZpSys8iM4AQAAAGeSNtdJcY3y1iedJR3dU6JTVbc1kyTZo38qi8oqNYITAAAAcKb55w/SRQ/lrT/bvESnuaL5+b7l467jpa2qUiM4AQAAAGeiLvdKKRfkrS8dH/AputY9x7e8dt/p3etEcAIAAADOVDd8mLe8YpqUtjegw8+Ki5THFSlJ+iPtQBkWVvkQnAAAAIAzld0h3bQkb31q08L3LYBhGFL2WZKkT3f8rywrq3QITgAAAMCZ7KwO0rk35q1nHAzocFtImiTpl4PryrCoyofgBAAAAJzpLp2Wt7xpcUCHZqd5Z9bL9jA5BAAAAIDTmc0uxdT2Ln88IqBDz41vJ0myK6Ksq6pUCE4AAAAApF6T8pYDeK6Tw4yVJLlNVxkXVLkQnAAAAABIzS/LW361R7EPO7t2vHfBcCo9J72Mi6o8CE4AAAAAvGLqeF/T/pBc2cU6pG2dur7l3w/9Xh5VVQoEJwAAAABe176dt/z11GId0ia5mlwZ9SRJP+0jOAEAAAA43SW1liKqe5e3f1WsQ6pXCZUnJ0GS9Mn20/dZTgQnAAAAAHnaDva+7lpZ7EPCbZGSpKqO+PKoqFIgOAEAAADIU69L3nIxH4abcczb47Tu0IryqKhSIDgBAAAAyFO/q2TYvcvzbirWIdXDo8uvnkqC4AQAAAAgj2FIdbwPtdX2L4t1SINqDXzLpmmWR1WWIzgBAAAA8Nf5zrzlvT8VuXu4UdW3vHb/2vKoyHIEJwAAAAD+GnbLW37xwiJ3Pzc5b1KInw/8XB4VWY7gBAAAAMBfSJjU86m89T0/nnL3RglRcmclSpJ+O/RbeVZmGYITAAAAgPw6jsxbfvmiU+6aUqOKPDk1JEmHsg6VZ1WWITgBAAAAKFiDS/KWczIL3S0hOlyenJqSpKNZ6eVdlSUITgAAAAAKdt27ecu7VhW6W7Uqob4ep01HNpR3VZYgOAEAAAAomD1EiqjuXd7xzSl3reKIlCTFRySVd1WWIDgBAAAAKFy9E7Pqff/KKXcL8XiH6u0/vre8K7IEwQkAAABA4Vpd433NTpOcxwvd7dDhGN/yhr9Ov+F6BCcAAAAAhWvSJ29585JCdzvdn+VEcAIAAABQONtJkeHApkJ3C7HbZLq89zkddxXeMxWsCE4AAAAATq3lVd7XL54odJdmidFy53h7nY5kH6mAoioWwQkAAADAqdVum7d8cHOBu4SG2GS6qkgiOAEAAAA4E503LG/5uXaSaebbxWG3yXR7g9PB4wcrqrIKQ3ACAAAAcGohYVKfKXnrf23Lt4vbY8p0R0iSoh3RFVVZhSE4AQAAACha++F5y398n+/t2MhQma5YSdLyP5ZXTE0ViOAEAAAAoHiqnuV9/fDWfG/FR4f5ljOdmRVVUYUhOAEAAAAonqiahb5Vr2YVuY/XliS5Tbc8pqeiqqoQBCcAAAAAxdNvet7y0T1+bzWMj5Inu5Zv/XSbWY/gBAAAAKB4ElrmLS+4x++tmHCHkmKifOubDxc8bXmwIjgBAAAAKB7DkJr1O7GSf0ryvzJyfMv7M/dXUFEVg+AEAAAAoPhaDfC+7vo231udGsTJnZUoSTIMoyKrKncEJwAAAADFF3ZiOF7WkXxvHTiWLdNVVZLkdDsrsKjyR3ACAAAAUHzRtQp96+Im8TI9IZKkNfvWVFRFFYLgBAAAAKD4ImLzltP3+b1VMyZcht37DKfUzNQKLKr8EZwAAAAAFF90Yt7yxgV+bxmSPNne9+Mj4iuwqPJHcAIAAAAQmGop3tdvZ/ptrhsXKU9ODUlSjidHpxOCEwAAAIDAJLbyvh7c6Lc5xGaTTO89Tj/u+7GiqypXBCcAAAAAgWkzKG/ZzHueU2LVcN/ygeMHKrKickdwAgAAABCYht3ylo/+4VusWz1SnuyakqQqIdEVXVW5IjgBAAAACIzdkbe8dZlv0WYzlBTtDU7m348JcpYHpxkzZiglJUXh4eHq0KGDVq9eXei+TqdTEyZMUIMGDRQeHq7WrVtr0aJFFVgtAAAAAD9fPOW3GhMeIUnKcTM5RJmZO3euRo8erfHjx+vHH39U69at1bNnT+3fv7/A/R966CG9+OKL+s9//qPff/9dt912m6644gqtXbu2gisHAAAAznDtb/G+HtsnuV2+zQeOepddZrZM8/Tpd7I0OE2dOlXDhw/X0KFD1bx5c82cOVORkZF67bXXCtz/zTff1AMPPKA+ffqofv36uv3229WnTx8988wzFVw5AAAAcIbr/njectYR32Lj+ATfclpOWgUWVL5CrLpwTk6O1qxZo3Hjxvm22Ww2devWTatWrSrwmOzsbIWHh/tti4iI0DfffFPodbKzs5Wdne1bT0vz/vKcTqecTmdpPkKZyK2hMtSCyo/2gkDRZhAo2gwCRZs5k9mVe6eTa++vMut2liT1bFZLP22yyTA8+uPoH4qsFul3VGVqM4HUYFlwOnjwoNxutxISEvy2JyQkaMOGDQUe07NnT02dOlUXXnihGjRooGXLlumDDz6Q2+0u9DoTJ07UY489lm/7kiVLFBkZWcAR1li6dKnVJSCI0F4QKNoMAkWbQaBoM2emHo5qinAe1sbP39KWhKOSpC0HDRkhHknSgq8WaItjS4HHVoY2k5mZWex9LQtOJTF9+nQNHz5cTZs2lWEYatCggYYOHVro0D5JGjdunEaPHu1bT0tLU3Jysnr06KGYmJiKKPuUnE6nli5dqu7du8vhcBR9AM5otBcEijaDQNFmECjazJktZMd46fBhNYs6psZ9+kiS3D/v1XvfNVRIlS1Kbp6sPo36+B1TmdpM7mi04rAsONWoUUN2u1379u3z275v3z4lJiYWeEzNmjX10UcfKSsrS4cOHVKtWrU0duxY1a9fv9DrhIWFKSwsLN92h8Nh+S/qZJWtHlRutBcEijaDQNFmECjazBmq1jnS4e2ybVoo24nff3JclEyX9xlOv/31m651XFvgoZWhzQRyfcsmhwgNDVXbtm21bFnevO8ej0fLli1Tx44dT3lseHi4ateuLZfLpffff1+XX355eZcLAAAA4O/OOvF3uz3UtynCYZcRckSSVDWsqgVFlQ9Lh+qNHj1agwcPVrt27dS+fXtNmzZNGRkZGjp0qCTpxhtvVO3atTVx4kRJ0nfffac9e/aoTZs22rNnjx599FF5PB7dd999Vn4MAAAA4MxU70LvqztHMk3JMFQ3LlLu4ykKqbJdaVlZ1tZXhiwNTgMHDtSBAwf0yCOPKDU1VW3atNGiRYt8E0bs2rVLNltep1hWVpYeeughbdu2TVFRUerTp4/efPNNxcbGWvQJAAAAgDNYVHze8s4VUsr5ig53SB7vELhfD/1sUWFlz/LJIUaNGqVRo0YV+N7y5cv91rt06aLff/+9AqoCAAAAUKTI6nnL+36XUs6XJFUJs8klKcIebU1d5cDSB+ACAAAACHIxdbyv+37xbXKY3hFkOW7rn9VUVghOAAAAAEouNtn7Ghnn2/TXMe9zVnPcLisqKhcEJwAAAAAld9b/eV+z032bEqIjJUluk+AEAAAAAFJIhPd1xwrfpqoR3ueo7s7YaEVF5YLgBAAAAKDkTI/39cB636YQuyFJctjCraioXBCcAAAAAJRcrXPyll05kqQwxUqS7IqwoKDyQXACAAAAUHINu+Utp+89seB96pEp7nECAAAAAMkeIlU9y7u842tJUkr1GElSlifNqqrKHMEJAAAAQOk4TtzLdHCzJCnSEeV7K8edY0VFZY7gBAAAAKB0cu9z2rZckuR2hvneOu46bkFBZY/gBAAAAKB0HN7nNsmZKUmqFpk3KcT6v9YXdETQITgBAAAAKJ3cHqecDElSQkzeNOSr9662oqIyR3ACAAAAUDpRCd7XtD2SpNAQmzw51SRJVRxVrKqqTBGcAAAAAJRO1Tp5y6apKqEhcmU0lsTkEAAAAADgFXtW3nJ2murGRUoe77Ocftj3g0VFlS2CEwAAAIDSCY/JWz76hxx2mwxHuiQpOTrZoqLKFsEJAAAAQOlF1vC+ZqcruXqEPMdrS5IycrItLKrsEJwAAAAAlJ7H5X09uFmRoSEyTbsk6biTe5wAAAAAwCs60fu6ebEkKTI0VJL0y6G1VlVUpghOAAAAAEovxjs0T2l/SpJs9izv5pB4qyoqUwQnAAAAAKVXt5P3dd/vkqQQt/eeJ5sRYlVFZYrgBAAAAKD0cp/lFN9UklQr1vvg24wcp1UVlSmCEwAAAIDSy73HyeWdRW9/undSCMPwWFVRmSI4AQAAACi9kHDv637vUL2mid5nO3lM06qKyhTBCQAAAEDpOSL9VsPsDklSehbTkQMAAACAV0ytvGVnlo4e997bFBpiWFRQ2SI4AQAAACi9yLi85dSfVb9GtCTJY7otKqhsEZwAAAAAlJ5xUs/S7u/ksNslScedLosKKlsEJwAAAABlI6Gl9zUkXDku76QQrpA9FhZUdghOAAAAAMpGzSbeV49LNaLCJEk2M/IUBwQPghMAAACAsmHzzqQnj0txETVPbGRyCAAAAADIYwvxvrqdigzx9jh5jAx5zOB/CC7BCQAAAEDZsHknhNDRPxQXnuDbfDjrsEUFlR2CEwAAAICyYQ/1vv61VXZbiEzTG6ScHqeFRZUNghMAAACAslGjsfd123IlxIRJHu/QvWx3toVFlQ2CEwAAAICy0epq32KU87BkeO9t2vjXRqsqKjMEJwAAAABlI7K6bzHayJJh8w7R25950KqKygzBCQAAAEDZcXif2xSWvkuuY96he78f+t3KisoEwQkAAABA2XFlSZJshzZIMiVJO9N2WlhQ2SA4AQAAACg7cQ0lSfaDG+XJqSFJqhoWa2FBZYPgBAAAAKDsxNSWJNlSf5Y7y7v804G1VlZUJghOAAAAAMpOfDPva0iYcofqxYRWta6eMkJwAgAAAFB26rSTJBl/rJbprCZJCrGFWFlRmSA4AQAAACg7sXV9i4a8gcnpdlpVTZkhOAEAAAAoO9VSfIvGibixJ2O3RcWUHYITAAAAgLITFuNbrG56e5rC7RFWVVNmCE4AAAAAyk5IqG8x+sQzndym26pqygzBCQAAAEC56BKxQ5LkMT3WFlIGCE4AAAAAypajiiQp0vAO1fPQ4wQAAAAAf9N2sCSpo/snSZIpM+h7nQhOAAAAAMpWZHVJUoSZNw252xPcvU4EJwAAAABlq3p9SVK8+6Bv06GsQ1ZVUyYITgAAAADK1ol7nGorzbcp05VpVTVlguAEAAAAoGxFJ0qSjtqqyeOKkiQ53c5THVHpEZwAAAAAlK2waElSVc9hyQyRJLk8LisrKjWCEwAAAICyVaWmb9EwDUlSakaqVdWUCYITAAAAgLIVFi3JG5gMx1FJ0pYjWywsqPQITgAAAADKlmFIMiVJdle4JKnKiQkjghXBCQAAAEDZi/JOEFEj0/tMJ+5xAgAAAIC/c+dIkhwnep5cJsEJAAAAAPzVPleSFGVmS5KOu45bWU2pEZwAAAAAlL3oJEmS7USP02+HfrOymlIjOAEAAAAoe1VqSJIcIemSpOSoZCurKTWCEwAAAICyl30iMGV7pyXnHicAAAAA+LuY2pIkp0IlSW6P28pqSo3gBAAAAKDsRXqnIQ81PZIkt0lwAgAAAAB/9jBJUhP9IUnadHiTldWUGsEJAAAAQNk78cDbHbZqkiS7YbeymlIjOAEAAAAoe9VSJElN3UckSTGhMdbVUgYITgAAAADKXmgVSVLUidn0PPJYWU2pEZwAAAAAlL34ZpKk3AF6HpPgBAAAAAD+QsIlSYZpSmI6cgAAAADIz/A++JYepzIyY8YMpaSkKDw8XB06dNDq1atPuf+0adPUpEkTRUREKDk5WXfffbeysrIqqFoAAAAAxeVKbOMLHG6CU8nNnTtXo0eP1vjx4/Xjjz+qdevW6tmzp/bv31/g/m+//bbGjh2r8ePHa/369Xr11Vc1d+5cPfDAAxVcOQAAAICi2Owhsp8YqpftcllcTelYGpymTp2q4cOHa+jQoWrevLlmzpypyMhIvfbaawXuv3LlSnXu3FnXXXedUlJS1KNHD1177bVF9lIBAAAAqHg2u8MXOHakbbG0ltIKserCOTk5WrNmjcaNG+fbZrPZ1K1bN61atarAYzp16qT//ve/Wr16tdq3b69t27Zp4cKFuuGGGwq9TnZ2trKzs33raWlpkiSn0ymn01lGn6bkcmuoDLWg8qO9IFC0GQSKNoNA0WZwKnbDJueJe508pun3N3hlaDOB1GBZcDp48KDcbrcSEhL8tickJGjDhg0FHnPdddfp4MGDOv/882Waplwul2677bZTDtWbOHGiHnvssXzblyxZosjIyNJ9iDK0dOlSq0tAEKG9IFC0GQSKNoNA0WZQkI5/HVENt3c2vVBPFS1cuND3XmVoM5mZmcXe17LgVBLLly/XU089peeff14dOnTQli1bdOedd+rxxx/Xww8/XOAx48aN0+jRo33raWlpSk5OVo8ePRQTY/3Ti51Op5YuXaru3bvL4XBYXQ4qOdoLAkWbQaBoMwgUbQanEjL9Ph06cY9TSKhNffr0qVRtJnc0WnFYFpxq1Kghu92uffv2+W3ft2+fEhMTCzzm4Ycf1g033KBhw4ZJklq1aqWMjAzdcsstevDBB2Wz5b9lKywsTGFhYfm2OxwOy39RJ6ts9aByo70gULQZBIo2g0DRZlCgRt3k+HWuJMltuv3aSGVoM4Fc37LJIUJDQ9W2bVstW7bMt83j8WjZsmXq2LFjgcdkZmbmC0d2u3dmePNEkgUAAABQSYRGK+TE3+kZrqMWF1M6lg7VGz16tAYPHqx27dqpffv2mjZtmjIyMjR06FBJ0o033qjatWtr4sSJkqR+/fpp6tSpOuecc3xD9R5++GH169fPF6AAAAAAVBJRNRXjyXt+U6YzUw4FZ8+kpcFp4MCBOnDggB555BGlpqaqTZs2WrRokW/CiF27dvn1MD300EMyDEMPPfSQ9uzZo5o1a6pfv3568sknrfoIAAAAAApT6xxVPSk45bhz5LATnEpk1KhRGjVqVIHvLV++3G89JCRE48eP1/jx4yugMgAAAAClEhmnk8eFpTvTVcVexbJySsPSB+ACAAAAOI3VaOy36vK4LCqk9AhOAAAAAMqHI0KSFHviWU4e03OqvSs1ghMAAACAcpNlq+ILHQQnAAAAACiAy+aQceLJQQQnAAAAAChAlOuI7PImJ4ITAAAAABQgx15FxolljwhOAAAAAJDPjmqdfKHDNE1LaykNghMAAACAcuMIDZXtNLjHqUQPwHW73Zo9e7aWLVum/fv3y+Px/wI+//zzMikOAAAAQHCLzjkoW3jw3+NUouB05513avbs2erbt69atmwpwzCKPggAAADAGSetWgvZju+SJOW4cyyupuRKFJzmzJmjd999V3369CnregAAAACcTuwh2ulwSJIOZx+2uJiSK9E9TqGhoWrYsGFZ1wIAAADgNGOz2RXvckmSHDaHxdWUXImC0z333KPp06cH9awYAAAAAMqfW3bVcrklnYH3OH3zzTf64osv9Omnn6pFixZyOPyT4wcffFAmxQEAAAAIbpHhobKdeACu23RbXE3JlSg4xcbG6oorrijrWgAAAACcZuw2Q/YzdTryWbNmlXUdAAAAAE5Dht3huz/ojOtxynXgwAFt3LhRktSkSRPVrFmzTIoCAAAAcHrwxKbIviP4n+NUoskhMjIydNNNNykpKUkXXnihLrzwQtWqVUs333yzMjMzy7pGAAAAAEHKqJ7iCx1ZzmxLaymNEgWn0aNH68svv9T//vc/HTlyREeOHNHHH3+sL7/8Uvfcc09Z1wgAAAAgSIVXP0s5hiFJ2nl4s8XVlFyJhuq9//77mjdvnrp27erb1qdPH0VERGjAgAF64YUXyqo+AAAAAEHMHpOg7BPByXGm9ThlZmYqISEh3/b4+HiG6gEAAADwsdsM1cnxBqdfjmy0uJqSK1Fw6tixo8aPH6+srCzftuPHj+uxxx5Tx44dy6w4AAAAAMHNYbcpw/DGjlqhcRZXU3IlGqo3ffp09ezZU3Xq1FHr1q0lST/99JPCw8O1ePHiMi0QAAAAQPCyGVIjZ7aWK0SurDSryymxEgWnli1bavPmzXrrrbe0YcMGSdK1116rQYMGKSIiokwLBAAAABC8DMPwDXNzWVpJ6ZT4OU6RkZEaPnx4WdYCAAAA4DR0UNUk5cjjCd7oVOzgNH/+fPXu3VsOh0Pz588/5b6XXXZZqQsDAAAAcJow7d6X7DNgqF7//v2Vmpqq+Ph49e/fv9D9DMOQ2+0ui9oAAAAAnAZilSHJJtN13OpSSqzYwcnj8RS4DAAAAACnkmrESzoot81udSklVqLpyAty5MiRsjoVAAAAgNNIliIlSS4zeDtgShScJk+erLlz5/rWr7nmGlWvXl21a9fWTz/9VGbFAQAAAAh+puF9AO7X7v0WV1JyJQpOM2fOVHJysiRp6dKl+uyzz7Ro0SL17t1b9957b5kWCAAAACDYeWNHq5wzYFa9k6WmpvqC0yeffKIBAwaoR48eSklJUYcOHcq0QAAAAADBLd7tDU6usrtTqMKVqPJq1app9+7dkqRFixapW7dukiTTNJlRDwAAAICfX44nSJJcdofFlZRciXqcrrzySl133XVq1KiRDh06pN69e0uS1q5dq4YNG5ZpgQAAAACCW82qVSVJbpkWV1JyJQpOzz77rFJSUrR79249/fTTioqKkiTt3btXI0aMKNMCAQAAAAQ324lpyD1nWnByOBwaM2ZMvu133313qQsCAAAAcHqxGd7YEbxTQwQQnObPn6/evXvL4XBo/vz5p9z3sssuK3VhAAAAAE4PxongdMw4A3qc+vfvr9TUVMXHx6t///6F7mcYBhNEAAAAAPCJMLy39mQYFhdSCsUOTh6Pp8BlAAAAADiV1KNuKSK473EK3onUAQAAAASF5oknZtUzgrfLqUTB6Y477tC///3vfNufe+453XXXXaWtCQAAAMBp5LA70rfsMYNz9FqJgtP777+vzp0759veqVMnzZs3r9RFAQAAADh9xEZH+5bdZnDOh1Ci4HTo0CFVPfEQq5PFxMTo4MGDpS4KAAAAwOkjKjzCt3xG9Tg1bNhQixYtyrf9008/Vf369UtdFAAAAIDTh2Fz+JaDNTiV6AG4o0eP1qhRo3TgwAFdfPHFkqRly5bpmWee0bRp08qyPgAAAABBzrCH+pY9nuAcqlei4HTTTTcpOztbTz75pB5//HFJUkpKil544QXdeOONZVogAAAAgODmsVfxLWcdP2RhJSVXouAkSbfffrtuv/12HThwQBEREYqKiirLugAAAACcLhx5k0NkZAbnnAglfo6Ty+XSZ599pg8++ECm6X2Q1Z9//qljx46VWXEAAAAAgp/NZijO5R2itz8z1eJqSqZEPU47d+5Ur169tGvXLmVnZ6t79+6Kjo7W5MmTlZ2drZkzZ5Z1nQAAAACClM0wdCjELklyZRyQFG9tQSVQoh6nO++8U+3atdPhw4cVEZE3teAVV1yhZcuWlVlxAAAAAIKfYRhqmZ0tSXJ6XBZXUzIl6nH6+uuvtXLlSoWGhvptT0lJ0Z49e8qkMAAAAACnB5shuTze7OD0ZFtcTcmUqMfJ4/HI7c4/jeAff/yh6JOeCgwAAAAAhiT7ieUdGXutLKXEShScevTo4fe8JsMwdOzYMY0fP159+vQpq9oAAAAAnAZsNkM7Qw1JUrQttIi9K6cSBacpU6ZoxYoVat68ubKysnTdddf5hulNnjy5rGsEAAAAEMRMU2qd6V3OyTxgbTElVKJ7nJKTk/XTTz9p7ty5+umnn3Ts2DHdfPPNGjRokN9kEQAAAACQ4/IoVsclRchp2IvcvzIKODg5nU41bdpUn3zyiQYNGqRBgwaVR10AAAAAThOJVcO12lNNUpZ+ztytbiXqvrFWwEP1HA6HsrKyyqMWAAAAAKchu83QXyGmJCmpZIPeLFeie5xGjhypyZMny+UKzjnYAQAAAFQcu81QsyxvcNqV/ZfF1ZRMieLe999/r2XLlmnJkiVq1aqVqlSp4vf+Bx98UCbFAQAAAAh+dsNQuhEqKUf7zeDsfClRcIqNjdVVV11V1rUAAAAAOA3ZbYY8rihJxxRvD7e6nBIJKDh5PB7961//0qZNm5STk6OLL75Yjz76KDPpAQAAACiUzWYo1O2QJOV4grPHKaB7nJ588kk98MADioqKUu3atfXvf/9bI0eOLK/aAAAAAJwG3B6PDNM7DflaZ3De4xRQcHrjjTf0/PPPa/Hixfroo4/0v//9T2+99ZY8Hk951QcAAAAgyMVVCZPTMCRJ0cYZMKverl271KdPH996t27dZBiG/vzzzzIvDAAAAMDpwW4zFO4KkyTFuM+AoXoul0vh4f43czkcDjmdzjItCgAAAMDpw2YYitZxSZJpd1hcTckE1E9mmqaGDBmisLAw37asrCzddtttflOSMx05AAAAgFx2m6HtnlqSdko5GVaXUyIBBafBgwfn23b99deXWTEAAAAATj92m2QzvA/A9djDiti7cgooOM2aNau86gAAAABwmrIZhg6bMZIkj0yLqymZgO5xAgAAAIBA2QxDHtMbPYIzNhGcAAAAAJQzu82Q50T0CNYHGRGcAAAAAJSrcIdd5okH4DJUDwAAAAAKUDM6TG55H4BLjxMAAAAAFCI20vs8WJMep5KbMWOGUlJSFB4erg4dOmj16tWF7tu1a1cZhpHvp2/fvhVYMQAAAIBA2E88+NY0g7PPyfLgNHfuXI0ePVrjx4/Xjz/+qNatW6tnz57av39/gft/8MEH2rt3r+/n119/ld1u1zXXXFPBlQMAAAAoLo/NG5wO2+0WV1IylgenqVOnavjw4Ro6dKiaN2+umTNnKjIyUq+99lqB+1evXl2JiYm+n6VLlyoyMpLgBAAAAFRix2zV81bM4BuuF9ADcMtaTk6O1qxZo3Hjxvm22Ww2devWTatWrSrWOV599VX94x//UJUqVQp8Pzs7W9nZ2b71tLQ0SZLT6ZTT6SxF9WUjt4bKUAsqP9oLAkWbQaBoMwgUbQbFZdNJf6+b7krRZgKpwdLgdPDgQbndbiUkJPhtT0hI0IYNG4o8fvXq1fr111/16quvFrrPxIkT9dhjj+XbvmTJEkVGRgZedDlZunSp1SUgiNBeECjaDAJFm0GgaDMoSvqxLCnWu2yarkrRZjIzM4u9r6XBqbReffVVtWrVSu3bty90n3Hjxmn06NG+9bS0NCUnJ6tHjx6KiYmpiDJPyel0aunSperevbscDofV5aCSo70gULQZBIo2g0DRZlBc9333vkJzV0ynunfvZ3mbyR2NVhyWBqcaNWrIbrdr3759ftv37dunxMTEUx6bkZGhOXPmaMKECafcLywsTGFhYfm2OxwOy39RJ6ts9aByo70gULQZBIo2g0DRZlCUDg2StPbEsmlmV4o2E8j1LZ0cIjQ0VG3bttWyZct82zwej5YtW6aOHTue8tj33ntP2dnZuv7668u7TAAAAAClZDPyQorNfczCSkrG8qF6o0eP1uDBg9WuXTu1b99e06ZNU0ZGhoYOHSpJuvHGG1W7dm1NnDjR77hXX31V/fv3V1xcnBVlAwAAAAiA3Z4XPY55CE4BGzhwoA4cOKBHHnlEqampatOmjRYtWuSbMGLXrl2y2fw7xjZu3KhvvvlGS5YssaJkAAAAAAGyGTbFuDxKs9t0xHPE6nICZnlwkqRRo0Zp1KhRBb63fPnyfNuaNGkiMwjnfgcAAADOVHbDUJrd2yES4rF+KvJAWf4AXAAAAACnP7vNULPsHEmSzZNlcTWBIzgBAAAAKHc2myGX6R3w5jEMi6sJHMEJAAAAQLmzGZInN36YHmuLKQGCEwAAAIByt/1ghiRvT5Op4JuvgOAEAAAAoNw1TYyW4ctL9DgBAAAAQD5VwkJk+HqcCE4AAAAAkI/dyI1NkoLw0UIEJwAAAADlzmYzJJMeJwAAAAAolO2kHieTWfUAAAAAID/7Sckj1HXEsjpKiuAEAAAAoNzZDUPRypIkZdvCLK4mcAQnAAAAAOXOYbdpvxEpSTpgHLe4msARnAAAAACUu9gqoUoP8d7bFG2GWFxN4AhOAAAAAMpdVJhdtbJODNFjOnIAAAAAyM9x0uwQhghOAAAAAJBPiM0mM29CcktrKQmCEwAAAIBy5/J4CE4AAAAAcCoJMeG+ZZPgBAAAAAD5hdgMKbfHyfRYWktJEJwAAAAAlLsQm03GiY6miJxD1hZTAgQnAAAAAOUuxG4owsiWJGU5oi2uJnAEJwAAAADlLsRm6KgZ5V3hOU4AAAAAkF9YiF2+e5yCEMEJAAAAQLmrEmY/qaOJHicAAAAAyCfEZlNuj5PJUD0AAAAAyC/EnjcdOc9xAgAAAIACEJwAAAAAoAgOm80XlxiqBwAAAAAFsNkMmb4ep+BDcAIAAABQIWwGQ/UAAAAAoAje4BTlPGBxHYEjOAEAAACoEOHKkSRl2aMtriRwBCcAAAAAFSJDVSRJniCMIcFXMQAAAIDg5B2pF4R3OBGcAAAAAFQQwzSsLqHECE4AAAAAKgiz6gEAAADAKRm+oXoEJwAAAAAoBEP1AAAAAKBYNjjcVpcQMIITAAAAgAqREZIpSartCr4YEnwVAwAAAAhKcTlxkiSnwT1OAAAAAFAgm2mXJO23E5wAAAAAoEAew3tv0367x+JKAkdwAgAAAFAhQkyHJCmJe5wAAAAAoGDZx73xI/j6mwhOAAAAACpIRGjIiSXucQIAAACAAoU77FaXUGIEJwAAAAAVwpAhKRj7mwhOAAAAACqIYZwITobFhZQAwQkAAABAhaDHCQAAAACKZJz0f4MLwQkAAABAxcgdqmcGX58TwQkAAABAhfAN1QvCLieCEwAAAIAKYQTlID0vghMAAACACuGbVc/iOkqC4AQAAACgQhGcAAAAAKAQhi9+BF90IjgBAAAAqBAM1QMAAACAIpzITQQnAAAAACiMKXqcAAAAAOCUDqU7rS6hxAhOAAAAACrEWdXDJUkOM9viSgJHcAIAAABQIQwjRJLkNBwWVxI4ghMAAACACuEJ8fY4cY8TAAAAABTCfmJaPY/FdZQEwQkAAABAhTicyeQQAAAAAHBKtapGWl1CiRGcAAAAAFQIm807VG9TWPDFkOCrGAAAAEBQMk9MC1HLGXx3ORGcAAAAAFSISDtD9QAAAADglGwnZtULRgQnAAAAABXCdiJ+8BwnAAAAACiEcWJyCIJTCcyYMUMpKSkKDw9Xhw4dtHr16lPuf+TIEY0cOVJJSUkKCwtT48aNtXDhwgqqFgAAAEBJZWa7rC6hxEKsvPjcuXM1evRozZw5Ux06dNC0adPUs2dPbdy4UfHx8fn2z8nJUffu3RUfH6958+apdu3a2rlzp2JjYyu+eAAAAAABqV4lXMqyuoqSsTQ4TZ06VcOHD9fQoUMlSTNnztSCBQv02muvaezYsfn2f+211/TXX39p5cqVcjgckqSUlJSKLBkAAABACdlswXuPk2XBKScnR2vWrNG4ceN822w2m7p166ZVq1YVeMz8+fPVsWNHjRw5Uh9//LFq1qyp6667Tvfff7/sdnuBx2RnZys7O9u3npaWJklyOp1yOp1l+IlKJreGylALKj/aCwJFm0GgaDMIFG0GgTA93shkGpWjzQRSg2XB6eDBg3K73UpISPDbnpCQoA0bNhR4zLZt2/T5559r0KBBWrhwobZs2aIRI0bI6XRq/PjxBR4zceJEPfbYY/m2L1myRJGRlWce+aVLl1pdAoII7QWBos0gULQZBIo2g+L4Y+9uKcK7XBnaTGZmZrH3tXSoXqA8Ho/i4+P10ksvyW63q23bttqzZ4/+9a9/FRqcxo0bp9GjR/vW09LSlJycrB49eigmJqaiSi+U0+nU0qVL1b17d9/wQ6AwtBcEijaDQNFmECjaDAJx6LP90n7vUL3K0GZyR6MVh2XBqUaNGrLb7dq3b5/f9n379ikxMbHAY5KSkuRwOPyG5TVr1kypqanKyclRaGhovmPCwsIUFhaWb7vD4bD8F3WyylYPKjfaCwJFm0GgaDMIFG0GxRFi8/4db6pytJlArm/ZdOShoaFq27atli1b5tvm8Xi0bNkydezYscBjOnfurC1btsjj8fi2bdq0SUlJSQWGJgAAAACVh2EYVpdQYpY+x2n06NF6+eWX9frrr2v9+vW6/fbblZGR4Ztl78Ybb/SbPOL222/XX3/9pTvvvFObNm3SggUL9NRTT2nkyJFWfQQAAAAAxWQoeB+Aa+k9TgMHDtSBAwf0yCOPKDU1VW3atNGiRYt8E0bs2rXLN2WhJCUnJ2vx4sW6++67dfbZZ6t27dq68847df/991v1EQAAAAAUk82wtN+mVCyfHGLUqFEaNWpUge8tX74837aOHTvq22+/LeeqAAAAAJQ5I3h7nII38gEAAAAIKjZxjxMAAAAAnFpuj1MQ5ieCEwAAAIAKYbMxVA8AAAAATimYZ9UjOAEAAACoEME8q17wVg4AAAAgqBhMDgEAAAAAp2ZwjxMAAAAAFIXgBAAAAACnFBrijR8EJwAAAAAoRJVQh9UllBjBCQAAAECFcNjtkngALgAAAAAUymFnqB4AAAAAnFLEiaF6mbbgiyHBVzEAAACAoOSwhVpdQokRnAAAAABUCIctxOoSSozgBAAAAKBCGEYQzgpxAsEJAAAAQIUwlBecTDO4poggOAEAAACoGMHb4URwAgAAAFBBHFV8i/Q4AQAAAEBBjLz4EWS5ieAEAAAAoGKcPFLPDLLH4BKcAAAAAFQIwwje+BG8lQMAAAAIWsF2j1PwPoGqnLndbjmdznK/jtPpVEhIiLKysuR2u8v9eghuhbUXh8Mhu91uYWUAAABFO/k5TgSnIGeaplJTU3XkyJEKu15iYqJ2794d1A8EQ8U4VXuJjY1VYmIi7QgAAFRafvc4EZyCW25oio+PV2RkZLn/EerxeHTs2DFFRUXJZmPkJE6toPZimqYyMzO1f/9+SVJSUpKVJQIAABTK+Nv0EMGE4HQSt9vtC01xcXEVck2Px6OcnByFh4cTnFCkwtpLRESEJGn//v2Kj49n2B4AAKicTh6qF2TBib/UT5J7T1NkZKTFlQCBy223FXFvHgAAQMkE7z1OBKcCcI8IghHtFgAAVHpB/PcKwQkAAABAhfD/h156nHAGGTJkiPr37+9b79q1q+666y7L6qmsHn30UbVp08bqMgAAACxl+k1HbmEhJUBwOo2kpqbqzjvvVMOGDRUeHq6EhAR17txZL7zwgjIzMyukhg8++ECPP/54mZ7z7+HsVPsZhuH7iYuLU69evfTzzz+XaT1FMQxDH330kd+2MWPGaNmyZRVaBwAAQGVzcocTk0PAEtu2bdM555yjJUuW6KmnntLatWu1atUq3Xffffrkk0/02WefFXpsWU4mUL16dUVHR5fZ+QLVq1cv7d27V3v37tWyZcsUEhKiSy+91LJ6ckVFRVXYTI0AAACVVTA/x4ngVATTNJWZ4yrXn+M57gK3B9KYRowYoZCQEP3www8aMGCAmjVrpvr16+vyyy/XggUL1K9fP9++hmHohRde0GWXXaYqVaroySeflNvt1s0336x69eopIiJCTZo00fTp0/2u4Xa7NXr0aMXGxiouLk733Xdfvhr/PlQvOztbY8aMUe3atVWlShV16NBBy5cv970/e/ZsxcbGavHixWrWrJmioqJ84UfyDnF7/fXX9fHHH/t6kk4+/u/CwsKUmJioxMREtWnTRmPHjtXu3bt14MAB3z6//PKLLr74YkVERCguLk633HKLjh075nvf4/FowoQJqlOnjsLCwtSmTRstWrTI935OTo5GjRqlpKQkhYeHq27dupo4caIkKSUlRZJ0xRVXyDAM3/rfh+rl9qJNmTJFSUlJiouL08iRI/1C7N69e9W3b19FRESoXr16evvtt1W/fn298MILhX5+AACAyswI4ln1eI5TEY473Wr+yGJLrv37hJ6KDC36V3To0CFfT1OVKlUK3OfvM649+uijmjRpkqZNm6aQkBB5PB7VqVNH7733nuLi4rRy5UrdcsstSkpK0oABAyRJzzzzjGbPnq3XXntNzZo10zPPPKMPP/xQF198caG1jRo1Sr///rvmzJmjWrVq6cMPP1SvXr30yy+/qFGjRpKkzMxMTZkyRW+++aZsNpuuv/56jRkzRm+99ZbGjBmj9evXKy0tTbNmzZLk7dUqjmPHjum///2vGjZs6OvtycjIUM+ePdWxY0d9//332r9/v4YNG6ZRo0Zp9uzZkqTp06frmWee0YsvvqhzzjlHr732mi677DL99ttvatSokf79739r/vz5evfdd3XWWWdp9+7d2r17tyTp+++/V3x8vGbNmqVevXqd8nlKX3zxhZKSkvTFF19oy5YtGjhwoNq0aaPhw4dLkm688UYdPHhQy5cvl8Ph0OjRo30PuQUAAAhGPAAXltqyZYtM01STJk38tteoUUNZWVmSpJEjR2ry5Mm+96677joNHTrUb//HHnvMt1yvXj2tWrVK7777ri84TZs2TePGjdOVV14pSZo5c6YWLy48VO7atUuzZs3Srl27VKtWLUnee30WLVqkWbNm6amnnpLkHSo4c+ZMNWjQQJI3bE2YMEGSd4hbRESEsrOzlZiYWOR38cknnygqKkqSNyQlJSXpk08+8T0s9u2331ZWVpbeeOMNX8h87rnn1K9fP02ePFkJCQmaMmWK7r//fv3jH/+QJE2ePFlffPGFpk2bphkzZmjXrl1q1KiRzj//fBmGobp16/quX7NmTUlSbGxskfVWq1ZNzz33nOx2u5o2baq+fftq2bJlGj58uDZs2KDPPvtM33//vdq1aydJeuWVV3xhEwAAIDidfJMTwem0EuGw6/cJPcvt/B6PR+lp6YqOifb9cX/ytUtj9erV8ng8GjRokLKzs/3ey/1j/GQzZszQa6+9pl27dun48ePKycnxDS87evSo9u7dqw4dOvj2DwkJUbt27QrtZv3ll1/kdrvVuHFjv+3Z2dl+9/tERkb6QpMkJSUllbhn5aKLLvINZTt8+LCef/559e7dW6tXr1bdunW1fv16tW7d2q9nrnPnzvJ4PNq4caMiIiL0559/qnPnzn7n7dy5s3766SdJ3mF23bt3V5MmTdSrVy9deuml6tGjR8C1tmjRwq9HKikpSb/88oskaePGjQoJCdG5557re79hw4aqVq1awNcBAACoLE4eBRVsk0MQnIpgGEaxhsuVlMfjkSvUrsjQkHzBqbgaNmwowzC0ceNGv+3169eXJEVEROQ75u9D+ubMmaMxY8bomWeeUceOHRUdHa1//etf+u6770pUk+QdKme327VmzZp8Q9Zye4UkyeFw+L1nGEaJx7xWqVJFDRs29K2/8sorqlq1ql5++WU98cQTJTrn35177rnavn27Pv30U3322WcaMGCAunXrpnnz5gV0noI+t8fjKZMaAQAAKqfg7XFicojTQFxcnLp3767nnntOGRkZJTrHihUr1KlTJ40YMULnnHOOGjZsqK1bt/rer1q1qpKSkvyClMvl0po1awo95znnnCO32639+/erYcOGfj/FGXaXKzQ0VG63u0SfyzAM2Ww2HT9+XJLUrFkz/fTTT37f04oVK2Sz2dSkSRPFxMSoVq1aWrFihd95VqxYoebNm/vWY2JiNHDgQL388suaO3eu3n//ff3111+SvIGopPXmatKkiVwul9auXevbtmXLFh0+fLhU5wUAALCU33TkwYXgdJp4/vnn5XK51K5dO82dO1fr16/Xxo0b9d///lcbNmw45SQFktSoUSP98MMPWrx4sTZt2qSHH35Y33//vd8+d955pyZNmqSPPvpIGzZs0IgRI3TkyJFCz9m4cWMNGjRIN954oz744ANt375dq1ev1sSJE7VgwYJif7aUlBT9/PPP2rhxow4ePHjK6dOzs7OVmpqq1NRUrV+/Xv/85z917Ngx36yCgwYNUnh4uAYPHqxff/1VX3zxhf75z3/qhhtuUEJCgiTp3nvv1eTJkzV37lxt3LhRY8eO1bp163TnnXdKkqZOnap33nlHGzZs0KZNm/Tee+8pMTFRsbGxvnqXLVum1NTUEgedpk2bqlu3brrlllu0evVqrV27VrfccosiIiLyTfQBAAAQLGx+f8YEV3RiqN5pokGDBlq7dq2eeuopjRs3Tn/88YfCwsLUvHlzjRkzRiNGjDjl8bfeeqvWrl2rgQMHyjAMXXvttRoxYoQ+/fRT3z733HOP9u7dq8GDB8tms+mmm27SFVdcoaNHjxZ63lmzZumJJ57QPffcoz179qhGjRr6v//7v4CerTR8+HAtX75c7dq107Fjx/TFF1+oa9euBe67aNEiJSUlSZKio6PVtGlTvffee779IyMjtXjxYt15550677zzFBkZqauuukpTp071neOOO+7Q0aNHdc8992j//v1q3ry55s+f75uYITo6Wk8//bQ2b94su92u8847TwsXLvQNtXzmmWc0evRovfzyy6pdu7Z27NhR7M96sjfeeEM333yzLrzwQiUmJmrixIn67bffFBYWVqLzAQAAWO/k6cgtLKMEDDPYJlAvpbS0NFWtWlVHjx5VTEyM33tZWVnavn276tWrp/Dw8Aqpx+PxKC0tTTExMSW+xwlnhj/++EPJycn66KOP1K9fv3ztxYr2i8rP6XRq4cKF6tOnT7776oCC0GYQKNoMAnHw8B5dNL+XJGlZ3yWKr5FkaT2nygZ/R48TUEl9/vnnOnbsmFq1aqW9e/fqvvvuU0pKijp16mR1aQAAACViGMHbUUBwAiopp9OpBx54QNu2bVN0dLQ6deqkN998k3/NAwAApwWmIwdQJnr27KmePf2fIZY7tBMAACAYGSff46TgegxL8PaVAQAAAAgqxknxI9hmWiA4AQAAAKgQht/zb4MrORGcAAAAAFSMIJ5FOngrBwAAABC0gqu/ieAEAAAAwBLBFZ0ITgAAAAAqxMmz6gUbghMAAACACufxMB05Kpjb7VanTp105ZVX+m0/evSokpOT9eCDD/q2vf/++7r44otVrVo1RUREqEmTJrrpppu0du1a3z6zZ8+WYRi+n6ioKLVt21YffPBBhX0mSeratavuuuuuCr0mAAAAyo+NySFgJbvdrtmzZ2vRokV66623fNv/+c9/qnr16ho/frwk6f7779fAgQPVpk0bzZ8/Xxs3btTbb7+t+vXra9y4cX7njImJ0d69e7V3716tXbtWPXv21IABA7Rx48YK/WwAAAA4TZn0OJ1eTFPKySjfH2dmwdsDmNu+cePGmjRpkv75z39q7969+vjjjzVnzhy98cYbCg0N1bfffqunn35aU6dO1dSpU3XBBRforLPOUtu2bfXQQw/p008/9TufYRhKTExUYmKiGjVqpCeeeEI2m00///yzb5/Dhw/rxhtvVLVq1RQZGanevXtr8+bNfud5//331aJFC4WFhSklJUXPPPOM3/vPP/+8GjVqpPDwcCUkJOjqq6+WJA0ZMkRffvmlpk+f7uv52rFjR4C/PAAAAFQmfg/ADbLJIUKsLqDSc2ZKT9Uqt9PbJMUW9uYDf0qhVYp9rn/+85/68MMPdcMNN+iXX37RI488otatW0uS3nnnHUVFRWnEiBEFHmsYhd+o53a79cYbb0iSzj33XN/2IUOGaPPmzZo/f75iYmJ0//33q0+fPvr999/lcDi0Zs0aDRgwQI8++qgGDhyolStXasSIEYqLi9OQIUP0ww8/6I477tCbb76pTp066a+//tLXX38tSZo+fbo2bdqkli1basKECZKkmjVrFvu7AAAAQOUTzJNDEJxOI4Zh6IUXXlCzZs3UqlUrjR071vfepk2bVL9+fYWE5P3Kp06dqkceecS3vmfPHlWtWlWS9/6oqKgoSdLx48flcDj00ksvqUGDBpLkC0wrVqxQp06dJElvvfWWkpOT9dFHH+maa67R1KlTdckll+jhhx+W5O0V+/333/Wvf/1LQ4YM0a5du1SlShVdeumlio6OVt26dXXOOedIkqpWrarQ0FBFRkYqMTGxHL81AAAAWCK4OpwITkVyRHp7fsqJx+NRWnq6YqKj898s54gM+HyvvfaaIiMjtX37dv3xxx9KSUkpdN+bbrpJl112mb777jtdf/31Mk8aGhgdHa0ff/xRkpSZmanPPvtMt912m+Li4tSvXz+tX79eISEh6tChg++YuLg4NWnSROvXr5ckrV+/XpdffrnfNTt37qxp06bJ7Xare/fuqlu3rurXr69evXqpV69euuKKKxQZGfjnBgAAQOVn2PJ6nIJtqB73OBXFMLzD5crzxxFZ8PZTDJ8ryMqVK/Xss8/qk08+Ufv27XXzzTf7wlCjRo20bds2OZ1O3/6xsbFq2LChateune9cNptNDRs2VMOGDXX22Wdr9OjR6tq1qyZPnly67/MkueHsnXfeUVJSkm9o4ZEjR8rsGgAAAKhETv77NoD7+SsDgtNpIjMzU0OGDNHtt9+uiy66SK+++qpWr16tmTNnSpKuvfZaHTt2TM8//3yJr2G323X8+HFJUrNmzeRyufTdd9/53j906JA2btyo5s2b+/ZZsWKF3zlWrFihxo0by263S5JCQkLUrVs3Pf300/r555+1Y8cOff7555Kk0NBQud3uEtcLAACAyiZ4e5wYqneaGDdunEzT1KRJkyRJKSkpmjJlisaMGaPevXurY8eOuueee3TPPfdo586duvLKK5WcnKy9e/fq1VdflWEYfkMFTdNUamqqJO89TkuXLtXixYt990Q1atRIl19+uYYPH64XX3xR0dHRGjt2rGrXru0bnnfPPffovPPO0+OPP66BAwdq1apVeu6553zh7ZNPPtG2bdt04YUXqlq1alq4cKE8Ho+aNGni+wzfffedduzYoaioKFWvXj2o5/4HAAA40/n/JRdcwYm/Qk8DX375pWbMmKFZs2b53R906623qlOnTr4he1OmTNHbb7+ttWvX6tJLL1WjRo10zTXXyOPxaNWqVYqJifEdm5aWpqSkJCUlJalZs2Z65plnNGHCBL+H6c6aNUtt27bVpZdeqo4dO8o0TS1cuFAOh0OSdwa+d999V3PmzFHLli31yCOPaMKECRoyZIgk71DBDz74QBdffLGaNWummTNn6p133lGLFi0kSWPGjJHdblfz5s1Vs2ZN7dq1qwK+TQAAAJSbk4bqBdlIPXqcTgddunSRy+Uq8L3Fixf7rQ8YMEADBgw45fmGDBniCzenUq1aNd805YW56qqrdNVVVxX43vnnn6/ly5cXemzjxo21atWqIusAAABAcDD8glNwJSd6nAAAAABUiGB+jhPBCQAAAEAFyQtOHnksrCNwBCcAAAAAFcLGdOQAAAAAUIQAn1NamRCcAAAAAFQ4JocAAAAAgAL4DdXjOU4AAAAAUJCTJ4cILgQnAAAAABXC8Jscwro6SoLgBAAAAKBCGLbgjR/BWzmC3o4dO2QYhtatW1foPsuXL5dhGDpy5EiF1QUAAIAKYLqtriAglSI4zZgxQykpKQoPD1eHDh20evXqQvedPXu2DMPw+wkPD6/AaiunIUOG5PteDMNQr169rC4NAAAACHohVhcwd+5cjR49WjNnzlSHDh00bdo09ezZUxs3blR8fHyBx8TExGjjxo2+dSOI54MvS7169dKsWbP8toWFhVlUDQAAAHD6sLzHaerUqRo+fLiGDh2q5s2ba+bMmYqMjNRrr71W6DGGYSgxMdH3k5CQUG71maapTGdmuf4cdx0vcHugc9uHhYX5fS+JiYmqVq2aJO939sorr+iKK65QZGSkGjVqpPnz5/uOPXz4sAYNGqSaNWsqIiJCjRo18gthu3fv1oABAxQbG6vq1avr8ssv144dO3zvDxkyRP3799dTTz2lhIQExcbGasKECXK5XLr33ntVvXp11alTJ1+wk6QNGzaoU6dOCg8PV8uWLfXll1+e8nN+8803uuCCCxQREaHk5GTdcccdysjICOi7AgAAgLVMT3DNq2dpj1NOTo7WrFmjcePG+bbZbDZ169ZNq1atKvS4Y8eOqW7duvJ4PDr33HP11FNPqUWLFgXum52drezsbN96WlqaJMnpdMrpdPrt63Q6ZZqmPB6PPCd+kZnOTHWc07HEn7E0Vv1jlSIdkcXa1zRNX+2FeeyxxzRp0iRNnjxZzz33nAYNGqTt27erevXqeuihh/T7779rwYIFqlGjhrZs2aLjx4/L4/HI6XSqZ8+e+r//+z99+eWXCgkJ0ZNPPqlevXpp3bp1Cg0NlWma+vzzz1W7dm0tX75cK1as0PDhw7VixQpdeOGFWrVqld59913deuutuuSSS1SnTh1frffee6+mTp2q5s2b69lnn1W/fv20detWxcXF+fbJ/Z1s3bpVvXr10uOPP65XXnlFBw4c0B133KGRI0eeMmyfLnLDdEG/a4/HI9M05XQ6ZbfbrSgPlVDuf+f+/t87oDC0GQSKNoNAGaYp0zDkdLstbzeBXN/S4HTw4EG53e58PUYJCQnasGFDgcc0adJEr732ms4++2wdPXpUU6ZMUadOnfTbb7+pTp06+fafOHGiHnvssXzblyxZoshI/1ASEhKixMREHTt2TDk5OZKk467jJf14pZaeni5XiKtY+zqdTi1YsEAxMTF+2++++27dc889kqR//OMf6tu3ryTp/vvv13/+8x8tX75c3bp107Zt29SiRQs1btxYktS+fXtJ3qA5d+5cuVwuPfPMM75hkdOmTVNKSooWLlyoiy++WE6nU7GxsXr88cdls9l09dVX6+mnn1Z6erpGjhwpSRoxYoQmT56spUuX6qqrrtKxY8ckSTfffLO6d+8uSZo0aZI+/fRTPf/887rzzjuVmZnp+y5sNpsef/xxXX311Ro6dKgkb1t58skndemll2rSpElnzP1u6enp+bbl5OTo+PHj+uqrr+RyFa/d4MyxdOlSq0tAkKHNIFC0GRRX42zvP/CuW/OTtq3/09Jacv/WLA7L73EKVMeOHdWxY14PUKdOndSsWTO9+OKLevzxx/PtP27cOI0ePdq3npaWpuTkZPXo0SNfyMjKytLu3bsVFRXl+wM82ozWqn8U3vtVFtLT0xUdHZ1ve0RIRLHv33I4HOratauef/55v+3Vq1f3fc527dr5lmNiYhQTE6Njx44pJiZGo0aN0jXXXKNff/1V3bt31+WXX65OnTpJkjZv3qxt27YpOTnZ79xZWVnau3evYmJi5HA41LJlS8XGxvreT0pKUosWLfy+57i4ON81o6KiJEldu3b12+e8887T9u3bFRMT4wu30dHRiomJ0fr16/Xzzz9r3rx5vv1ze18OHTqkZs2aFev7Clamafray9/bRlZWliIiInThhReeMQESRXM6nVq6dKm6d+8uh8NhdTkIArQZBIo2g0B1d3avNG0mdzRacVganGrUqCG73a59+/b5bd+3b58SExOLdQ6Hw6FzzjlHW7ZsKfD9sLCwAidIcDgc+X5RbrdbhmHIZrPJdtIc81H2qGLVUhIej0euEJciHZF+1wyUYRiKiory9RgVJCwszO8auX9422w29e3bVzt37tTChQt9DXnkyJGaMmWKMjIy1LZtW7311lv5zlmzZk3ZbDYZhqHQ0NB85y9om2maft/x37/v3BkBC9rn2LFjuvXWW3XHHXfkq+Wss84q1XcYDHKH5+V+PyfL/T0U1LYB2gUCRZtBoGgzCFRlaDOBXN/SvzJDQ0PVtm1bLVu2zLfN4/Fo2bJlfr1Kp+J2u/XLL78oKSmpvMo8Y9SsWVODBw/Wf//7X02bNk0vvfSSJOncc8/V5s2bFR8fr4YNG/r9VK1atdTX/fbbb33LLpdLa9asKbTn6Nxzz9Xvv/+er46GDRsqNDS01LUAAAAABbH8n+dHjx6tl19+Wa+//rrWr1+v22+/XRkZGb57WG688Ua/ySMmTJigJUuWaNu2bfrxxx91/fXXa+fOnRo2bJhVH6HSyM7OVmpqqt/PwYMHi3XsI488oo8//lhbtmzRb7/9pk8++cQXXgYNGqQaNWro8ssv19dff63t27dr+fLluuOOO/THH3+Uuu4ZM2boww8/1IYNGzRy5EgdPnxYN910U4H73n///Vq5cqVGjRqldevWafPmzfr44481atSoUtcBAAAAFMbye5wGDhyoAwcO6JFHHlFqaqratGmjRYsW+SaM2LVrl9+QpMOHD2v48OFKTU1VtWrV1LZtW61cuVLNmze36iNUGosWLcrX89akSZNCJ9o4WWhoqMaNG6cdO3YoIiJCF1xwgebMmSNJioyM1FdffaX7779fV155pdLT01W7dm1dcskl+e4TK4lJkyZp0qRJWrdunRo2bKj58+erRo0aBe579tln68svv9SDDz6oCy64QKZpqkGDBho4cGCp6wAAAAAKY5iBPiwoyKWlpalq1ao6evRogZNDbN++XfXq1auwm+s9Ho/S0tIUExNz2t+fg9I7VXuxov2i8nM6nVq4cKH69Olj+ThyBAfaDAJFm0GgKlObOVU2+Dv+UgcAAACAIhCcAAAAAKAIBCcAAAAAKALBCQAAAACKQHAqwBk2XwZOE7RbAACA8kNwOknurB6ZmZkWVwIELrfdWj07DQAAwOnI8uc4VSZ2u12xsbHav3+/JO/ziwzDKNdrejwe5eTkKCsri+nIUaSC2otpmsrMzNT+/fsVGxsru91ucZUAAACnH4LT3yQmJkqSLzyVN9M0dfz4cUVERJR7SEPwO1V7iY2N9bVfAAAAlC2C098YhqGkpCTFx8fL6XSW+/WcTqe++uorXXjhhQyxQpEKay8Oh4OeJgAAgHJEcCqE3W6vkD9E7Xa7XC6XwsPDCU4oEu0FAADAGtxUAwAAAABFIDgBAAAAQBEITgAAAABQhDPuHqfch4SmpaVZXImX0+lUZmam0tLSuGcFRaK9IFC0GQSKNoNA0WYQqMrUZnIzQW5GOJUzLjilp6dLkpKTky2uBAAAAEBlkJ6erqpVq55yH8MsTrw6jXg8Hv3555+Kjo6uFM9NSktLU3Jysnbv3q2YmBiry0ElR3tBoGgzCBRtBoGizSBQlanNmKap9PR01apVSzbbqe9iOuN6nGw2m+rUqWN1GfnExMRY3nAQPGgvCBRtBoGizSBQtBkEqrK0maJ6mnIxOQQAAAAAFIHgBAAAAABFIDhZLCwsTOPHj1dYWJjVpSAI0F4QKNoMAkWbQaBoMwhUsLaZM25yCAAAAAAIFD1OAAAAAFAEghMAAAAAFIHgBAAAAABFIDgBAAAAQBEITuVsxowZSklJUXh4uDp06KDVq1efcv/33ntPTZs2VXh4uFq1aqWFCxdWUKWoLAJpMy+//LIuuOACVatWTdWqVVO3bt2KbGM4/QT635lcc+bMkWEY6t+/f/kWiEon0DZz5MgRjRw5UklJSQoLC1Pjxo3536czTKBtZtq0aWrSpIkiIiKUnJysu+++W1lZWRVULaz21VdfqV+/fqpVq5YMw9BHH31U5DHLly/Xueeeq7CwMDVs2FCzZ88u9zoDRXAqR3PnztXo0aM1fvx4/fjjj2rdurV69uyp/fv3F7j/ypUrde211+rmm2/W2rVr1b9/f/Xv31+//vprBVcOqwTaZpYvX65rr71WX3zxhVatWqXk5GT16NFDe/bsqeDKYZVA20yuHTt2aMyYMbrgggsqqFJUFoG2mZycHHXv3l07duzQvHnztHHjRr388suqXbt2BVcOqwTaZt5++22NHTtW48eP1/r16/Xqq69q7ty5euCBByq4clglIyNDrVu31owZM4q1//bt29W3b19ddNFFWrdune666y4NGzZMixcvLudKA2Si3LRv394cOXKkb93tdpu1atUyJ06cWOD+AwYMMPv27eu3rUOHDuatt95arnWi8gi0zfydy+Uyo6Ojzddff728SkQlU5I243K5zE6dOpmvvPKKOXjwYPPyyy+vgEpRWQTaZl544QWzfv36Zk5OTkWViEom0DYzcuRI8+KLL/bbNnr0aLNz587lWicqJ0nmhx9+eMp97rvvPrNFixZ+2wYOHGj27NmzHCsLHD1O5SQnJ0dr1qxRt27dfNtsNpu6deumVatWFXjMqlWr/PaXpJ49exa6P04vJWkzf5eZmSmn06nq1auXV5moREraZiZMmKD4+HjdfPPNFVEmKpGStJn58+erY8eOGjlypBISEtSyZUs99dRTcrvdFVU2LFSSNtOpUyetWbPGN5xv27ZtWrhwofr06VMhNSP4BMvfwCFWF3C6OnjwoNxutxISEvy2JyQkaMOGDQUek5qaWuD+qamp5VYnKo+StJm/u//++1WrVq18//HB6akkbeabb77Rq6++qnXr1lVAhahsStJmtm3bps8//1yDBg3SwoULtWXLFo0YMUJOp1Pjx4+viLJhoZK0meuuu04HDx7U+eefL9M05XK5dNtttzFUD4Uq7G/gtLQ0HT9+XBERERZV5o8eJ+A0MWnSJM2ZM0cffvihwsPDrS4HlVB6erpuuOEGvfzyy6pRo4bV5SBIeDwexcfH66WXXlLbtm01cOBAPfjgg5o5c6bVpaGSWr58uZ566ik9//zz+vHHH/XBBx9owYIFevzxx60uDSgVepzKSY0aNWS327Vv3z6/7fv27VNiYmKBxyQmJga0P04vJWkzuaZMmaJJkybps88+09lnn12eZaISCbTNbN26VTt27FC/fv182zwejyQpJCREGzduVIMGDcq3aFiqJP+dSUpKksPhkN1u921r1qyZUlNTlZOTo9DQ0HKtGdYqSZt5+OGHdcMNN2jYsGGSpFatWikjI0O33HKLHnzwQdls/Ls9/BX2N3BMTEyl6W2S6HEqN6GhoWrbtq2WLVvm2+bxeLRs2TJ17NixwGM6duzot78kLV26tND9cXopSZuRpKefflqPP/64Fi1apHbt2lVEqagkAm0zTZs21S+//KJ169b5fi677DLfLEbJyckVWT4sUJL/znTu3FlbtmzxhWxJ2rRpk5KSkghNZ4CStJnMzMx84Sg3eJumWX7FImgFzd/AVs9OcTqbM2eOGRYWZs6ePdv8/fffzVtuucWMjY01U1NTTdM0zRtuuMEcO3asb/8VK1aYISEh5pQpU8z169eb48ePNx0Oh/nLL79Y9RFQwQJtM5MmTTJDQ0PNefPmmXv37vX9pKenW/URUMECbTN/x6x6Z55A28yuXbvM6Ohoc9SoUebGjRvNTz75xIyPjzefeOIJqz4CKligbWb8+PFmdHS0+c4775jbtm0zlyxZYjZo0MAcMGCAVR8BFSw9Pd1cu3atuXbtWlOSOXXqVHPt2rXmzp07TdM0zbFjx5o33HCDb/9t27aZkZGR5r333muuX7/enDFjhmm3281FixZZ9REKRHAqZ//5z3/Ms846ywwNDTXbt29vfvvtt773unTpYg4ePNhv/3fffdds3LixGRoaarZo0cJcsGBBBVcMqwXSZurWrWtKyvczfvz4ii8clgn0vzMnIzidmQJtMytXrjQ7dOhghoWFmfXr1zeffPJJ0+VyVXDVsFIgbcbpdJqPPvqo2aBBAzM8PNxMTk42R4wYYR4+fLjiC4clvvjiiwL/PsltJ4MHDza7dOmS75g2bdqYoaGhZv369c1Zs2ZVeN1FMUyTPlMAAAAAOBXucQIAAACAIhCcAAAAAKAIBCcAAAAAKALBCQAAAACKQHACAAAAgCIQnAAAAACgCAQnAAAAACgCwQkAAAAAikBwAgAgAIZh6KOPPpIk7dixQ4ZhaN26dZbWBAAofwQnAEDQGDJkiAzDkGEYcjgcqlevnu677z5lZWVZXRoA4DQXYnUBAAAEolevXpo1a5acTqfWrFmjwYMHyzAMTZ482erSAACnMXqcAABBJSwsTImJiUpOTlb//v3VrVs3LV26VJLk8Xg0ceJE1atXTxEREWrdurXmzZvnd/xvv/2mSy+9VDExMYqOjtYFF1ygrVu3SpK+//57de/eXTVq1FDVqlXVpUsX/fjjjxX+GQEAlQ/BCQAQtH799VetXLlSoaGhkqSJEyfqjTfe0MyZM/Xbb7/p7rvv1vXXX68vv/xSkrRnzx5deOGFCgsL0+eff641a9bopptuksvlkiSlp6dr8ODB+uabb/Ttt9+qUaNG6tOnj9LT0y37jACAyoGhegCAoPLJJ58oKipKLpdL2dnZstlseu6555Sdna2nnnpKn332mTp27ChJql+/vr755hu9+OKL6tKli2bMmKGqVatqzpw5cjgckqTGjRv7zn3xxRf7Xeull15SbGysvvzyS1166aUV9yEBAJUOwQkAEFQuuugivfDCC8rIyNCzzz6rkJAQXXXVVfrtt9+UmZmp7t27++2fk5Ojc845R5K0bt06XXDBBb7Q9Hf79u3TQw89pOXLl2v//v1yu93KzMzUrl27yv1zAQAqN4ITACCoVKlSRQ0bNpQkvfbaa2rdurVeffVVtWzZUpK0YMEC1a5d2++YsLAwSVJERMQpzz148GAdOnRI06dPV926dRUWFqaOHTsqJyenHD4JACCYEJwAAEHLZrPpgQce0OjRo7Vp0yaFhYVp165d6tKlS4H7n3322Xr99dfldDoL7HVasWKFnn/+efXp00eStHv3bh08eLBcPwMAIDgwOQQAIKhdc801stvtevHFFzVmzBjdfffdev3117V161b9+OOP+s9//qPXX39dkjRq1CilpaXpH//4h3744Qdt3rxZb775pjZu3ChJatSokd58802tX79e3333nQYNGlRkLxUA4MxAjxMAIKiFhIRo1KhRevrpp7V9+3bVrFlTEydO1LZt2xQbG6tzzz1XDzzwgCQpLi5On3/+ue6991516dJFdrtdbdq0UefOnSVJr776qm655Rade+65Sk5O1lNPPaUxY8ZY+fEAAJWEYZqmaXURAAAAAFCZMVQPAAAAAIpAcAIAAACAIhCcAAAAAKAIBCcAAAAAKALBCQAAAACKQHACAAAAgCIQnAAAAACgCAQnAAAAACgCwQkAAAAAikBwAgAAAIAiEJwAAAAAoAj/Dx3r+sacuVBoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Features (Gradient Boosting):\n",
            "                  feature  importance\n",
            "4       Annual.pct.driven    0.368805\n",
            "3               Territory    0.163293\n",
            "2          Years.noclaims    0.113777\n",
            "1            Credit.score    0.086114\n",
            "8   Left.turn.intensity09    0.080846\n",
            "0             Insured.age    0.063824\n",
            "6           Brake.06miles    0.048636\n",
            "5           Accel.06miles    0.048536\n",
            "9  Right.turn.intensity08    0.013113\n",
            "7   Left.turn.intensity08    0.013056\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Pipeline completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime SHAP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsg491ShWtrY",
        "outputId": "2838bbe1-51f0-4a75-f3f2-2547037a49d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SHAP in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from SHAP) (2.2.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from SHAP) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from SHAP) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from SHAP) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from SHAP) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SHAP) (4.14.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->SHAP) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->SHAP) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->SHAP) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=ba4e4964a5b887379361ca1644047659ac99ae45047773faa046e00655ce6023\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For data splitting and preprocessing\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
        "    roc_curve, precision_recall_curve\n",
        ")\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# For interpretability\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "# For deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Google Colab mount (if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: LOAD AND PREPROCESS DATA\n",
        "# =============================================================================\n",
        "\n",
        "file_path = '/content/drive/My Drive/Insurance/telematics_syn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Derive target\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "\n",
        "# Handle negative Car.age\n",
        "if 'Car.age' in df.columns:\n",
        "    median_age = df[df['Car.age'] >= 0]['Car.age'].median()\n",
        "    df.loc[df['Car.age'] < 0, 'Car.age'] = median_age\n",
        "    print(f\"Imputed negative Car.age with median: {median_age:.1f}\")\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Log-transform skewed intensity features\n",
        "intensity_cols = [col for col in df.columns if 'intensity' in col.lower() or\n",
        "                  'accel' in col.lower() or 'brake' in col.lower() or\n",
        "                  'driving.percentage' in col.lower() or 'speed' in col.lower()]\n",
        "for col in intensity_cols:\n",
        "    if col != 'ClaimYN':\n",
        "        df[col] = np.log1p(df[col])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: FEATURE SCALING AND SMOTE\n",
        "# =============================================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "print(f\"SMOTE: Balanced dataset size: {X_resampled.shape[0]} samples\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: TRAIN-VALIDATION-TEST SPLIT\n",
        "# =============================================================================\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.15, random_state=42, stratify=y_resampled\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: GRADIENT BOOSTING PATH\n",
        "# =============================================================================\n",
        "\n",
        "# Hyperparameter grid\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_search = RandomizedSearchCV(\n",
        "    gb, gb_param_grid, n_iter=10, cv=3, scoring='roc_auc', n_jobs=-1, random_state=42\n",
        ")\n",
        "gb_search.fit(X_train, y_train)\n",
        "gb_best = gb_search.best_estimator_\n",
        "\n",
        "print(\"\\n✅ Gradient Boosting Path trained.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: NEURAL PROCESSING PATH WITH xLSTM-INSPIRED LAYER\n",
        "# =============================================================================\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train.values)\n",
        "X_val_tensor = torch.FloatTensor(X_val.values)\n",
        "X_test_tensor = torch.FloatTensor(X_test.values)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values)\n",
        "y_val_tensor = torch.FloatTensor(y_val.values)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=128, shuffle=True)\n",
        "\n",
        "# Define xLSTM-inspired sub-layer\n",
        "class xLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(xLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Standard LSTM gates\n",
        "        self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.candidate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "        # \"Forget-and-Reintegrate\" mechanism\n",
        "        self.noise_filter = nn.Linear(hidden_size, hidden_size)\n",
        "        self.reintegrate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        h, c = hidden\n",
        "\n",
        "        # Concatenate input and hidden state\n",
        "        combined = torch.cat((x, h), dim=1)\n",
        "\n",
        "        # Standard LSTM\n",
        "        f = self.sigmoid(self.forget_gate(combined))\n",
        "        i = self.sigmoid(self.input_gate(combined))\n",
        "        o = self.sigmoid(self.output_gate(combined))\n",
        "        g = self.tanh(self.candidate(combined))\n",
        "\n",
        "        c_next = f * c + i * g\n",
        "        h_next = o * self.tanh(c_next)\n",
        "\n",
        "        # xLSTM-inspired: noise filtering and reintegrate\n",
        "        filtered = self.tanh(self.noise_filter(h_next))\n",
        "        reintegrated = self.sigmoid(self.reintegrate(filtered))\n",
        "        h_enhanced = h_next * (1 - reintegrated) + filtered * reintegrated\n",
        "\n",
        "        return h_enhanced, c_next\n",
        "\n",
        "class xLSTMBlock(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(xLSTMBlock, self).__init__()\n",
        "        self.cell = xLSTMCell(input_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        seq_len, batch_size, _ = x.size()\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            hidden = self.cell(x[t], hidden)\n",
        "            outputs.append(hidden[0])\n",
        "        return torch.stack(outputs), hidden\n",
        "\n",
        "# Full Neural Processing Path\n",
        "class NeuralProcessingPath(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes=[100, 50]):\n",
        "        super(NeuralProcessingPath, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
        "        self.xlstm = xLSTMBlock(hidden_sizes[0], hidden_sizes[0])  # xLSTM after first layer\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape for sequence processing: treat features as time steps\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = x.unsqueeze(0)  # Add sequence dim (1, batch, features)\n",
        "        h0 = (torch.zeros(x.size(1), x.size(2)), torch.zeros(x.size(1), x.size(2)))\n",
        "        x, _ = self.xlstm(x, h0)\n",
        "        x = x.squeeze(0)  # Remove sequence dim\n",
        "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
        "        return torch.sigmoid(self.fc3(x)).squeeze()\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = NeuralProcessingPath(X_train.shape[1]).to(device)\n",
        "\n",
        "# Training\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(50):  # Reduce epochs for speed\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(\"✅ Neural Processing Path (xLSTM-enhanced) trained.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: ENSEMBLE PREDICTION\n",
        "# =============================================================================\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    nn_val_proba = model(X_val_tensor).numpy()\n",
        "    nn_test_proba = model(X_test_tensor).numpy()\n",
        "\n",
        "gb_val_proba = gb_best.predict_proba(X_val)[:, 1]\n",
        "gb_test_proba = gb_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute weights from validation accuracy\n",
        "gb_val_pred = (gb_val_proba >= 0.5).astype(int)\n",
        "nn_val_pred = (nn_val_proba >= 0.5).astype(int)\n",
        "\n",
        "acc_gb = accuracy_score(y_val, gb_val_pred)\n",
        "acc_nn = accuracy_score(y_val, nn_val_pred)\n",
        "\n",
        "w_gb = acc_gb / (acc_gb + acc_nn)\n",
        "w_nn = acc_nn / (acc_gb + acc_nn)\n",
        "\n",
        "print(f\"\\nEnsemble Weights: GB={w_gb:.3f}, NN={w_nn:.3f}\")\n",
        "\n",
        "# Final ensemble probability\n",
        "ensemble_val_proba = w_gb * gb_val_proba + w_nn * nn_val_proba\n",
        "ensemble_test_proba = w_gb * gb_test_proba + w_nn * nn_test_proba\n",
        "\n",
        "# Optimize threshold on validation set\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, ensemble_val_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
        "\n",
        "ensemble_test_pred = (ensemble_test_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: MODEL EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate(y_true, y_pred, y_proba, name):\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"F1:        {f1_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"AUC-ROC:   {roc_auc_score(y_true, y_proba):.4f}\")\n",
        "    print(f\"MCC:       {matthews_corrcoef(y_true, y_pred):.4f}\")\n",
        "\n",
        "evaluate(y_test, gb_best.predict(X_test), gb_test_proba, \"Gradient Boosting\")\n",
        "evaluate(y_test, (nn_test_proba >= 0.5).astype(int), nn_test_proba, \"Neural Path\")\n",
        "evaluate(y_test, ensemble_test_pred, ensemble_test_proba, \"Dual-Path Ensemble\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: INTERPRETABILITY (SHAP & LIME)\n",
        "# =============================================================================\n",
        "\n",
        "# SHAP for Gradient Boosting\n",
        "explainer = shap.TreeExplainer(gb_best)\n",
        "shap_values = explainer.shap_values(X_val)\n",
        "shap.summary_plot(shap_values, X_val, show=False)\n",
        "plt.title(\"SHAP Feature Importance (Gradient Boosting)\")\n",
        "plt.show()\n",
        "\n",
        "# LIME for a sample instance\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train.values, feature_names=X_train.columns, class_names=['No Claim', 'Claim'],\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "i = np.random.randint(0, len(X_test))\n",
        "exp = lime_explainer.explain_instance(\n",
        "    X_test.iloc[i].values, lambda x: gb_best.predict_proba(x), num_features=10\n",
        ")\n",
        "exp.show_in_notebook(show_table=True)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "# ROC Curves\n",
        "plt.figure(figsize=(8, 6))\n",
        "fpr_gb, tpr_gb, _ = roc_curve(y_test, gb_test_proba)\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, nn_test_proba)\n",
        "fpr_ens, tpr_ens, _ = roc_curve(y_test, ensemble_test_proba)\n",
        "\n",
        "plt.plot(fpr_gb, tpr_gb, label=f\"GB (AUC = {roc_auc_score(y_test, gb_test_proba):.3f})\")\n",
        "plt.plot(fpr_nn, tpr_nn, label=f\"NN (AUC = {roc_auc_score(y_test, nn_test_proba):.3f})\")\n",
        "plt.plot(fpr_ens, tpr_ens, label=f\"Ensemble (AUC = {roc_auc_score(y_test, ensemble_test_proba):.3f})\")\n",
        "plt.plot([0,1],[0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves'); plt.legend(); plt.grid(True); plt.show()\n",
        "\n",
        "print(\"\\n✅ Framework execution completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "LapqkR37WrSM",
        "outputId": "462b0610-7677-4f03-c22e-725241ecf40d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Imputed negative Car.age with median: 5.0\n",
            "SMOTE: Balanced dataset size: 194604 samples\n",
            "Train: 136300, Val: 29113, Test: 29191\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-239385404.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m )\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mgb_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0mgb_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES (Minimal & Efficient)\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, matthews_corrcoef, precision_recall_curve, roc_curve\n",
        ")\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# SHAP & LIME (lightweight use)\n",
        "import shap\n",
        "\n",
        "# PyTorch (optimized)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Google Colab mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: LOAD AND PREPROCESS DATA (Efficient)\n",
        "# =============================================================================\n",
        "\n",
        "file_path = '/content/drive/My Drive/Insurance/telematics_syn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Derive target\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "df.drop(['NB_Claim', 'AMT_Claim'], axis=1, inplace=True)\n",
        "\n",
        "# Fix negative Car.age\n",
        "if 'Car.age' in df.columns:\n",
        "    median_age = df.loc[df['Car.age'] >= 0, 'Car.age'].median()\n",
        "    df.loc[df['Car.age'] < 0, 'Car.age'] = median_age\n",
        "\n",
        "# One-hot encode\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Log-transform intensity-related features\n",
        "intensity_keywords = ['intensity', 'accel', 'brake', 'percentage', 'speed']\n",
        "intensity_cols = [c for c in df.columns if any(k in c.lower() for k in intensity_keywords) and c != 'ClaimYN']\n",
        "df[intensity_cols] = np.log1p(df[intensity_cols])\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: SCALE & BALANCE (Optimized SMOTE)\n",
        "# =============================================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# SMOTE only on training data (avoid data leakage)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Apply SMOTE to training only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_temp, y_temp)\n",
        "\n",
        "# Now split train into train + val\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.176, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "# Convert to DataFrame for easier handling later\n",
        "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
        "X_val = pd.DataFrame(X_val, columns=X.columns)\n",
        "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
        "\n",
        "print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: GRADIENT BOOSTING (Faster Randomized Search)\n",
        "# =============================================================================\n",
        "\n",
        "# Reduced hyperparameter grid and iterations\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 150],\n",
        "    'learning_rate': [0.1, 0.15],\n",
        "    'max_depth': [4, 5],\n",
        "    'min_samples_split': [10],\n",
        "    'min_samples_leaf': [2],\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_search = RandomizedSearchCV(\n",
        "    gb, gb_param_grid, n_iter=6, cv=3, scoring='roc_auc', n_jobs=-1, random_state=42, verbose=0\n",
        ")\n",
        "gb_search.fit(X_train, y_train)\n",
        "gb_best = gb_search.best_estimator_\n",
        "\n",
        "print(\"✅ Gradient Boosting trained.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: NEURAL NETWORK (SIMPLIFIED xLSTM-INSPIRED MODEL)\n",
        "# =============================================================================\n",
        "\n",
        "# Simplified xLSTM-inspired layer using efficient linear transforms\n",
        "class xLSTMBlock(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.linear = nn.Linear(input_dim, 4 * hidden_dim)  # f, i, o, g\n",
        "        self.filter = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.reintegrate = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        h, c = hidden\n",
        "        combined = torch.cat((x, h), dim=1)\n",
        "        gates = self.linear(combined)\n",
        "        f, i, o, g = gates.chunk(4, dim=1)\n",
        "\n",
        "        f = self.sigmoid(f)\n",
        "        i = self.sigmoid(i)\n",
        "        o = self.sigmoid(o)\n",
        "        g = self.tanh(g)\n",
        "\n",
        "        c = f * c + i * g\n",
        "        h = o * self.tanh(c)\n",
        "\n",
        "        # xLSTM-style enhancement\n",
        "        filtered = self.tanh(self.filter(h))\n",
        "        r = self.sigmoid(self.reintegrate(filtered))\n",
        "        h = h * (1 - r) + filtered * r\n",
        "\n",
        "        return h, c\n",
        "\n",
        "# Efficient FF + xLSTM model\n",
        "class NeuralPath(nn.Module):\n",
        "    def __init__(self, input_size, hidden_dims=[128, 64]):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_dims[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dims[0])\n",
        "        self.xlstm = xLSTMBlock(hidden_dims[0], hidden_dims[0])\n",
        "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dims[1])\n",
        "        self.fc3 = nn.Linear(hidden_dims[1], 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        batch_size = x.size(0)\n",
        "        h0 = (torch.zeros(batch_size, self.xlstm.hidden_dim).to(x.device),\n",
        "              torch.zeros(batch_size, self.xlstm.hidden_dim).to(x.device))\n",
        "        x, _ = self.xlstm(x, h0)\n",
        "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
        "        return torch.sigmoid(self.fc3(x)).squeeze()\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train.values).to(device)\n",
        "X_val_tensor = torch.FloatTensor(X_val.values).to(device)\n",
        "X_test_tensor = torch.FloatTensor(X_test.values).to(device)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values).to(device)\n",
        "y_val_tensor = torch.FloatTensor(y_val.values).to(device)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train_tensor, y_train_tensor),\n",
        "    batch_size=256, shuffle=True, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "# Model\n",
        "model = NeuralPath(X_train.shape[1]).to(device)\n",
        "\n",
        "# Optimizer and loss\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "best_val_loss = float('inf')\n",
        "patience, wait = 0, 0\n",
        "\n",
        "print(\"Training Neural Path...\")\n",
        "\n",
        "for epoch in range(50):\n",
        "    epoch_loss = 0.0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(train_loader)\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= 10:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"✅ Neural Path trained.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: ENSEMBLE WITH OPTIMAL THRESHOLD\n",
        "# =============================================================================\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    nn_val_proba = model(X_val_tensor).cpu().numpy()\n",
        "    nn_test_proba = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "gb_val_proba = gb_best.predict_proba(X_val)[:, 1]\n",
        "gb_test_proba = gb_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Weighting by validation AUC (more stable than accuracy)\n",
        "auc_gb = roc_auc_score(y_val, gb_val_proba)\n",
        "auc_nn = roc_auc_score(y_val, nn_val_proba)\n",
        "w_gb = auc_gb / (auc_gb + auc_nn)\n",
        "w_nn = auc_nn / (auc_gb + auc_nn)\n",
        "\n",
        "print(f\"Ensemble Weights: GB={w_gb:.3f}, NN={w_nn:.3f}\")\n",
        "\n",
        "# Ensemble probabilities\n",
        "ensemble_val_proba = w_gb * gb_val_proba + w_nn * nn_val_proba\n",
        "ensemble_test_proba = w_gb * gb_test_proba + w_nn * nn_test_proba\n",
        "\n",
        "# Optimize threshold using F1 on validation\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, ensemble_val_proba)\n",
        "f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
        "\n",
        "ensemble_test_pred = (ensemble_test_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate(y_true, y_pred, y_proba, name):\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"F1:        {f1_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"AUC-ROC:   {roc_auc_score(y_true, y_proba):.4f}\")\n",
        "    print(f\"MCC:       {matthews_corrcoef(y_true, y_pred):.4f}\")\n",
        "\n",
        "evaluate(y_test, gb_best.predict(X_test), gb_test_proba, \"Gradient Boosting\")\n",
        "evaluate(y_test, (nn_test_proba >= 0.5).astype(int), nn_test_proba, \"Neural Path\")\n",
        "evaluate(y_test, ensemble_test_pred, ensemble_test_proba, \"Dual-Path Ensemble\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: INTERPRETABILITY (Efficient SHAP)\n",
        "# =============================================================================\n",
        "\n",
        "# Fast approximate SHAP for tree model\n",
        "explainer = shap.TreeExplainer(gb_best, feature_names=X_train.columns, approximate=True)\n",
        "shap_values = explainer.shap_values(X_val)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(shap_values, X_val, plot_type=\"bar\", show=False)\n",
        "plt.title(\"SHAP Feature Importance (Gradient Boosting)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: ROC CURVE VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "fpr_gb, tpr_gb, _ = roc_curve(y_test, gb_test_proba)\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, nn_test_proba)\n",
        "fpr_ens, tpr_ens, _ = roc_curve(y_test, ensemble_test_proba)\n",
        "\n",
        "plt.plot(fpr_gb, tpr_gb, label=f\"GB (AUC = {roc_auc_score(y_test, gb_test_proba):.3f})\")\n",
        "plt.plot(fpr_nn, tpr_nn, label=f\"NN (AUC = {roc_auc_score(y_test, nn_test_proba):.3f})\")\n",
        "plt.plot(fpr_ens, tpr_ens, label=f\"Ensemble (AUC = {roc_auc_score(y_test, ensemble_test_proba):.3f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves - Model Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Optimization complete. Framework executed efficiently.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXK5mb0mjIMl",
        "outputId": "072b366b-3e8d-44d3-bb49-43dc780cff70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Train: 136301, Val: 29113, Test: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fs-dhc_Tv6Ms"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}