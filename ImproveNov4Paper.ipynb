{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKWQLDzzM9358YELPlUhPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Insurance/blob/main/ImproveNov4Paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PaCF6xK33DD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess data (as per your code)\n",
        "df = pd.read_csv('/content/drive/My Drive/Insurance/telematics_syn.csv')\n",
        "df['ClaimYN'] = ((df['NB_Claim'] >= 1) & (df['AMT_Claim'] > 1000)).astype(int)\n",
        "df = df.drop(['NB_Claim', 'AMT_Claim'], axis=1)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "X = df.drop('ClaimYN', axis=1)\n",
        "y = df['ClaimYN']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split into train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train models\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "nn_model.fit(X_train, y_train)\n",
        "\n",
        "# Get validation predictions and weights\n",
        "gb_val_proba = gb_model.predict_proba(X_val)[:, 1]\n",
        "nn_val_proba = nn_model.predict_proba(X_val)[:, 1]\n",
        "gb_val_acc = accuracy_score(y_val, (gb_val_proba > 0.5).astype(int))\n",
        "nn_val_acc = accuracy_score(y_val, (nn_val_proba > 0.5).astype(int))\n",
        "weight_gb = gb_val_acc / (gb_val_acc + nn_val_acc)\n",
        "weight_nn = nn_val_acc / (gb_val_acc + nn_val_acc)\n",
        "\n",
        "# Weighted ensemble on test set\n",
        "X_test, _, y_test, _ = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "gb_test_proba = gb_model.predict_proba(X_test)[:, 1]\n",
        "nn_test_proba = nn_model.predict_proba(X_test)[:, 1]\n",
        "ensemble_proba = (weight_gb * gb_test_proba + weight_nn * nn_test_proba)\n",
        "ensemble_pred = (ensemble_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\nWeighted Ensemble Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, ensemble_pred):.4f}\")\n",
        "print(f\"AUC-ROC: {roc_auc_score(y_test, ensemble_proba):.4f}\")"
      ]
    }
  ]
}